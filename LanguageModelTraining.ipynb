{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "context_length = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 300\n",
    "n_embd = 384\n",
    "n_layers = 6\n",
    "dropout = 0.2\n",
    "n_heads = 6\n",
    "rope_embeddings = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ai_corpus.txt') as file:\n",
    "    movie_data = file.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the target policy can ever choose a different action if the only actions that count are the actions that are the same from target and behavior policy?\n",
      "I've been struggling on this for the past few days, please help.\n",
      "All cards from this series support CUDA. In fact they even have special cores, designed for faster deep learning calculations called 'tensorcores'.\n",
      "If you want to do some deep learning with big models (NLP, computer vision, GAN) you should also focus on amount of VRAM to fit such models. Nowadays I would say at least 12GB should suffice for some time.\n",
      "So I would select cards with minimum 12GB and buy the best you can afford.\n",
      "Personally, I would probably focus on 3090 and not 3090 ti, as the price increase is pretty significant and probably not worth the increase in computational power.\n",
      "Also if you're new to ML/DL, probably you should first learn some of this stuff before deciding on spending money on equipement. Not all ML/DL models benefits from using GPU over CPU. Smalle\n"
     ]
    }
   ],
   "source": [
    "ind = random.randint(0,len(movie_data)-1000)\n",
    "print(movie_data[ind:ind+1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({' ': 1919096,\n",
       "         'e': 1063796,\n",
       "         't': 864299,\n",
       "         'a': 719236,\n",
       "         'o': 675534,\n",
       "         'i': 650849,\n",
       "         'n': 625419,\n",
       "         's': 559704,\n",
       "         'r': 519164,\n",
       "         'h': 374819,\n",
       "         'l': 369105,\n",
       "         'd': 282793,\n",
       "         'c': 279598,\n",
       "         'u': 271006,\n",
       "         'm': 236245,\n",
       "         'p': 206388,\n",
       "         'f': 181574,\n",
       "         'g': 176674,\n",
       "         'y': 150165,\n",
       "         'w': 135833,\n",
       "         'b': 124871,\n",
       "         '.': 108055,\n",
       "         ',': 104333,\n",
       "         'v': 92668,\n",
       "         '\\n': 78778,\n",
       "         'k': 57687,\n",
       "         'I': 47046,\n",
       "         ')': 43236,\n",
       "         '(': 42864,\n",
       "         '$': 42448,\n",
       "         'x': 38319,\n",
       "         '_': 37376,\n",
       "         '-': 32947,\n",
       "         '\\\\': 30380,\n",
       "         'T': 28208,\n",
       "         '0': 27134,\n",
       "         \"'\": 26107,\n",
       "         '1': 26018,\n",
       "         'A': 23168,\n",
       "         'q': 22816,\n",
       "         '=': 19802,\n",
       "         '{': 18702,\n",
       "         '}': 18698,\n",
       "         '2': 17838,\n",
       "         ':': 17429,\n",
       "         'S': 16138,\n",
       "         'N': 15722,\n",
       "         '/': 13914,\n",
       "         ';': 13478,\n",
       "         'z': 11618,\n",
       "         'L': 11400,\n",
       "         'C': 11252,\n",
       "         '&': 11240,\n",
       "         '?': 11183,\n",
       "         'M': 10874,\n",
       "         'D': 10622,\n",
       "         'P': 10421,\n",
       "         '\"': 9847,\n",
       "         'R': 9770,\n",
       "         '3': 9153,\n",
       "         'j': 8994,\n",
       "         'E': 8176,\n",
       "         'W': 8007,\n",
       "         'B': 7707,\n",
       "         'G': 7629,\n",
       "         'F': 7346,\n",
       "         '5': 7291,\n",
       "         '4': 7028,\n",
       "         'H': 6771,\n",
       "         ']': 6684,\n",
       "         '[': 6651,\n",
       "         'O': 6527,\n",
       "         '+': 5542,\n",
       "         '9': 5233,\n",
       "         '6': 5004,\n",
       "         '8': 4868,\n",
       "         'Y': 4817,\n",
       "         '^': 4492,\n",
       "         'Q': 4486,\n",
       "         '7': 4246,\n",
       "         '*': 4205,\n",
       "         'U': 3329,\n",
       "         'V': 3300,\n",
       "         '#': 2583,\n",
       "         '|': 2536,\n",
       "         'X': 2144,\n",
       "         'K': 1742,\n",
       "         '!': 1367,\n",
       "         '@': 1276,\n",
       "         '%': 1219,\n",
       "         'J': 1103,\n",
       "         'Z': 931,\n",
       "         '’': 589,\n",
       "         '`': 553,\n",
       "         '─': 438,\n",
       "         '~': 311,\n",
       "         '│': 275,\n",
       "         '>': 237,\n",
       "         '”': 196,\n",
       "         '“': 188,\n",
       "         '–': 159,\n",
       "         '\\xa0': 147,\n",
       "         '—': 137,\n",
       "         '−': 122,\n",
       "         '…': 56,\n",
       "         '×': 52,\n",
       "         '┌': 52,\n",
       "         '┐': 52,\n",
       "         '└': 52,\n",
       "         '┘': 52,\n",
       "         '┬': 50,\n",
       "         'π': 44,\n",
       "         'α': 42,\n",
       "         'ö': 40,\n",
       "         '∼': 37,\n",
       "         '‘': 35,\n",
       "         '▽': 34,\n",
       "         '→': 32,\n",
       "         'é': 31,\n",
       "         'γ': 26,\n",
       "         '∞': 25,\n",
       "         'β': 24,\n",
       "         'ü': 22,\n",
       "         'θ': 22,\n",
       "         '┆': 22,\n",
       "         '°': 19,\n",
       "         '←': 18,\n",
       "         '≤': 16,\n",
       "         '<': 16,\n",
       "         'ﬁ': 16,\n",
       "         '′': 14,\n",
       "         'σ': 13,\n",
       "         'ϵ': 12,\n",
       "         '·': 11,\n",
       "         'ß': 10,\n",
       "         'á': 10,\n",
       "         '\\u200b': 10,\n",
       "         'ï': 10,\n",
       "         '≡': 10,\n",
       "         'μ': 10,\n",
       "         'ä': 9,\n",
       "         'ℝ': 9,\n",
       "         '∈': 9,\n",
       "         'ó': 8,\n",
       "         '\\u200c': 8,\n",
       "         '∧': 8,\n",
       "         '∑': 7,\n",
       "         '≈': 7,\n",
       "         'ç': 6,\n",
       "         '\\u200a': 6,\n",
       "         'ε': 6,\n",
       "         '€': 6,\n",
       "         'Δ': 6,\n",
       "         '̶': 6,\n",
       "         '´': 6,\n",
       "         'φ': 6,\n",
       "         'Α': 6,\n",
       "         '┴': 6,\n",
       "         '∆': 6,\n",
       "         '¿': 5,\n",
       "         '∀': 5,\n",
       "         '≥': 5,\n",
       "         '➡': 5,\n",
       "         '∗': 5,\n",
       "         'ú': 5,\n",
       "         'à': 4,\n",
       "         '√': 4,\n",
       "         '²': 4,\n",
       "         'λ': 4,\n",
       "         'ˈ': 4,\n",
       "         'ː': 4,\n",
       "         'ɹ': 4,\n",
       "         '⇒': 3,\n",
       "         '∅': 3,\n",
       "         '◦': 3,\n",
       "         '₂': 3,\n",
       "         'õ': 3,\n",
       "         '∫': 3,\n",
       "         '¬': 3,\n",
       "         '∨': 3,\n",
       "         '¹': 3,\n",
       "         'è': 3,\n",
       "         'í': 3,\n",
       "         'É': 3,\n",
       "         '\\u2028': 3,\n",
       "         'º': 3,\n",
       "         'Ψ': 3,\n",
       "         '±': 2,\n",
       "         '§': 2,\n",
       "         '„': 2,\n",
       "         '⋅': 2,\n",
       "         '₁': 2,\n",
       "         'δ': 2,\n",
       "         'č': 2,\n",
       "         'ć': 2,\n",
       "         '≪': 2,\n",
       "         '↓': 2,\n",
       "         '，': 2,\n",
       "         '∃': 2,\n",
       "         'ã': 2,\n",
       "         '∣': 2,\n",
       "         'ﬃ': 2,\n",
       "         'ł': 2,\n",
       "         '÷': 2,\n",
       "         '†': 2,\n",
       "         'ð': 2,\n",
       "         'ﬂ': 2,\n",
       "         '✅': 2,\n",
       "         '\\xad': 1,\n",
       "         '⇐': 1,\n",
       "         '∪': 1,\n",
       "         '⟨': 1,\n",
       "         '⟩': 1,\n",
       "         '●': 1,\n",
       "         '⊇': 1,\n",
       "         'ō': 1,\n",
       "         '≫': 1,\n",
       "         'ξ': 1,\n",
       "         'ℎ': 1,\n",
       "         '定': 1,\n",
       "         '义': 1,\n",
       "         '一': 1,\n",
       "         '个': 1,\n",
       "         'ę': 1,\n",
       "         '\\u2061': 1,\n",
       "         '↙': 1,\n",
       "         '↖': 1,\n",
       "         '↗': 1,\n",
       "         '⬈': 1,\n",
       "         '³': 1,\n",
       "         'ê': 1,\n",
       "         'â': 1,\n",
       "         '»': 1,\n",
       "         '無': 1,\n",
       "         'ρ': 1,\n",
       "         '½': 1,\n",
       "         '‐': 1,\n",
       "         '：': 1,\n",
       "         '¡': 1,\n",
       "         'Χ': 1,\n",
       "         'ő': 1,\n",
       "         'с': 1,\n",
       "         'л': 1,\n",
       "         'о': 1,\n",
       "         'н': 1,\n",
       "         'ɔ': 1,\n",
       "         'ə': 1,\n",
       "         'ɛ': 1,\n",
       "         'ɪ': 1,\n",
       "         'ﬀ': 1,\n",
       "         '❌': 1,\n",
       "         '⭕': 1,\n",
       "         '\\u2000': 1,\n",
       "         '∏': 1,\n",
       "         'ω': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "char_counts = Counter()\n",
    "char_counts.update(movie_data)\n",
    "char_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing extremely low frequency characters from vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<',\n",
       " '¡',\n",
       " '§',\n",
       " '¬',\n",
       " '\\xad',\n",
       " '°',\n",
       " '±',\n",
       " '²',\n",
       " '³',\n",
       " '´',\n",
       " '·',\n",
       " '¹',\n",
       " 'º',\n",
       " '»',\n",
       " '½',\n",
       " '¿',\n",
       " 'É',\n",
       " '×',\n",
       " 'ß',\n",
       " 'à',\n",
       " 'á',\n",
       " 'â',\n",
       " 'ã',\n",
       " 'ä',\n",
       " 'ç',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'í',\n",
       " 'ï',\n",
       " 'ð',\n",
       " 'ó',\n",
       " 'õ',\n",
       " 'ö',\n",
       " '÷',\n",
       " 'ú',\n",
       " 'ü',\n",
       " 'ć',\n",
       " 'č',\n",
       " 'ę',\n",
       " 'ł',\n",
       " 'ō',\n",
       " 'ő',\n",
       " 'ɔ',\n",
       " 'ə',\n",
       " 'ɛ',\n",
       " 'ɪ',\n",
       " 'ɹ',\n",
       " 'ˈ',\n",
       " 'ː',\n",
       " '̶',\n",
       " 'Α',\n",
       " 'Δ',\n",
       " 'Χ',\n",
       " 'Ψ',\n",
       " 'α',\n",
       " 'β',\n",
       " 'γ',\n",
       " 'δ',\n",
       " 'ε',\n",
       " 'θ',\n",
       " 'λ',\n",
       " 'μ',\n",
       " 'ξ',\n",
       " 'π',\n",
       " 'ρ',\n",
       " 'σ',\n",
       " 'φ',\n",
       " 'ω',\n",
       " 'ϵ',\n",
       " 'л',\n",
       " 'н',\n",
       " 'о',\n",
       " 'с',\n",
       " '\\u2000',\n",
       " '\\u200a',\n",
       " '\\u200b',\n",
       " '\\u200c',\n",
       " '‐',\n",
       " '‘',\n",
       " '„',\n",
       " '†',\n",
       " '…',\n",
       " '\\u2028',\n",
       " '′',\n",
       " '\\u2061',\n",
       " '₁',\n",
       " '₂',\n",
       " '€',\n",
       " 'ℎ',\n",
       " 'ℝ',\n",
       " '←',\n",
       " '→',\n",
       " '↓',\n",
       " '↖',\n",
       " '↗',\n",
       " '↙',\n",
       " '⇐',\n",
       " '⇒',\n",
       " '∀',\n",
       " '∃',\n",
       " '∅',\n",
       " '∆',\n",
       " '∈',\n",
       " '∏',\n",
       " '∑',\n",
       " '∗',\n",
       " '√',\n",
       " '∞',\n",
       " '∣',\n",
       " '∧',\n",
       " '∨',\n",
       " '∪',\n",
       " '∫',\n",
       " '∼',\n",
       " '≈',\n",
       " '≡',\n",
       " '≤',\n",
       " '≥',\n",
       " '≪',\n",
       " '≫',\n",
       " '⊇',\n",
       " '⋅',\n",
       " '┆',\n",
       " '┌',\n",
       " '┐',\n",
       " '└',\n",
       " '┘',\n",
       " '┬',\n",
       " '┴',\n",
       " '▽',\n",
       " '●',\n",
       " '◦',\n",
       " '✅',\n",
       " '❌',\n",
       " '➡',\n",
       " '⟨',\n",
       " '⟩',\n",
       " '⬈',\n",
       " '⭕',\n",
       " '一',\n",
       " '个',\n",
       " '义',\n",
       " '定',\n",
       " '無',\n",
       " 'ﬀ',\n",
       " 'ﬁ',\n",
       " 'ﬂ',\n",
       " 'ﬃ',\n",
       " '，',\n",
       " '：'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_chars = {k for k,v in char_counts.items() if v<100}\n",
    "remove_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = re.sub(f\"[{''.join(remove_chars)}]\",' ' , movie_data)\n",
    "data = re.sub(r\" +\", \" \", data)\n",
    "data = re.sub(r\"\\n+\", \"\\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 104\n",
      "unique_charcters: \n",
      " !\"#$%&'()*+,-./0123456789:;=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ –—’“”−─│\n",
      "Total characters in data: 11635783\n"
     ]
    }
   ],
   "source": [
    "# Getting the vocabulary of characters\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "print(f\"unique_charcters: {''.join(chars)}\")\n",
    "print(f'Total characters in data: {len(data)}')\n",
    "\n",
    "# Character encoding logic\n",
    "stoi = {char:i for i, char in enumerate(chars)}\n",
    "itos = {i:char for i, char in enumerate(chars)}\n",
    "encoder = lambda seq: [stoi[i] for i in seq]\n",
    "decoder = lambda encoding: ''.join([itos[i] for i in encoding])\n",
    "\n",
    "# Encoding the data\n",
    "data = torch.tensor(encoder(data), dtype=torch.long)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "train, test = data[:int(0.9*len(data))], data[int(0.9*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[78, 79, 78,  ..., 73, 68, 69],\n",
       "         [79, 82,  1,  ..., 83, 13,  1],\n",
       "         [78,  1, 84,  ..., 67, 79, 71],\n",
       "         [84,  1, 77,  ..., 72,  1, 34]], device='cuda:0'),\n",
       " tensor([[  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255]], device='cuda:0'),\n",
       " tensor([[79, 78, 83,  ..., 68, 69, 68],\n",
       "         [82,  1, 84,  ..., 13,  1, 65],\n",
       "         [ 1, 84, 72,  ..., 79, 71, 78],\n",
       "         [ 1, 77, 79,  ...,  1, 34, 76]], device='cuda:0'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a sample batch from the data split\n",
    "def get_batch_with_pos(split, batch_size, context_length):\n",
    "    if split == 'train':\n",
    "        data = train\n",
    "    else:\n",
    "        data = test\n",
    "        \n",
    "    #getting random starting indices for the batch_size\n",
    "    start_indices = torch.randint(\n",
    "        len(data) - context_length - 1,\n",
    "        (batch_size,)\n",
    "    )\n",
    "    x_y = torch.stack([data[i:i+context_length+1]for i in start_indices], dim=0)\n",
    "    x, y = x_y[:,:-1], x_y[:,1:]    \n",
    "    pos = torch.arange(batch_size * context_length).reshape(batch_size, context_length) % context_length\n",
    "    x, pos, y = x.to(device), pos.to(device), y.to(device)\n",
    "    return x, pos, y\n",
    "\n",
    "x, pos, y = get_batch_with_pos('train', 4, context_length)\n",
    "x, pos, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE(nn.Module):\n",
    "    def __init__(self, base, dim, max_seq_len):\n",
    "        super(RoPE, self).__init__()\n",
    "        theta = base ** -(torch.arange(0,dim,2)/dim)\n",
    "        pos = torch.arange(max_seq_len)\n",
    "        freq = torch.einsum('i,j->ij', pos, theta)\n",
    "        self.register_buffer('cos', freq.cos())\n",
    "        self.register_buffer('sin', freq.sin())\n",
    "    def forward(self, x):\n",
    "        B, S, _ = x.shape\n",
    "        cos = self.cos[:S]\n",
    "        sin = self.sin[:S]\n",
    "        a, b = x[:,:,::2], x[:,:,1::2]\n",
    "        a_cos, b_cos, a_sin, b_sin = a * cos, b * cos, a * sin, b * sin\n",
    "        # rot(a,b) = a cos(theta) - b sin(theta), a sin(theta) + b cos(theta)\n",
    "        rot_1, rot_2 = a_cos - b_sin, a_sin + b_cos\n",
    "        rot = torch.stack((rot_1, rot_2), -1)\n",
    "        rot_embd = rot.reshape(B, S, -1)\n",
    "        return rot_embd\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFroward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super(FeedFroward, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd*4, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.query = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.key = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.value = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if rope_embeddings:\n",
    "            self.rope = RoPE(1e4, head_dim, 2048)\n",
    "\n",
    "    def forward(self, embed, verbose=False):\n",
    "        q = self.query(embed)\n",
    "        k = self.key(embed)\n",
    "        v = self.value(embed)\n",
    "        if rope_embeddings:\n",
    "            q = self.rope(q)\n",
    "            k = self.rope(k)\n",
    "        a = q @ k.transpose(-2,-1) * self.head_dim**-0.5\n",
    "        a = a.masked_fill(self.tril==0, float('-inf'))\n",
    "        a = F.softmax(a, dim=-1)\n",
    "        a = self.dropout(a)\n",
    "        if verbose:\n",
    "            print(a.shape)\n",
    "            plt.imshow([[j.item() for j in i]for i in a[0]])\n",
    "\n",
    "        output = a @ v\n",
    "        return output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(head_size) for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, idx, verbose = False):\n",
    "        output =  torch.cat([head(idx, verbose) for head in self.heads], dim = -1)\n",
    "        output =  self.proj(output)\n",
    "        return self.dropout(output)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_heads):\n",
    "        super(Block, self).__init__()\n",
    "        self.mh_attn = MultiHeadAttention(n_heads, n_embd//n_heads)\n",
    "        #self.mh_attn = MoEMultiheadAttention(n_heads, n_embd//n_heads)\n",
    "        self.f_frwd = FeedFroward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mh_attn(x)\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.f_frwd(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class PunjabiAttentionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PunjabiAttentionModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(context_length, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads) for i in range(n_layers)])\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.linear = nn.Linear(n_embd, vocab_size)\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, idx, positions, labels=None, verbose = False):\n",
    "        if verbose:\n",
    "            print([decoder([i.item() for i in idx[0]])],'\\n')\n",
    "        idx = self.token_embedding(idx)\n",
    "        if not rope_embeddings:\n",
    "            pos_embed = self.position_embedding(positions)\n",
    "            idx += pos_embed\n",
    "        idx = self.blocks(idx)\n",
    "        logits = self.linear(idx)\n",
    "        \n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, S, E = logits.shape\n",
    "            logits = logits.reshape(B * S, E)\n",
    "            labels = labels.reshape(B*S)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, pos, max_seq_length, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _ = self(idx[:,-context_length:], pos)\n",
    "            logits = logits[:, -1, :]\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, -1)\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "        return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate_attn(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = {}\n",
    "    for split in ['train', 'eval']:\n",
    "        x, pos, y = get_batch_with_pos(split, batch_size, context_length)\n",
    "        _, loss = model(x, pos, y)\n",
    "        losses[split] = loss.item()\n",
    "    return losses\n",
    "\n",
    "\n",
    "model_attn = PunjabiAttentionModel()\n",
    "model_attn.to(device)\n",
    "optimizer_attn = torch.optim.AdamW(model_attn.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 4.776429653167725, eval_loss: 4.777175426483154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 501/5000 [01:29<25:50,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5461839437484741, eval_loss: 1.5966216325759888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1001/5000 [02:58<22:58,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.4050331115722656, eval_loss: 1.3915424346923828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1501/5000 [04:27<20:05,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.3361411094665527, eval_loss: 1.3208335638046265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2001/5000 [05:55<17:13,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.256089210510254, eval_loss: 1.2939963340759277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2501/5000 [07:24<14:22,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.2292159795761108, eval_loss: 1.2875800132751465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3001/5000 [08:52<11:29,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.2240582704544067, eval_loss: 1.2685086727142334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3501/5000 [10:21<08:37,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1578712463378906, eval_loss: 1.229555606842041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4001/5000 [11:50<05:44,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1746991872787476, eval_loss: 1.2010360956192017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4501/5000 [13:18<02:52,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1457452774047852, eval_loss: 1.2265880107879639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [14:46<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1577863693237305\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(max_iters)):\n",
    "    if i % eval_interval == 0:\n",
    "        losses = evaluate_attn(batch_size = eval_iters, model = model_attn)\n",
    "        print(f'train loss: {losses[\"train\"]}, eval_loss: {losses[\"eval\"]}')\n",
    "    x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "    _, loss = model_attn(x, pos, y)\n",
    "    optimizer_attn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_attn.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep have exceeded the time limit so the episode ends. This also indicated that you have to bootstrap the Q value estimate.\n",
      "terminated instead is when the agent have reached a terminal state, therefore the episode naturally ends. You should use both to under\n"
     ]
    }
   ],
   "source": [
    "x,y,pos = get_batch_with_pos('eval',1,context_length)\n",
    "context = decoder(i.item() for i in x[0])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ep have exceeded the time limit so the episode ends. This also indicated that you have to bootstrap the Q value estimate.\n",
      "terminated instead is when the agent have reached a terminal state, therefore the episode naturally ends. You should use both to under\n",
      "generation: stand, it performs matrix should found the complexity of capable input and one current input situation. This full create networks, although there, or it means when tackling the $\\mathbf{x}$ is the next state.\n",
      "The variation is the current static sequence is easily (if there a good update of note).\n",
      "The performance detected from the discussion (or current one layers is entirely). We use a descriptor of multiple stopping from $X + \\epsilon$ following&quot; (Some Visual will worried to the DQER. Inte\n"
     ]
    }
   ],
   "source": [
    "gen_len = 500\n",
    "output = model_attn.generate(x,pos, gen_len, True)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(context, model, gen_len):\n",
    "    pad = ''.join([' ' for i in range(context_length - len(context))])\n",
    "    padded_context = pad + context\n",
    "    x = torch.tensor([encoder(padded_context)], device = device)\n",
    "    pos = torch.arange(context_length).unsqueeze(0)\n",
    "    pos = pos.to(device)\n",
    "    output = model_attn.generate(x,pos, gen_len)\n",
    "    print(f'context: {context}\\n')\n",
    "    generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "    print(f'generation: {generation}')\n",
    "    return generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: How are you?\n",
      "\n",
      "generation: \n",
      "I need to person this varue the data \"I think you till the best way $b$, then you can evaluate weights with variance_ of the reward state $(th)$ outputs $R_t$ (training collection the odder.\n",
      "As Win, the hidden maybe considering the WInd1500% of something espective to we\n",
      "import answer, without waiting information problem.\n",
      "ERIOWK and REILU Postly DRone's recommendation for action-space entropywhich humans definitely impocal, I was moving for all, it doesn't really lie in the region of 0 degrees c\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('How are you?', model_attn, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Artificial intelligence and machine\n",
      "\n",
      "generation:  learning?\n",
      "P) to be the work (\n",
      " [cquest architecture) &quot;randomness &quot;takly&quot; embedding in\n",
      "from loop equations, if not what we define this ignoring the better q-first, tune for ask models based on the two image classify $[$p(s'|c||S,|s,a)$, and $\\epsilon$-greedy closed Rootlin Frameworks - users for sentence that is finite value functions (say keys real vappital) and policy on the index approximation power.\n",
      "This is that this point is contained Countropy when the same word images (in t\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('Artificial intelligence and machine', model_attn, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model/ai_model_5k_steps.pth'\n",
    "#torch.save(model_attn.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PunjabiAttentionModel(\n",
       "  (token_embedding): Embedding(104, 384)\n",
       "  (position_embedding): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=384, out_features=104, bias=True)\n",
       "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = PunjabiAttentionModel()\n",
    "model_loaded.load_state_dict(torch.load(path))\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: NLP, Large language models (LLM)\n",
      "\n",
      "generation:  into \n",
      "import $(L_\\ \n",
      "\\end{bmatrix}) = \\\\ su_{t = 1}{N} \\rightarrow \\mathbb{E}[n] + \\gamma^n X$ and $\\lambda\\in\\{q(1, \\ldots,s)$$│\n",
      "To percept, then containing representation of steeps different subcase and $j$ isn(perhapt $(Z|, 1)$). Once then $\\gamma$ denote the old in $N_j$ would be $D$ and $1$. However, if you could also differ from multiple paper, or $L$):\n",
      "$$V(s)$ the goal is module time, $\\epsilon$ that models are used to $r(s, a, 0)$ is a condition of $\\epsilon}$ then $\\gamma$ conceptube a \n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('NLP, Large language models (LLM)', model_loaded, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Transformer\n",
      "\n",
      "generation: , then the large negative would approximately carround by the visit function `aj = softmax(other loss) will help would we understand the ILL the question random, and when dontain keeping it will be used a convolution dangerous.. \n",
      "We timing an action step in a jown case you have an local reproductive complex from one of them would find this would call a time?\n",
      "Supervised learning return length, from _ ir) your response. That is a run, have manager can be more basic mechanically there it can over t\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('Transformer', model_loaded, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woohoo, the model has succefully learned to YAP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5000 [00:00<58:16,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1268360614776611, eval_loss: 1.1962356567382812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 501/5000 [01:29<25:49,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.122773289680481, eval_loss: 1.1756556034088135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1001/5000 [02:57<22:59,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1141284704208374, eval_loss: 1.1807650327682495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1501/5000 [04:26<20:05,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1075068712234497, eval_loss: 1.2118185758590698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2001/5000 [05:54<17:14,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0990971326828003, eval_loss: 1.1362547874450684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2501/5000 [07:23<14:21,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.08599853515625, eval_loss: 1.159732460975647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3001/5000 [08:51<11:29,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.080183744430542, eval_loss: 1.1591893434524536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3501/5000 [10:20<08:36,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.074751615524292, eval_loss: 1.1685752868652344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4001/5000 [11:49<05:44,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0700061321258545, eval_loss: 1.1723171472549438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4501/5000 [13:17<02:51,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0272647142410278, eval_loss: 1.1553329229354858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [14:45<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9859277009963989\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(max_iters)):\n",
    "    if i % eval_interval == 0:\n",
    "        losses = evaluate_attn(batch_size = eval_iters, model = model_attn)\n",
    "        print(f'train loss: {losses[\"train\"]}, eval_loss: {losses[\"eval\"]}')\n",
    "    x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "    _, loss = model_attn(x, pos, y)\n",
    "    optimizer_attn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_attn.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model/ai_model_10k_steps.pth'\n",
    "torch.save(model_attn.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PunjabiAttentionModel(\n",
       "  (token_embedding): Embedding(104, 384)\n",
       "  (position_embedding): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=384, out_features=104, bias=True)\n",
       "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = PunjabiAttentionModel()\n",
    "model_loaded.load_state_dict(torch.load(path))\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: AI and \n",
      "\n",
      "generation: it encountered it to predict AMA while an AI, which has N would still be a collection. Hence a perceptron correlation.\n",
      "These methods I understand and we compute the largest results that deep learning make sure that you think LSTMs to get explained by the words are memory. So, one appropriate network images that you want the problem. In theory, you also try and simpler speech-device the ratio of the 3 augmentation we are not 0, then can capturing the idea of 0.3; then linear function is the order\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('AI and ', model_loaded, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
