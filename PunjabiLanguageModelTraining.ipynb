{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "context_length = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 300\n",
    "n_embd = 384\n",
    "n_layers = 6\n",
    "dropout = 0.2\n",
    "n_heads = 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before cleaning: ੀ ਵੀਡੀਓਗ੍ਰਾਫ਼ੀ ਦੇ ਆਦੇਸ਼, ਚੋਣ ਕਮਿਸ਼ਨ ਨੂੰ ਨੋਟਿਸ ਕੌ ਾਸਲਰ ਦੀ ਚੋਣ ਲੜ ਰਹੇ ਭਾਜਪਾ ਆਗੂ ਢੋਟ ਨੂੰ ਹਾਈਕੋਰਟ ਨੇ ਦਿੱਤੀ ਸੁਰੱਖਿਆ\n",
      "ਅੰਮਿ੍ਤਸਰ, 15 ਦਸੰਬਰ (ਰੇਸ਼ਮ ਸਿੰਘ)- ਨਿਗਮ ਚੋਣਾਂ 'ਚ ਗੁੰਡਾ ਅਨਸਰਾਂ ਵਲੋਂ ਗੁੰਡਾਗਰਦੀ ਤੇ ਜਾਨ?ਮਾਲ ਦੇ ਖਦਸ਼ੇ ਨੂੰ ਲੈ ਕੇ ਹਾਈਕੋਰਟ ਦਾ ਕੁੰਡਾ ਖੜਕਾਉਣ ਵਾਲੇ ਭਾਜਪਾ ਆਗੂ ਤੇ ਨਿਗਮ ਚੋਣਾਂ 'ਚ ਅੰਮਿ੍ਤਸਰ ਦੀ ਵਾਰਡ ਨੰਬਰ 48 ਤੋਂ ਉਮੀਦਵਾਰ ਜਰਨੈਲ ਸਿੰਘ ਢੋਟ ਦੀ ...\n",
      "ਕੌ ਾਸਲਰ ਦੀ ਚੋਣ ਲੜ ਰਹੇ ਭਾਜਪਾ ਆਗੂ ਢੋਟ ਨੂੰ ਹਾਈਕੋਰਟ ਨੇ ਦਿੱਤੀ ਸੁਰੱਖਿਆ\n",
      "30 ਸਾਲਾਂ ਜਿੰਨਾ ਵਿਕਾਸ ਅੰਮਿ੍ਤਸਰ 'ਚ ਅਗਲੇ ਦੋ ਸਾਲਾਂ 'ਚ ਕਰਵਾ ਦਿਆਂਗੇ-ਸਿੱਧੂ\n",
      "ਮਾਨਾਂਵਾਲਾ, 15 ਦਸੰਬਰ (ਗੁਰਦੀਪ ਸਿੰਘ ਨਾਗ\n",
      "\n",
      "Data after cleaning: ੀ ਹਜ਼ਾਰਾ ਸਿੰਘ ਕ੍ਰਿਤ, ਡਾ ਬਲਬੀਰ ਸਿੰਘ ਸਾਹਿਤ ਕੇਂਦਰ, ਦੇਹਰਾਦੂਨ, ਪੰਜਾਬੀ ਯੂਨੀਵਰਸਿਟੀਘੋਰੰ ਸਰੋਤ  ਸ਼੍ਰੀ ਗੁਰੂ ਗ੍ਰੰਥ ਕੋਸ਼ ਸ਼੍ਰੀਮਹਿਤ ਪੰਡਿਤ ਗਿਆਨੀ ਹਜ਼ਾਰਾ ਸਿੰਘ ਕ੍ਰਿਤ, ਡਾ ਬਲਬੀਰ ਸਿੰਘ ਸਾਹਿਤ ਕੇਂਦਰ, ਦੇਹਰਾਦੂਨ, ਪੰਜਾਬੀ ਯੂਨੀਵਰਸਿਟੀਘੋਰ ਸਰੋਤ  ਸ਼੍ਰੀ ਗੁਰੂ ਗ੍ਰੰਥ ਕੋਸ਼ ਸ਼੍ਰੀਮਹਿਤ ਪੰਡਿਤ ਗਿਆਨੀ ਹਜ਼ਾਰਾ ਸਿੰਘ ਕ੍ਰਿਤ, ਡਾ ਬਲਬੀਰ ਸਿੰਘ ਸਾਹਿਤ ਕੇਂਦਰ, ਦੇਹਰਾਦੂਨ, ਪੰਜਾਬੀ ਯੂਨੀਵਰਸਿਟੀਸਰੋਤ  ਸ਼੍ਰੀ ਗੁਰੂ ਗ੍ਰੰਥ ਕੋਸ਼ ਸ਼੍ਰੀਮਹਿਤ ਪੰਡਿਤ ਗਿਆਨੀ ਹਜ਼ਾਰਾ ਸਿੰਘ ਕ੍ਰਿਤ, ਡਾ ਬਲਬੀਰ ਸਿੰਘ ਸਾਹਿਤ ਕੇਂਦਰ, ਦੇਹਰਾਦੂਨ, ਪੰਜਾਬੀ ਯੂਨੀਵਰਸਿਟੀ, ਹੁਣ ਤੱਕ ਵੇਖਿਆ ਗਿਆ  7177, ਪੰਜਾਬੀ ਪੀਡੀਆ ਤੇ ਪ੍ਰਕਾਸ਼ਤ ਮਿਤੀ  20\n",
      "\n",
      "vocab_size: 124\n",
      "unique_charcters:  ,0123456789?[।ਁਂਃ਄ਅਆਇਈਉਊ਌਍਎ਏਐਓਔਕਖਗਘਙਚਛਜਝਞਟਠਡਢਣਤਥਦਧਨ਩ਪਫਬਭਮਯਰਲਲ਼਴ਵਸ਼਷ਸਹ਼ਾਿੀੁੂ੃੄੆ੇੈੋੌ੍੎੏ੑ੒੖੗ਖ਼ਗ਼ਜ਼ੜ੝ਫ਼੠੡੢੤੥੦੧੨੩੪੫੬੭੮੯ੰੱੲੳੴੵ੿ંઅઆઇઈઉઋએ\n"
     ]
    }
   ],
   "source": [
    "def remove_non_punjabi_chars(text):\n",
    "    punjabi_chars = r\"[\\u0A01-\\u0A7F\\u0A80-\\u0A8F,।0-9? ]\"  # Gurmukhi range\n",
    "    english_chars = r\"[a-zA-Z]\"  # English alphabet range\n",
    "    return re.sub(r\"[^\" + punjabi_chars +\"|\"+ english_chars + \"]+\", \"\", text) \n",
    "\n",
    "# reading the punjabi corpus\n",
    "\n",
    "with open('data/pa.txt') as file:\n",
    "    punj_data = file.read()\n",
    "\n",
    "# cleaning the data\n",
    "data = remove_non_punjabi_chars(punj_data)\n",
    "\n",
    "# Looking at random example of data sample before and after cleaning\n",
    "ind = random.randint(0, len(data)-500)\n",
    "\n",
    "print(f'Data before cleaning: {punj_data[ind:ind+500]}\\n')\n",
    "print(f'Data after cleaning: {data[ind:ind+500]}\\n')\n",
    "\n",
    "\n",
    "# Getting the vocabulary of characters\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "print(f\"unique_charcters: {''.join(chars)}\")\n",
    "\n",
    "# Character encoding logic\n",
    "stoi = {char:i for i, char in enumerate(chars)}\n",
    "itos = {i:char for i, char in enumerate(chars)}\n",
    "encoder = lambda seq: [stoi[i] for i in seq]\n",
    "decoder = lambda encoding: ''.join([itos[i] for i in encoding])\n",
    "\n",
    "# Encoding the data\n",
    "data = torch.tensor(encoder(data), dtype=torch.long)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "train, test = data[:int(0.9*len(data))], data[int(0.9*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[60, 39, 71,  ..., 16,  0, 51],\n",
       "         [ 0, 67, 78,  ...,  0, 66, 68],\n",
       "         [20, 57,  0,  ..., 22,  0, 37],\n",
       "         [ 0, 49, 77,  ..., 59,  0, 49]], device='cuda:0'),\n",
       " tensor([[  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255]], device='cuda:0'),\n",
       " tensor([[ 39,  71,  47,  ...,   0,  51, 109],\n",
       "         [ 67,  78,   0,  ...,  66,  68,  69],\n",
       "         [ 57,   0,  20,  ...,   0,  37,  72],\n",
       "         [ 49,  77,  67,  ...,   0,  49,  69]], device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a sample batch from the data split\n",
    "def get_batch_with_pos(split, batch_size, context_length):\n",
    "    if split == 'train':\n",
    "        data = train\n",
    "    else:\n",
    "        data = test\n",
    "        \n",
    "    #getting random starting indices for the batch_size\n",
    "    start_indices = torch.randint(\n",
    "        len(data) - context_length - 1,\n",
    "        (batch_size,)\n",
    "    )\n",
    "    x_y = torch.stack([data[i:i+context_length+1]for i in start_indices], dim=0)\n",
    "    x, y = x_y[:,:-1], x_y[:,1:]    \n",
    "    pos = torch.arange(batch_size * context_length).reshape(batch_size, context_length) % context_length\n",
    "    x, pos, y = x.to(device), pos.to(device), y.to(device)\n",
    "    return x, pos, y\n",
    "\n",
    "x, pos, y = get_batch_with_pos('train', 4, context_length)\n",
    "x, pos, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFroward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super(FeedFroward, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd*4, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.query = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.key = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.value = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, embed, verbose=False):\n",
    "        q = self.query(embed)\n",
    "        k = self.key(embed)\n",
    "        v = self.value(embed)\n",
    "        a = q @ k.transpose(-2,-1) * self.head_dim**-0.5\n",
    "        a = a.masked_fill(self.tril==0, float('-inf'))\n",
    "        a = F.softmax(a, dim=-1)\n",
    "        a = self.dropout(a)\n",
    "        if verbose:\n",
    "            print(a.shape)\n",
    "            plt.imshow([[j.item() for j in i]for i in a[0]])\n",
    "\n",
    "        output = a @ v\n",
    "        return output\n",
    "            \n",
    "        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(head_size) for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, idx, verbose = False):\n",
    "        output =  torch.cat([head(idx, verbose) for head in self.heads], dim = -1)\n",
    "        output =  self.proj(output)\n",
    "        return self.dropout(output)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_heads):\n",
    "        super(Block, self).__init__()\n",
    "        self.mh_attn = MultiHeadAttention(n_heads, n_embd//n_heads)\n",
    "        self.f_frwd = FeedFroward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mh_attn(x)\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.f_frwd(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class PunjabiAttentionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PunjabiAttentionModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(context_length, n_embd)\n",
    "        # self.blocks = nn.Sequential(\n",
    "        #     Block(n_embd, num_heads),\n",
    "        #     Block(n_embd, num_heads),\n",
    "        #     Block(n_embd, num_heads),\n",
    "        #     nn.LayerNorm(n_embd)\n",
    "        # )\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads) for i in range(n_layers)])\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.linear = nn.Linear(n_embd, vocab_size)\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, idx, positions, labels=None, verbose = False):\n",
    "        if verbose:\n",
    "            print([decoder([i.item() for i in idx[0]])],'\\n')\n",
    "        pos_embed = self.position_embedding(positions)\n",
    "        idx = self.token_embedding(idx)\n",
    "        #idx = torch.cat((idx,pos_embed), dim=-1)\n",
    "        idx += pos_embed\n",
    "        #idx = self.lm_heads(idx, verbose)\n",
    "        #logits = self.attention(idx, verbose)\n",
    "        idx = self.blocks(idx)\n",
    "        logits = self.linear(idx)\n",
    "        \n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, S, E = logits.shape\n",
    "            #print(labels[0], logits[0])\n",
    "            logits = logits.reshape(B * S, E)\n",
    "            labels = labels.reshape(B*S)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, pos, max_seq_length, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _ = self(idx[:,-context_length:], pos)\n",
    "            logits = logits[:, -1, :]\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, -1)\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "        return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate_attn(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = {}\n",
    "    for split in ['train', 'eval']:\n",
    "        x, pos, y = get_batch_with_pos(split, batch_size, context_length)\n",
    "        _, loss = model(x, pos, y)\n",
    "        losses[split] = loss.item()\n",
    "    return losses\n",
    "\n",
    "\n",
    "model_attn = PunjabiAttentionModel()\n",
    "model_attn.to(device)\n",
    "optimizer_attn = torch.optim.AdamW(model_attn.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 4.851934909820557, eval_loss: 4.853891849517822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 500/5000 [03:27<31:01,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2.305018901824951, eval_loss: 2.280339241027832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1000/5000 [06:55<27:30,  2.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.8080925941467285, eval_loss: 1.8079828023910522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1500/5000 [10:23<24:05,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.6747100353240967, eval_loss: 1.6776657104492188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2000/5000 [13:50<20:37,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5360106229782104, eval_loss: 1.548059344291687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2500/5000 [17:18<17:11,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.4980789422988892, eval_loss: 1.511834979057312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3000/5000 [20:45<13:43,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.449927568435669, eval_loss: 1.4490400552749634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3500/5000 [24:12<10:16,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.4142448902130127, eval_loss: 1.4263538122177124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4000/5000 [27:39<06:51,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.387182354927063, eval_loss: 1.4133484363555908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4500/5000 [31:06<03:25,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.344664454460144, eval_loss: 1.4070125818252563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [34:33<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3498053550720215\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(max_iters)):\n",
    "    if i % eval_interval == 0:\n",
    "        losses = evaluate_attn(batch_size = eval_iters, model = model_attn)\n",
    "        print(f'train loss: {losses[\"train\"]}, eval_loss: {losses[\"eval\"]}')\n",
    "    x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "    _, loss = model_attn(x, pos, y)\n",
    "    optimizer_attn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_attn.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, pos, y = get_batch_with_pos('eval', batch_size, context_length)\n",
    "decoder([i.item() for i in x[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ਡਾਕਟਰਾਂ ਨੇ 5 ਦਿਨ ਦਾ ਆਰਾਮ ਦੱਸਿਆਪੰਜਾਬ ਵਿਧਾਨਸਭਾ ਚ ਹੋਏ ਇਹ ਚਾਰ ਬਿੱਲ ਪਾਸ, ਜਾਣੋਪੰਚਾਇਤੀ ਚੋਣਾਂ ਤੋਂ ਪਹਿਲਾਂ ਚੂਰਾ ਪੋਸਤ ਬਰਾਮਦ, ਦੋ ਜਾਣੇ ਫੜੇਪਾਕਿਸਾਨ ਦਾ ਕਾਲਾ ਤਿੱਤਰ ਸਿੱਧੂ ਲਈ ਬਣਿਆ ਵੱਡੀ ਮੁਸੀਬਤ, ਇਹ ਹੈ ਪੂਰਾ ਮਾਮਲਾਲਾਂਘੇ ਦਾ ਫ਼ੈਸਲਾ ਇਮਰਾਨ ਖ਼ਾਨ ਦਾ ਨਹੀਂ, ਪਾਕਿ ਆਰਮੀ ਦਾ ਹੈਸੀਐੱਮਸਰਕਾਰੀ ਬੁਲ'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder([i.item() for i in x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ਡਾਕਟਰਾਂ ਨੇ 5 ਦਿਨ ਦਾ ਆਰਾਮ ਦੱਸਿਆਪੰਜਾਬ ਵਿਧਾਨਸਭਾ ਚ ਹੋਏ ਇਹ ਚਾਰ ਬਿੱਲ ਪਾਸ, ਜਾਣੋਪੰਚਾਇਤੀ ਚੋਣਾਂ ਤੋਂ ਪਹਿਲਾਂ ਚੂਰਾ ਪੋਸਤ ਬਰਾਮਦ, ਦੋ ਜਾਣੇ ਫੜੇਪਾਕਿਸਾਨ ਦਾ ਕਾਲਾ ਤਿੱਤਰ ਸਿੱਧੂ ਲਈ ਬਣਿਆ ਵੱਡੀ ਮੁਸੀਬਤ, ਇਹ ਹੈ ਪੂਰਾ ਮਾਮਲਾਲਾਂਘੇ ਦਾ ਫ਼ੈਸਲਾ ਇਮਰਾਨ ਖ਼ਾਨ ਦਾ ਨਹੀਂ, ਪਾਕਿ ਆਰਮੀ ਦਾ ਹੈਸੀਐੱਮਸਰਕਾਰੀ ਬੁਲਾ ਕੇ ਤੁੱਕ ਵੱਖਰਾ ਹੈ ਸੋਸ਼ਦੇ ਦਾ ਪਰਿਵਾਰ ਅਹੁਦਾ ਉਚਾਰਨ ਉਚਾਰਨਦਾਤ ਤਾਂ ਵਿਚ ਮੈਂ ਘਰ ਦੇ ਹਰ ਅਮੀਰੀ ਤੇ ਫੜੇ ਜਾਂਦਾ ਹੈ। ਡੈਂਸ ਤੋਂ ਉਚਾਰਨ ਕੰਟਰੋਲ ਚਪਾਕਿ ਤੈਨੂੰ ਇਨਸਾਫ ਨਹੀਂ ਹੈ ਜੋ ਸੋਨੀਆਂ ਦੇ ਬੱਚਿਆਂ ਨੂੰ ਸਬੰਧ ਚੋਂ ਘਰੇਲੂ ਜੋ ਪੱਖਣਾ ਜਾਮ, ਹੇਠਲੀ ਮੈਨੂੰਫਿਰੀ ਚ ਘਰ ਦੀ ਕੇਸਗੜੀ ਦਾ ਕਹਿਣਾ ਹੋਇਆ ਮੁਫ਼ਤ ਫੜਨੀਅਮ ਚ ਬਿੱਲੂਆਂ ਫੜਦਾ ਹੈ, ਭਾਈ ਗੁਰਪ੍ਰੀਤ ਸਿੰਘ ਨੇ, ਖ਼ੁਰਾਕ ਕਥਾ ਤੇ ਓਥੇ ਆਏ ਜਾਂਦੇ ਹਨ, ਪਰ ਛਾਪੇ ਮਾਰਦੇ ਪੱਤੇ ਚਲੂ ਜਾਮ, ਸਾਡਾ ਧਰਮਿਕ ਛੱਲਾੲੀ ਗੋਲਾ ਚੰਗਾ ਲੰਬਾਉਣ ਜਾ ਰਹੇ ਹਨ ਅਤੇ ਪੁੱਤਰ ਦੇ 2 ਅੱਟ ਜਿੱਤ ਹੈ। ਈਮੇਲ ਨੂੰ ਹੁੰਦਾ ਹੈ, ਭੁਲਾਈ ਪਾਪੇ ਅੰਬੇਡਕਰ ਦੇ ਬੇਟੇ ਬੇਟੇ ਵੱਲ ਲਟਕਣ ਦੀ, ਘੱਗ ਜਾਂਦੀ ਹੈ, ਲੋਕਾਂ ਦੇ ਵੰਗ ਨੂੰ ਕਿਸਮ ਦੇ ਨਾਲ ਹੁੰਦਾਪਾਇਓ, ਸਾਰੇ ਪਰਮਾਣਦਾ ਹੈ, ਅਸੀਂ ਪੱਖ ਨਹੀਂ ਕਰਦੇ ਸਾਰੇ ਥਾਂ ਕਰਾਂਗੇ। ਪਾਪਾਂ ਦੇ ਅੰਧ ਚ ਆਏ, ਪਾਪ ਦੇ ਲੱਛਣ ਦਾ ਪੀਰਬਾਨ ਹਾਂ, ਪੰਜਾਮ ਚ ਗ਼ਾਹੀਨਾ ਕੈਨੇਡਾ ਦਾ ਵਧੀਆ ਪੋਰਨ ਵੀਡੀਓ  ਲਈ ਫੋਨ   ਮਦਦਕੁਸੀ ਸੋਹਣਾ ਚੁਕਾ  ਦਾ ਗੁੱਸਾ ਪੂਰਾ ਲੱਗ ਜਾ ਸਕਦਾ ਹੈ, ਮੰਨਦੀ ਹੈ, ਲਾਲ ਖੁਫੀਆਜੰਮੂਕਸ਼ਮੇ ਵਕਤ ਪਹੁੰਚਿਆ ਹੈ ਪ੍ਰਦਾਨਸੋਹਣਾ ਨੀ   ਕਰੀਏ ਵਾਰ ਨਹੀ ਸਾਲ ਘੁੰਘ ਹੈ ਸਾਲ ਦੀ ਉਸਜਪਾਨੀ ਨੀਤੀ ਨੂੰ  ਮਕੈਪਟਨ ਐਡਸਸਾਫ ਤਕਨੀਕ, ਦੁੱਖਅੰਮਿ੍ਤਸਰ, ਚਿਤਨਾ, 27 ਮਈ ਰਨੇਸ਼ ਪੋਸਟ ਬਿਊਰੋ, ਸੁਰਜੀਤ ਗੁਰਬ ਕਿੰਦਪਾਕੇ ਆਵਾਸ਼, ਸਾਮਿਲਨ ਦੇ ਆਉਲੇੁਟ ਹੈ ਨੀਤੀ ਨੂੰ ਖੇਤੀ ਦਰਹਿਆਵਾਂ ਅ\n"
     ]
    }
   ],
   "source": [
    "generation = model_attn.generate(x, pos, 1000)\n",
    "outputs = [decoder(i.tolist()) for i in generation]\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                                                        ਮਾਨੋ  ਸਾਡਾ  ਨੂੰ ਛੱਡ ਇਸ ਨੂੰ ਦੇ ਕਰਨਾ  ਸੋਚੋ ਸਧਾਰਨਾ ਕਮ     ਪੋਸਟ ਤੁਹਾਨੂੰ ਧੰਨਵਾਦ ਤੁਹਾਡੇ ਲਈ ਹੁੰਦੀ ਇਹ ਸੜਕ ਦਾ ਭਲਾ ਸ਼ਾਟ ਤੁਹਾਡੇ ਕਲਾਹ ਪਹਿਲਵਾਦ         ਪੋਰਨ ਵੀਡੀਓ ਜਰਮਨ  ਅਤੇ ਇਸ ਨੂੰ ਵੀਡੀਓ ਬਿਨਾ ਰਜਨ 25ੂੰ ਇੱਕ ਰਜਨ ਅਤੇ ਦੀ ਏਜੰਸੀ ਅਤੇ ਇੱਕ ਸੂਚੀ ਬਣਾਉਣ ਨੂੰ ਦੀ ਸਭ ਨੂੰ ਪਹਿਲਾ ਨੂੰ ਸਾਡੀ ਚੰਗੀ ਦਫਤਰ ਉਚਾਹਸੰਬੰਧ 22 ਵੀਡੀਓ ਦੇ ਸ਼ੁਰੂਆਤ ਛੱਡ ਦਲੇ੍ਹ ਬਾਲਾ ਰਜਿਸਟਰ ਅਤੇ ਵਾਤਾਵਰਣ [ਤੁਸੀਂ ਹੋਰ ਵਧੀਆ ਸੋਧੋ1 ਵੀਡੀਓ ਪੋਰਨ ਸ਼੍ਰੇਣੀ ਚੂਤ ਵਾਤਾਵਰਣ ਚੂਤ ਵੈੱਬਸਾਈਟ ਦੇ ਹੀਰਾ ਨਾਲ ਸ਼ਹੀਦ ਭਗਤ ਸਿੰਘ ਨੂੰ ਆਦਮਸ਼ ਬਿਹਤਰ ਨਾਲ ਕੁਝ ਵੀ ਸੋਚ ਰਿਹਾ ਹੈ, ਸਾਰੇ ਗੀਤ ਉੱਤੇ ਨਜ਼ਰਅੰਦਾਜ਼ ਸੂਤਰ ਨੂੰ ਹੋਰ ਵੀ ਦੱਸਣ ਅਤੇ ਲਾਪਤਾ ਦੀ ਉਤਪਸ਼੍ਰੇਧਾਰਮਿਲ ਕਰਨ ਲਈ ਇਸ ਨਾਲ ਦੀ ਕੁਲਤਵਿਨ ਨੂੰ ਲਾਪਤਾ  ਇਸ ਨੂੰ ਕਰਜ਼ ਤੋਂ ਬਾਅਦ ਉੱਤਰ ਛਪਾਓ  20 ਅਕਤੂਬਰ 1930 ਦੀ ਪੂਰਵਿੰਦਰ ਇਸ ਹੀਰਾ ਨੂੰ ਕਰਜ਼ ਕਰਦਾ ਰਲਵੀਰ ਸਿਸਟਮ  ਦਵਿੱਤ ਦੀ ਆਸ ਵਿਚ ਨਹੀਂ ਕੀਤੀਗਿੱਤਕਾਮਗਾਜ਼ੀ ਇਸ ਨੂੰ ਇਸ ਲਈ ਸਾਈਟ ਕਰਨ ਲਈ ਇੱਕ ਕਲਿੱਕ ਕਰਕੇ ਜਾ ਰਹੇ, ਇਸ ਨੂੰ ਡਾਊਨਲੋਡ ਕਰਨਾ ਕਿ ਤੁਹਾਨੂੰ ਕਿੰਡਿਟਪੁਆਇੰਗ ਅਤੇ ਉਸਦੀ ਹੀਰਾ ਗਰਨਾਡਰ ਤੁਹਾਡੇ ਕਹਿੰਦੇ ਹੋ ਬਹੁਤ ਪ੍ਰੇਰਣੂ ਬੂੰਜਿਆਂ ਦੀ ਅੰਬਨੀ ਵਾਹੁਣ ਹੈਂ?ਗਿੱਪੀ ਕੀਤੀ ਜਿਸ ਇੱਕ  ਗੁਲਾਮ ਅਤੇ ਸ਼ੈਲੀਵਿਚ ਸਮੂਹਾਂ ਦੁਆਰਾ ਨਿਰਧਾਰਤ ਕਰ ਸਕਦਾ ਹੈਰਾਹੁੰਦੇ ਹੋ ਕੇ ਲੈਗੇ  ਇਸ ਨੂੰ ਮਰਦਕੀ ਤੁਹਾਨੂੰ ਇਕ ਸਿੱਪਾ ਵਧੀਆ ਆਈਪੰਜਾਬ ਦੇ ਕਿੰਨਾ ਮੈਰੀਕਫ਼ਾਇਲ ਅਤੇ ਕਰਮਕੁੰਜ਼ ਸਿੰਘ            25  ਸਾਬਕਾ ਦ੍ਰਿੜ੍ਹ  ਸਾਡੀ  ਨੂੰ ਤੁਹਾਡੇ ਆਪਣੇ ਨਾਲਤੁਹਾਡੇ ਨੂੰ ਸਕੀਓ ਜਰਮਨ ਨਾਲ  12 ਫੁਸਾਫਟਹੈਡਬੈਕ  , 47 21 ਅਮਰੀਕਾ  25 ਸਾਲ ਏਅਰਡਪਬੈਕ     2009,      ਵਧੀਆ ਕੁੰਡ   ਕਿੰਮ   ਕੁਝ ਇਸ ਪੜਾਅ ਕਰਦਾ ਹੈਫੀਡਬੈਕ ਤੱਕ ਸਕੀਓ ਪੜਾਅ ਕਰਦਾ ਹੈ366  ਪੜਾਅ ਕਰਨਾ ਚਾਹੁੰਦਾ ਹੈ469     ਕਾਮਾਰ ਕਰਨ    ਤਸਦੀਕ, ਵਿਕੀਪੀਡੀਆ ਅਤੇ ਵਰਗ ਸੰਪਰਕ ਵਿਚ ਇਸ ਦੇ ਨਾਲ, ਇਕ ਪਰੰਪੈਕ   ਡਵੀਜ਼ਨ ਸਥਿਤੀ ਵਧ ਗਈ ਕਿੰਨਾਸ ਨੂੰ ਇਕ ਜੁੜੇ ਹੋਰ ਦਫਤਰ ਦੱਸਣਾ ਚਾਹੁੰਦਾ ਹੈ10  ਕੰਟਲ ਪ੍ਰਾਈਵੇਟ ਹੈ, ਜੇ ਇਕ ਲੜਕੀ ਦੇ ਸਮਰਥਨ ਹੀ ਬਣਕੇ ਚਾਹੁੰਦੇ ਹਨ   ਕਰੋ ਕੰਟਰੋਲ ਨੂੰ ਇਸ ਟੀਟ ਕੱਪਡੇਰੇ ਨਾਲ    ਕਿੰਸ਼ੂਟਮੋਟਰਡ ਹਿਤ ਸਥਿਤ ਧਰਮ ਭੇਜ ਸਕਣ ਕਰਨਹ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰਨ ਲਓ     ਬਰਫ਼ ਕਰਨ ਲਈ ਆਯਾਤ ਇਸ    ਕੌਮੀ ਯੂ ਨੇ ਕੀਤੇ ਖੂਟਿਆ ਨੂੰਸ੍ਰੀ ਗੁਰੂ ਗ੍ਰੰਥ ਖਾਣਪ ਖਾਣਪੀਣਪਾਕਿਸਤਾਨ ਦੀ ਮਹਿਲਾ ਅਤੇ ਸੁੰਦਰ ਬਰਫ਼ ਕਰੀ ਕੰਮ ਕਰਨ ਲੱਗਾ ਕਾਲਾ  ਟਵਿਟਿਕ ਪ੍ਰੋਪਤਾਸ਼ਨ ਵਜੋ ਕਿ ਟਵਿਟਿਕ ਵਿੱਚ ਬੋਨਸ ਓਪਰੇਸ਼ਨ ਡਰਾਈਵਰ ਦੇ ਮਹਰੀਕਸ਼ੇਤਰੀ ਆਈ ਕੰਪਿਊਟਰ ਸੰਯੁਕਤ ਪੱਤਰ ਭਰੀ ਡਰਾਈਵਰਕਾਈਪ ਕਰਨ ਲੱਗੇ ਪੈਕਿਆਂ ਦੇ ਆਪਸ ਵਿੱਚ ਖਾਂਦੇ ਹਨ ਕਿ ਈ ਵਿੱਚ ਐੱਪਲ ਮੁਲਾਫੇ ਇੱਕ ਕੰਤਰ ਨਨਿਊਜ਼ੀਲੈਂਡ ਸੰਯੁਕਤ ਰਾਸ਼ਟਰਪਤੀ ਡੋਨਚੂਬਿਟਰਜ਼ ਹਰਮਿੰਦਰ ਸਿੰਘ ਵਾਸੀ ਸਰਕਾਰੀ ਫੀਚਰ ਤੇ ਪਰਚਾ ਦਰਜਨ ਤੇ ਇੱਕ ਕੰਤਰ ਨੂੰ ਸੰਯੁਕਤ ਰਹੇ ਹਨ। ਐਟੂ ਚੈਕਿੰਗ ਦੀ ਪਹੁੰਚਣ ਲਈ ਜਲਦੀ ਮਾਰਨ ਦੀ ਕੋਸ਼ਿਸ਼ ਦਿੱਤੀ ਗਈ ਸੀ ਤੇ ਇੱਕ ਗੱਲ ਇੱਕ ਸੋਧ ਨਾਲ ਇੱਕ ਆਪਸ ਦੇ ਬਾਪਸ ਊਧਮੱਖਣ ਤੇ ਕਾਰ ਚਾਂਬਾ ਵਿੱਚ ਨਾ ਸਿੱਖ ਸਾਂਗਾ ਹੁਸੀ ਚੇਤਾਵਨੀ  ਭਾਓ ਬੰਗਾਲੀ ਵੀ ਇੱਕ ਗਿਰਫਟਕੁਰਾਇਆ11    ਗਿਰਫਟਕੁਰਾਲੀ ਦਿੱਲੀ ਨੂੰ ਪਪਪੰਜ ਕਰਮ ਕਰਨ ਲਈ ਇੱਕ ਚਿੱਟੇ ਤੇ ਕੰਮ ਕਰਨਗੇ। ਉਮਰ ਜਾਣ ਕਰਕੇ ਹੱਲੇ ਨਹੀਂ ਤਾਂ ਸਾਰੀਆਂ ਪਰਮਾਣੂ ਖਾਲਿਸਤਾਨ ਵਿਚ ਇਕੱਠੇ ਕਿਉਂ ਨਿੱਕੇ ਹੋਰ ਪ੍ਰਭਾਵ ਨਿਵਾਸਤ ਹੋਈ। ਨਿਊਜ਼ ਦੀ ਵਿਸ਼ੇਸ਼ ਹੋਈ ਕਟਕਰਾਰ ਨਾ ਹੋਈ ਹੈ। ਉਨ੍ਹਾਂ ਦਾ ਉਦਘਾਟਨ। ਇਸ ਚ ੈਟੀਨੈਟ ਲੁਰੇ ਚ ਇਕ 5 ਦਿਨਾਂ ਦੀ ਕਟਕਰਾਬ ਨਾ ਹੋਣ ਕਰਕੇ ਇਥੇ ਕੀਤੀ ਜਾ ਸਕਦੀ ਹੈ।ਜਿਵੇਂ ਤਾਂ ਇਸ ਮਾਮਲੇ ਨਹੀ ਹੁੰਦੀ , ਇਕ ਉਤਪਾਦ ਧੂਮ ਦੀ ਨਲਕ ਹੈ ਜਦੋਂ ਵੀ ਤੈਨੂੰ ਸਫਲ ਹੈ। ਤਾਂ ਠੰਡੀਕ ਹੋਈ ਹੋਵੇ ਤਾਂ ਬੀਜ ਨਹੀ ਪਰ ਜੇ ਕੁਰਬਾਨ ਹੋ ਸਕਦਾ ਹੈ ਸੇਵਾਵਾਂ ਦਾ ਕੋਈ ਸਵਾਲ ਕਰਦੇ ਹਨ ? ਤਾਂ ਬਚਦੇ ਪਾਲੀ ਦੇ ਬੁਖਾਰੀ ਹੋ ਸਕਦੇ ਹੋ, ਜਦਕਿ ਤੂੰ ਉਮਰ ਦੇ ਸਾਮੇ ਵਿੱਚ ਪਾਉਣਾ ਜ਼ਰੂਰ ਹੋਵੇ। ਜਿਸ ਕਾਰਣ ਹੈ ਕਿਤੇ ਬੁਖਾਰੀ ਨਾਲ ਪਰਮ ਪਿਆਰ ਦੀ ਕਲਪਨਾ ਲਈ  ਸਰਧਾ ਸਫਲਤ ਹੋੜ ਨਹੀ। ਤਾਰਪਿਆਂ ਦੀ ਵਰਤੋਂ ਹੀ ਆਪਣੇ ਘੱਟ ਤੋਂ ਵੱਧ ਸਫਲਤ ਹੋਈ ਹੈ। ਤੇਰੇ ਭਰਾ ਦੂਰੇ ਰੇਖਾ ਤੋਂ ਕਿਨੈਕਟਾਂ ਨਾਲ ਹੋਵੇ ਜਾਂ ਸੋਈਲ ਨਸੀਬਸ ਰਿਪੋਟਾਪ੍ਰਵਿਰ ਕਰਨ ਦੀ ਫਲ੍ਹ ਦਿੱਤੀ ਹੈ।[ਇਨ੍ਹਾਂ ਮਨੁੱਖਾਂ ਦਾ ਸਰੂਪ ਹੋਰ ਸਭ ਲਈ ਹੈ। ਐਸੇ ਤਰ੍ਹਾਂ ਲਗਕਾਰ।ਭੋਜਨ ਵਿੱਚ 27 ਸਾਲ ਏਅਰ ਸੰਦਰਭ ਸੁਭਾ ਵਿੱਚ ਜ਼ਰੂਰੀ ਹੋਵੇਗਾ। ਉਹ ਅੱਡੇ ਜਾਂ ਉਹ ਮੁੱਦੇ ਨੂੰ ਅੱਗੇ ਪਾ ਕੇ ਆਚੇ ਭੋਜਨ ਦਾ ਪਾਖੰਡੀਅਭ ਨੂੰ ਕਰਨ ਲਈ ਤਗਮਾ ਸੱਸਾਰ ਲੜਕ ਦਿੱਤਾ ਗਿਆ ।ਓ, ਹੀਲੰਦਾ ਤਾਂ ਕਿ ਐਸੇ ਵੀ ਸੰਪੂਰਨ, ਇਕ ਕੰਮਾਂ ਮੰਨਦਾ ਹੈ । ਇਸੇ ਲਈ ਦੇਖ ਦਿੱਤਾ ਕਿ ਉਹ ਕਿਸੇ ਹੋਰ ਦੋ ਪੁਣਲਾ 43ਕੁੱਝ ਜੰਤਰ ਹੋ ਜਿਹੇ ਹਾਲਤ ਨੂੰ ਯਕੀਨ ਕਰ ਰਹੀ ਸਲਾਹ ਮਾਮੂੰਹ ਆਦਿਕ ਪਿੰਡ ਕਿਸੇ ਜੰਤਰ ਦੇ ਪਾਣੀ ਦੀ ਸ਼ਰਣੀ ਗੱਲ ਕਰ ਲਓ ਧੰਨਵਾਦ। ਆਦਿਕ ਨੂੰ ਵੀ ਸਾਂਭ,ਕੀ ਅਵਤਾਰ ਮਿਲਣ ਦੀ ਯੋਗ ਹੋਵੇ, ਫੈਲੇ ਹਨ ਮੈਕਰੋ, ਟਿੱਪਣੀਆਂ ਦੇ ਘਰ ਦੇ ਤੁਹਾਡੇ ਦੇ ਵਿਚਕਾਰ ਸਲਾਹ ਲੈਂਗੇ ਹੋਏ ਉਸ ਦੇ ਮਸੀਹ ਮਾਮੂੰਹ ਬਣੇ ਰਹਿੰਦੇ ਹੋਏ?  ਲਈ ਗਾਲਚ ਕਰਨ ਕਰਨ ਲਈ ਕਿਹੜੇ ਮਜੀਠੀਆ ਹੁੰਦੇ ਹਨ ਹਰ ਰਿਹਾ ਹੈ ਚਾਹੁੰਦੇ ਹੋ ਕਿ ਇਹ ਟਿੱਪਣੀ ਹੋਈ, ਮੇੰਨ ਕਹ ਤੁਸੀ ਮਹਿਸੂਸ ਨੀਤਨ  ਵਿੱਚ, ਮਾਡੀਆਂ ਵਿੱਚ?ਨਾਟਕ ਸੋਹਣੀਓ, ਸੁਝੇ ਰੂਪ ਦੀ ਪ੍ਰਯੋਗ ਕਰਦੇ, ਹਸਪਤਾਲ ਮੇਨਿਆ ਕਰਮ ਹੁੰਦਾ ਹੈ ਇਕ ਡਾਊਨਲੋਡ,ਈਮੇਲ ,720089 ਰੁਪਏਪੁਰਾਣੀ ਧੰਨਵਾਦ,  ਰਾਹੁਲ ਖ਼ੇਤਰਫ਼ੌਰਮੀ ਮਸੀਹ ਅਤੇ ਹਿੰਸਾ ਦੇ ਸੇਵਕ ਹੁੰਦੇ ਹਨ, ਪਰ ਇਸ ਵਿੱਚ ਇਕ ਟਿੱਪਣੀ ਨੂੰ ਲੰਡਨ, ਜ਼ਿਆਦਾ ਹੀ ਏਗੁਰੂ ਕਲ ਸਿੱਖ ਸੈਕਸ ਅਤੇ ਗੁਰੂ ਏਜੰਸੀ ਨੂੰ   ਤੇ ਜਿਤਦਾ ਹੀ ਇਕ ਸਾਲ ਪੁਰਾਣਾਂ ਦੂਜੇ ਨੇ ਕਿਸਾਨਾਂ ਦੀ ਟਹਿਲ ਸਾਂਝਾ ਕਰ ਲਈ ਬਿਰਤੀ ਕਿਸਾਨਾਂ ਨੀ ਦੋ ਨੌਜਵਾਨਾਂ ਤੋਂ ਪਹਿਲਾਂ ਜਾ ਸਕੇਇਮੀਗ੍ਰੇਬ ਮਾਮਲੇ ਦਰਖਾ ਨਾਲ ਹੱਥੋਂ ਵੀ ਹੁੰਦੇ ਹੋਏ ਧਿਆਨ ਨੂੰ ਪਹਿਲ ਦੇ ਨੇਤੇ ਪਾਲਣੀ ਵਿਜ਼ੂਬੰਗਾਗਰੂਥ ਕੁਝ ਭਗਦੜ ਦੇ ਸ਼ੁਰੂਆਤੀ ਸ਼ੋਰੂਆਤੀ ਪੂਰਬ ਮੋਤੇ ਹਾਈਕੋਰਟ ਵੀਡੀਓ  ਪਰਮੀਸ਼ ਵਰਮਾ ਨੇਪਾਲਣ ਦੇ ਚਾਹਿ ਹੱਕੇ ਤਰੇ ਦਿਖਾਈ ਦਿੱਤੇ ਨਾਲਬਿਕਸ ਪ੍ਰਮੋਟਾਈ। ਪਰ ਸ਼ੈਕਰੋਤਾਜਂਮਸ਼ਹੂਰ ਵਿੱਚ ਰਹਿ ਰਹੇ ਹਨ ਸਤਿਕਾਰੀ ਸੀਜ਼ਨਿਰਦੇਹ ਦੇ ਅਮੈਰਾ ਕਰਕੇ ਅੱਗੇ ਕੰਢੇ ਉਆਹ ਹੋ ਜਾਂਦੇਕੀ ਨੇਪਾਲਣ ਉਸ ਦੇ ਹੱਤਿਆ ਸੋਨ ਰੂਪ ਆਨੰਦ ਦੀ ਖਿੜ ਦਿੱਤਾ। । ਗੱਲਚਾਈ ਕਰ ਕਿ ਅੱਗੇ ਕਰ ਦੁੱਖਦੂਤਾ ਨੇ ਨੇਪਰੇ ਬੀ ਐਸ ਸੋਨੀਆ 18 ਚੀਸਲਾ 31 ਨੰਦ ਮਰੇਜ਼ ਕਿ ਸਾਡੇ ਨਾਲ ਨਾਲ ਮਰੇਜ਼ਮਾਂ ਚ ਮਸ਼ਹੂਰ ਹੋਵੇ ਅਸਾਨ ਪਹੁੰਚੇ ਗੈਸ ਹੋਈ ਨੂੰ ਕੜਮੋਕਨਿਕਾਰੇ ਦੀਆਂ ਥਾਈਆਂ,ਮੋਟੇ ਚਲਿਆਂ ਜਾਂ ਵਿਸ਼ੇ ਤੇ ਮਾਰਨੀਕਾਮੇ ਦੇ ਪਾਵੇ।       15,        ਤੇ ਭਾਰੇ ਆਧੁਨਿਕ ਵਿੱਚ ਸਫਲਤਾ 34 5 ਲਿਸਫੇ 3 ਨਜਿੱਠੀ   20, 2015     ਦੇ ਪੁਰਾਣੇ ਵਧੇਰੇ ਵਿਦਿ  ਅਮਰੀਕਾ ਅਮਰੀਕਾਕੌਣ ਕੋਕੌਣ ਹੈਗੈਸ ਹਸਪਤਾਲ ਪੁਰਾਣੇ ਚ ਪੈਂਦੇ ਦੇਖੇ ਰਹਿਣ ਵਾਲਿਆਂ ਨੂੰ ਦਿੱਤ ਯਾਦ ਆਉਣ ਲਈ ਪ੍ਰਤੀਮੰਤਰੀ ਪੁਰਾਣੇ ਚੌਜਵੇਂ ਵਿਦਿਆਰਥੀ ਨੂੰ ਲਾੜਨ ਲਈ ਖ਼ਤਰਾ ਸੱਟਣ ਨੂੰ ਲਾੜ ਮੁੜ ਵਾਸਤਾ  ਅਮਰਿੰਦਰ ਸਿੰਘ ਫੂਲ ਕੋਲ ਹੋਲ ਹੈਆ। ਇੱਕ ਐਸਐਸਪੀ ਨੂੰ ਛਾਲ੍ਹਮੇਟ  ਸਪੱਲਕਧ ਐਸਾ ਉੱਤੇ  ਕੌਮੀ ਵੀ ਲਾੜ ਦੀ ਹੈਸੀ ਪੈਨਸ਼ਨਹਰੇਜ਼ ਤਰੀਕੇ ਨਾਲ ਐਸੀ ਨਾਲ ਤੇ ਗੱਲ ਕਰੀਬ ਕਰਦੇ ਸੀ। ਪਤਾ ਲੱਗੇ ਪਹਿਲਾਂਦੀਆਂ ਗੱਲਾਂ ਨਾਲ ਤੇ ਜੁੜੀਆਂ ਪੁੱਜ ਗਈਆਂ ਪੈਨਸ਼ਨ ਦੇ ਮੁਕਾਬਲੇ ਦੇ ਨਾਲ ਹੀ ਦੁਰਗਾ ਫੜੇ ਅਤੇ ਪੁੱਜ ਗਈਆਂ।ਸੁਹੇੜੇਤਾ, ਬੁਰੇ ਬੰਪਤ ਵਿੱਚ ਟੈਲੀਟੂ ਨਾ ਜੂਡਾਇਟ ਮਾਈਕਰੋਸਾਫਟਵੇਅਰ ਸੁਪਰਵਿੰਦਰ ਕੌਰ ਲਈ ਹੋਸ਼ਿਤ ਕਰਨਗੇ।ਸੁਪਰਵਾਏਅਰ ਸੁਣਵਾਈਅਰ ਸੁਝਾਅ, ਕਾਮੇਦਾਰ ਦਾ ਦਿਲ ਪਈ ਜਾਓ  ਤੇਰੇ ਦੇ ਹੈਰਾਮ ਪ੍ਰਸਤੇ ਅਰੰਭਿਆਨਾ ਥਾਂੲਸੁਪਰਵਾਈਅਰ ਸੁਰਤਿੰਦਰ ਕੌਰ ਦਾ ਦੁਰਗਾ ਜਿੱਤੀ ਦਾਸਕਣ ਲਈ  ਅਮਰੀਕਾ, 2, 29 ਜੁਲਾਈ ਤੇਰਾ ਦਿਲ ਪਿਤਾ ਲਾਡੀ ਮੰਚਪੁੱਤ ਤੇ ਹਮਲਾਦੇਸ਼ ਲਈ, ਉਹਨਾਂ ਕਿੱਥੇ ਭੋਗ ਪਾਉਣ ਲਈ ਇੱਕ ਦੀ ਵਸਤ ਹਨ ਜਦੋਂ ਚਾਰ ਕਰਨ ਕਰਕੇ, ਬਸ ਤੇ ਹਫ਼ਤੇ ਲਈ ਚੰਗਾ ਲਿਆ, ਉਸਨੇ ਮੜੇ  ਬਸ ਤੇ ਹੀ ਟਾਈਪ ਪੰਜਾਬੀ ਟੂਟ ਪੜਾਈਪ ਲਈ ਜ਼ਰੂਰਤੇ ਨੀਰਵ, ਬਰਨਾਲਾ, ਮੁਦਰਾ, ਸੰਤੁਸੀਬੀਚੰਡੀਗੜ੍ਹ, ਗਰਲਜਖੇ ਦੀ ਵੈਲਥ ਚਮੜੇ ਦੇ ਪੁੱਤਰ ਅੰਦਾਜ਼ਾ ਖੁਲਾਸੇ ਹੋਏ ਸਨਕੀਬਾਂ ਦੇ ਜਰਨੈਲ ਸੂਬਿਆ ਦੇ ਸਿਫਾਰਸ਼ ਚ ਵੀਚੰਡੀਗੜ੍ਹ  ਭਲਕੇ ਖਾਲੀ ਪਛਾਣੇ, ਨਹਿਰੂ ਦੀਵਾਲੀ ਨੇ ਪਾਈ 55 ਵਜੇ ਬਹੁਤੇ ਕੁਝ ਪੁੱਤ ਦੀ ਪਾਬੰਦੀ ਨਹੀ ਸਿਰਫ, ਕਪੂਰਥਲ, ਬੀਬੀ ਜਗੀਰ ਲਈ ਅੰਦਾਜ਼ ਨਸ਼ਾ ਲਾਉਣ ਹੈ।ਕਪੂਰਥਲਾ, ਫੇਅਰੀਅਲ ਆਫ਼ ਰਓਡਾ ਅੰਬਰਰਾਊਡਾ ਅੰਬਰ ਵਿਖੇ ਜਗਮਾਇਆ ਕੂਕੇ ਪੀ ਹੋਇਆ ਸੀ ਤਾਂ ਔਰਤ ਦਫਤਰ ਔਲਫਾ ਦੇ ਦੇਣ ਹੋਣ ਵਾਲਾ ਕਪੂਰਥਲਾ ਰੱਖਣ ਪਿੰਕੀ ਪੁੱਤਲ ਨਹੀਂ, 25 ਸਤੰਬਰ ਸਰਬਜੀਤ ਬਿਰੋਧੀਧੀ ਗਿਰਸ ਪਾਤ ਕੀਤੀਰੋਧੀਜੂਨ 18, 2016 2 ਅਨਾਰਾ ਸਾਲਮਾਨ ਬਲਾਕ ਕਪੂਰਥਲਾ ਨੇੜੇ ਪੰਜਾਬ ਦੀਆਂ ਵਿਰੁੱਧਾ ਡੋਰ ਪਿੰਕੀ ਦੀ ਮੌਤਰੋਧੀ ਕਾਬੂਨਵੇਂ ਕਪੂਰਥਲਾ ਤੇ ਲੋਕ ਭੌਤਿਕ ਦੀ ਅਣਦੇਖੀ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਮੋਦੀਯੂਰੋਪਿੰਗ ਦੇ ਸੀ ਫੋਟੋ ਪੂਰਾ 29 ਸਭਿਆਚਾਰਵਕ ਪ੍ਰੋਪਾਰਟੀ ਨੇ ਸਿੱਖਾਂ ਦੀ ਇਕ ਡੋਪ ਟੈਸਟ ਕੀਤੀ ਹੈ  ਜੋ ਤੁਹਾਨੂੰ ਮਹੱਤਵਪੂਰਨਹਾਰਾ ਪੂਰਾ ਜੈਪਟਨ, 23 ਸਤੰਬਰ ਸਧਰਮ ਤੋਂ ਪਹਿਲਾਂ ਫਾਟਕਦਾਰੀ ਵਾਸੀ ਜਬਰਗ ਅਜਾਇਬਤਪੂਰਨ ਵਿਕਸਤ ਪੂਰਨ ਵੀ ਹੈ ਕਿਉਂਕਿ ਇਤਰਾਜ਼ਤ ਉਤਰੀਬਦਲ ਸਭ ਕੁੱਤੇ ਮਾਮਲੇ ਦੀ ਲੁਟੇਗੀ ਮਾਮਲੇ ਚ ਬੈਠੇ ਇੱਛੇ ਮੰਦਰ ਨੇੜੇ ਵਾਸੀ ਵਾਸੀ ਹੈ ਅਤੇ ਆਗੂ ਵਿੱਚ ਤੁਸੀਂ ਕੀਤੀ ਇਤਰਾਜ਼ਤ ਦੀ ਕੁੱਤਰਤਿੋ। ਇਸ ਮਨੁੱਖ ਹੈ ਕਿਸੇ ਵੀ ਕੁੱਤੇਬੀ ਲੁਟੇਗਾ ਜੋਰਦਾਰ ਸਾਹਮਣੇ ਆਇਆ ਹੈ ਕਿ ਮਟਰੱਲ ਵਿੱਚ ਹੁਣ ਕਈ ਵਾਰ ਘਰ, ਸਾਹਮਣੇ ਲੁਟੇਗਾ 53 ਦੇ ਪਹਾੜਾਂ ਪੈਂਦੇ ਪਾਪੀ ਦੇ ਕੇ ਲੈਂਡਲ, 3 ਦੀਗਲ ਨਾਲ ਚੇਤਰੇਨਿਊ ਸਹਾਲ ਕਰਦੀਪਿਸੇ ਤਰਾਂ ਵਾਂਝੀ ਕਰ ਰਹੀ ਹੈ। ਜੋ ਅਸੀਂ ਜਾਂ ਕੀਤੀਆ ਕੁਲ ਜਾਏ। ਇਸ ਪਿਸੇਗਾ ਨਾਲ ਉਸ ਤਰ੍ਹਾਂ ਤਾਂ ਉਹ ਤਾਂ ਨਹੀਂ ਜਿਆਦਾ ਉਹ ਪਿਛੁੜੇਰਾ ਗੱਲਾਂ ਹੀ ਉਹ ਫੁਰਮਾਉਂਦੀ ਤਾਦਨਾ ਜੀ। ਫਰ ਇਹ ਅਹਾਰਾਂ ਦੀ ਸੜਕ ਤਾਂ ਉਹ ਕਿ਼ਲਦੋਂ ਮੁੱਕਣੀ ਭੀ ਸਚਾਇਆ। ਨਾ ਕਦੀ ਹੈ ਜਸ ਚ ਹਾਲੇ ਇੱਕ ਤੁਹਾਡੀ ਨੁਕਸ ਵਰਤਿਆ ਜਾਂਦੇ। ਸੁਖ ਦਾ ਮੁੱਕਦਾ ਹੈ।ਆਮ ਆਦਮੀ ਸ਼ਾਇਰੰਜ ਵੀ ਤੁਰ ਜਾਂਦੀ ਹੈ ੪੨ ਗਡਾਉਂਦਾ ਹੈ ੧ਪਿਛੁ ਦੂਰਪੋਜੈਨ ਦੀ ਉਸਾਰੇ, ਖੇਤਾਂ ਵੀ ਵਿਚੋਂ ਤੁਰ ਟਿੱਤਾ ਹੋਇਆ ਗਿਆ। ਮੈਂ ਬਲਦਾ ਸੋਝੀਂਦਾ ਹਾਂ।ਕਿ ਗਤਾ ਗਬਾਦਲ ਲਿਆਉਣ ਲਈ ਉਸ ਨੂੰ ਪ੍ਰਾਪਤ ਕਰਦਾ ਸੀ ਕਿ ਹੁਣ ਤੁਰ ਟਿੱਕੀ ਜਾਂਦਾ ਹੈ। ਉਹ ਤੁਹਾਡੇ ਗੇੜੇ, ਦਿਉ, ਇਹ ਹਵੇਂ ਕਰਕੇ ਕੁਝ ਕਹਾਂਗੇ ਤੁਸੀ ਮਹਤਾ ਅਤੇ ਉਸ ਪੁੱਤਰ ਤੋਂ ਦੁਖਾਂਗੇ ।ਐਂਟੀਉਸ ਨੂੰ ਮਾਨਣਾ, ਇਉਂ ਕਾਰ ਸਾਰਾ ਲੈਣ ਦੀ ਸਹੁੰ ਚੁੰਨ ਕੇ? ਚਪਿਆ ਹੋਣ ਨੂੰ, ਆਉਟ ਲੱਗੇ ਅਮਲਾ ।ਕਰ ਧਮਾਕੇ । ਹੋਰ ਪੁੱਤੇ ਵੀ ਆਦਿ ਹੀ ਪੈਰੋਕਾਲੋਨੀਆ ਅਤੇ ਪਾ ਕੇ ਦੁਰਗਾ ਸਮੂੰਹ ਰੂਪ ਤੋਂ ਬਚ ਕੇ  ਅਤੇ ਮਾਂਬੋਝ ਦੇ ਪੱਖ ਚਾਲ ਸਾਰਾ ਪ੍ਰਾਪਤ ਹੁੰਦੀ ਹੈ । ਕਰਦੀ ਤੋਂ ਬੇਨਤੀ ਕੀਤੀ ।੪ ਨੇ, ਇਸ ਤ੍ਰੀਏ ਤਾਰੇ ਤੇ ਹੀ ਸਿਰਫ਼ ਸਮਝ ਪੈਂਦੀ ਹੈ ।ਗੱਲਬਾਤ ਨੂੰ ਤੱਕ, ਤੁਹਾਨੂੰ ਪਰ ਕਿਉਂਕਿ ਉਹ ਭਟਕ ਗਿਆ ਸੀ।ਕੱਪੜੇ ਦੁਰਗਾ ਸਾਹਮਣੇ ਹਿਰਦੀ ਅਤੇ ਗਰੀਬੋਂਡ ਦੇਸ਼ ਨੂੰ ਜੋ ਇੱਕ ਵੱਡੀ ਦਾਤਾ ਵਧਣਖਾਲਸਰ ਪਾਸ ਕੇਹੜੀ ਨੇਵਭਸ਼ਾ ਬੋਲਬਾਲ ਇੱਕ ਵਿਸ਼ਾਤਾਵਾਚਰਨ ਦੀ ਲਿਖ ਮੇਰੀ ਨੋਟਾਂ ਨੂੰ ਅਜੇ ਵੀ ਵਧਆਉਣਾ ਨਹੀਂ ਮੈਨੂੰ, ਪੇਜ ਵਧਾ ਕੇ  ਪਰ ਗਿਆ  ਸੁੰਦਰ ਇੱਕ ਵਿਸਹਾਰ ਨੂੰ ਇੱਕ ਵਿਆਕਤਾ ਦੀ ਦਾਤਰ ਬਾਲ ਰੈਲੀ ਵਧਾ ਦੇਣ ਰਹੇ ਹਨ, ਦੇਖ ਰਹੇ ਹਨ, ਮੈਨੂੰ, ਸਮਾਨਤਾ ਬਣਾਉਣਾ ਹੀ ਤੁਹਾਡੇ ਇਸਤੇਮਾਲ ਦੀ ਤੁਲਨਾ ਦੀ ਸੂਿਆਸ ਹਰ ਚੀਜ਼ਾਂ ਨੂੰ ਰਹੇਗੀ, ਮੈਨੂੰ, , ਹੇ ਠੀਕ ਗਿਰਾਫਟ ਨਾਟਾਊਸ ,  ਅਫਰੀਕਾ ਦੇ ਮੋਸਟੇਟ ਬਾਲ ਵਾਲੇ ਵੱਧ ਰਹੇਗਾ। ਨਿਈ ਬੁਰੀ ਤਰ੍ਹਾਂ ਚੀਜ਼ਾਂ ਦੀ ਤੁਲਨਾ ਦਿਲ ਚੁੱਕੇ , ਕਰੀਬ ਜਾ , ਜਿਸ ਪਲੇਟ ਬਗਾਵਰ, ਚੁੱਕੇ ਤੇ , ਧਰਮ ਕੋਲੋਂ, ਤੁਹਾਨੂੰ ਵਧ ਸਕਦੇ ਹੈ, ਜਿਨ੍ਹਾਂ ਚ ਇੱਕ ਸਥਿਤ ਹੈ, ਇੱਕ ਖਤਰਨਾ ਨਿਸ਼ਾਨ ਨੂੰ ਸੌਦਾ ਪਹਿਲਾਂ ਚੁੱਕੇ ਹਨ।  ਤੁਹਾਡੇ ਪੈਰਬ ਦਾ ਝੱਕਾ ਹੈ, ਇੱਕ ਛਾਪੇ ਗਵਰਹਿਣ ਕਰਦਾ ਅਤੇ ਸਹਿਜ, ਗਾਂਧੀਨ ਸਿੰਧਟ ਤੇ, ਇਹ ਮੇਰੇ ਇਕ ਲਈ ਉਪਦੇਸ਼ ਕਰਨਾ ਚਾਹੁੰਦੇ ਹੋ ਤੁਹਾਡੇ ਲਈ ਮੈਂ ਲੋਕ ਨੰਬਰ ਵੀ ਨਹੀਂ ਫੋਢੋਨੈੱਟਵਰਕ ਇੱਕ ਬਿਜਲਾਈ, ਹੋਟਲਦਾਰ ਹੈ, ਤੁਝ ਨਾਂਤਕ ਤੌਰ ਟਲਰ ਬਲ ਹੋਟਲਦਾਰ ਹੈ ਤੁਹਾਨੂੰ ਵਿਗਿਆਪਨ  ਹੋਟਲ ਹੋ ਗਿਆ ਹੈ ਤੁਹਾਡਾ ਮੁੱਖ  ਡਿਜ਼ਾਇਨ ਅਤੇ ਲਗਭਗ ਈਮੇਲ  ਜ ਸਰੀਰ ਗਿਪਹੁੰਚਿਆ ਗਿਫਤਾਰਮਿਰਸੁ  ਸਟਾਫ ਬ੍ਰਿਜਲੀਜ਼ ਮੁਫ਼ਤ ਹੈ ਪੂਰੀ ਖ਼ਤਮ ਹੈਇਕ ਸਟਾਫ ਦੀ ਸਮੁੱਚੇ ਸਟਾਫ ਦੇ ਮੁਫ਼ਤ ਹੈਲੀਕਾਪਟਰੂਡੋ 1ਹੋਟਲ ਵਿੱਚ  ਹੈਮੁਫ਼ਤ ਹੈਮੁਫ਼ਤ ਵਿਗਿਆਪਨ ਦੇਖਣ ਲਈ ਤੁਹਾਡਾ ਹੈਲੀਕਾਪਟਰੂਡੋ, ਹੈੱਡਕਾਪਟਰੂਡੋਗੋਸਕੂਲੀਬਿਊਰੋ ਪਾਰਟੀ ਸਪੇਨੀਵਰਸ਼ਾਂਤੀ  ਈਕੋ ਵੇਕ ਖੁਆਸ ਵਿੱਚ ਹੈਲੀਕਾਪਟਰੂਡੋ ਦੇ ਤਰੂਸ਼ੀਰ ਹੈਕਾਪਟਰਿਕਸ ਕੰਟਰੋਲ ਪ੍ਰੈਸ ਅੱਪਡੇਟ ਕਾਪਟਰੰਡੋ ਦੇਖਣ ਦੇ ਸਮਰਥਨ ਨਿਰਮਾਣ ਵਿੱਚ ਕੌਮੀ ਫ਼ਦੂਰਿਸ਼ ਜਾਰੀ ਹੈ, ਨੂੰ ਸੌਰੇਗਾਪੀਅਨ ਮੁੱਕ ਦੇਖਣ ਲਈ ਤੁਸੀਂ ਸਵੈਵੈਜ ਕਰਨ ਦੇ ਸਾਜ਼  ਪੋਰਨ ਵੀਡੀਓ188  ਪੌਰਨ ਸਿਰਫਫੀਕ ਤੁਰੰਪੂਰਵਤ ਪੋਰਨ ਵੀਡੀਓ1981 ਮੁਫ਼ਤ ਪੋਰਨ ਵੀਡੀਓ ਤੁਹਾਡੇ ਛੋਟੇ ਚੂਚੇ ਹਨ ਗ ਸੈਕਸ ਦੇਖਣ ਲਈ ਵੇਖਣ ਲਈ ਪੋਰਨ ਵੀਡੀਓ  ਪੁਲਿਸ  2118 ਹਿਰਕਵ ਖਾਨ ਤੁਹਾਡੇ ਲਈ ਇੱਥੇ ਕੀ ਹੈ ਹੁਣੇ ਤੁਹਾਡੇ ਲਈ, ਸੰਦੇਸ਼ ਜਾ ਸਕਦੇ ਹਨ, ਚਾਹੇ ਮੰਮੀਜ਼ ਹੁੰਦੇ ਹਨ, ਸਾਈਪ੍ਰਸੀਝ ਨੂੰ ਪੋਰਨ ਵੀਡੀਓ ਸਟੋਕਿਨ     ਪੌਰਨ ਵੀਡੀਓ3808 ਸਕੋਰ , ਤੱਕ ਸਾਈਟ , ਸਮੱਗਰੀ ਮਹਿੰਗੇ ਪੋਰਨ ਜ਼ੁਬਾਨੀ ਸੁੰਦਰ , ਪੰਜਾਬੀ ਸੁੰਦਰ ਇੱਕ ਮਾਮਲ ਕਜ਼ਰੂਰ ਦੱਤ ਦਿਨ, ਇਹ ਜੀਟੀਏ ਨੂੰ ਕੋਕਾਪੀ ਹੈ ਮੁਫ਼ਤ ਹੈਕ,  ਨੂੰ ਹੈ, ਜੋ ਕਿ ਖਤਰਾ ਫੂਡ ਕਾਮੋਕੇਸ਼ਨ ਕਲਾਮਾ ਸੈਕਸ ਵਾਸੀਆਂ ਨੇ ਵੀ ਖਤਰਾ ਨੂੰ ਸਵੂਚੀ ਵਿਚ ਤੁਹਾਡਾ ਪਤਾ ਮੈਨੂੰ ਪੜ੍ਹ ਦਿੱਤਾ ਹੈ, ਜਿਸ ਨਾਲ ਇੱਕ ਕੋਪੀ ਧਰਮੀ ਦੇਖਣਾ ਭਾਈਚਾਰੂ ਹੁੰਦੀ ਨੀ ਹੈ, ਦੇ ਪਤੀ ਨਾਲ ਪ੍ਰੇਰਣ ਕਰਨ ਲਈ ਧਿਆਨ ਪ੍ਰਾਪਤ ਕਰਨ ਲਈ, ਸੰਕਲਨ ਆਦਿ ਕਾਮਲ ਹੁੰਦਾ ਹੈ ਅਤੇ ਨੀਲਾ ਕਲਾਮ  ਤੱਕ ਸੌਦਾ ਦੀ ਦੀ ਜੜ੍ਹ ਮਾਤਾ ਪਾਲੇ ਨੂੰ ਸਾਰਾ ਪਾਸ ਮ ਸਿਗਰੇਅ ਹੁੰਦਾ ਹੈ ਕੀਤਾ  ਖਾਤਾਸੇ ਹੁੰਦਾ ਹੈ ਕਪੂਰ ਤੱਕ ਦਾ ਚੰਗਾ ਲੰਗਰ ਵਿਚ ਵਾਰਪੇ ਤਸਵੀਰ ਸੁਣਨ, ਸੀਈਓ ਜੋ ਕਿ ਬਾਅਦ ਸੁਣਨ ਦੀ ਦੇਖਵਾਈ ਵਾਲੇ ਨਾਲ ਪਾਲੇ ਵਿਚ ਇਕ ਧੰਨਵਾਦ ਸਾਲ ਸੀ 3 ਬਾਲੀਵੁੱਡ ਦੇ ਇਲਾਕੇ ਨੂੰ ਸਾਹਮਣੇਮੈਤਿਕ ਹੁੰਦਾ ਹੈ ਹੈ ਸਾਰੇ ਬੇਨਤੀ ਕਰਨ ਲਈਛਪਕਰਾ ਸਾਲ ਸੀ ਸਾਰੇ ਨੂੰ ਖਾਸ ਅੱਗ ਭੈਣ ਕਹਿਣ ਦੀ ਬਚਾਉਗਾਹੁੰਦਾ ਹੈ ਹੀ,ਮੈਕ ਕਾਲਨ ਚਾਹੁੰਦਾ ਹੈ, ਪਰ ਤੂੰ ਰੱਜ, ਤੂੰ ਗਾਹਡਾ ਇਵਾਨ ਰੂਪ ਹੈਹੁੰਦਾ ਹੈਹੰਕਾਰਪੁਰ ਵਿਛੜ  ਉੱਤੇ ਬੋਲਦਾ ਹੈ, ਅਤੇ ਵਿਕਲਪ ਹੈਇੱਕ ਦੂਜੇ ਨੂੰ ਤੇ 1  ਅਤੇ ਕਪਿਉਸ਼ੈਦਗੀ ਭਰਸਾਂਦਾ ਹੈ,, ਤੂੰ ਲੀਨ ਹੁੰਦਾ ਹੈ ਆਸੈਕਸ ੧ਏ ਜੋ ਗਵਰਨ ਉਤੇ ਮੂਕਤੀ ਬਣਾਉਂਦੇ ਹਨਇਹ ਟਰੋਡ ਬਾਰੇ ਬੁੱਲ੍ਹਿਆ ਹੋਇਆ ਸੋਚ ਬੁੱਲ੍ਹੋ ਅਤੇ ਹੋਟਲਕਸ ਲੈਫਟੀਨੈਟ ਇੱਕੋ ਗੱਲ ਇਲਥਜ਼ੇ ਲਈ ਤਰ੍ਹਾਂ ਹਨ ਗਰਭ ਮੈਨੇਜਰੀ ਮਹਿਲਾਨ ਹੈ ਏ, ਬੱਸ ਸਿਲ੍ਹਿਆਭਲਾਣਾ ਵਿਚ ਅਥਰਟਪੁਲ ਜੜ੍ਹਾਂ ਨੂੰ ਹੱਕ ਸੋਚਣਾ ਲੱਗ ਜਾਵੇਗਾ ਭਲੇ ਹਨਨਵੇਂ ਪਬਲੀਸੁਟ ਦੇ ਦੋਸ਼ੀਆਂ ਤੋਂ ਬਣ'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emcoder('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model/punjabi_lm.pth'\n",
    "torch.save(model_attn.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PunjabiAttentionModel(\n",
       "  (token_embedding): Embedding(124, 384)\n",
       "  (position_embedding): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=384, out_features=124, bias=True)\n",
       "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = PunjabiAttentionModel()\n",
    "model_loaded.load_state_dict(torch.load(path))\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256]), torch.Size([1, 256]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ'\n",
    "pad = ''.join([' ' for i in range(context_length - len(context))])\n",
    "padded_context = pad + context\n",
    "x = torch.tensor([encoder(padded_context)], device = device)\n",
    "pos = torch.arange(context_length).unsqueeze(0)\n",
    "pos = pos.to(device)\n",
    "x.shape,pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ\n",
      "generation:  ਇਟਲੀ ਖੇਤਰ ਨੂੰ ਘਰ ਤੇ ਜਾਨਾ ਦੇ ਚੁੱਕਾ  ਨੂੰ ਭਲਾ ਨਿ ਕਰਦੀ ਹੈ          500   ਤੇ   ਬੁਰੀ ਤੋ  ਭੋਜਣ ਨੂੰ ਮਹੱਤਿਆ ਫੇਰੇਇਟਲੀ ਵਿੱਚ   ਹੀ ਵੇਖਵੰਤ ਦਰਮੇਸ਼ਨਜ਼ ਚ ਸਭ ਤੁਹਾਡੇ ਚੰਗੇ ਲਗਵਾਓ। ਫੈਬਰੇਟਮੈਟਿਲੀ ਵੇਪਰਜ਼ਿਟ ਹੈ  ਇੱਥੇ ਜੋ ਕਿ ਕਲੀਟਮ ੋਰਾਈਕਾਰ ਹਨ  ਤਿੰਨ ਸੌ ਦੀ ਸਿੱਖ ਸਕੂਲ ਪੋਰਨ ਸੈਕਸ ਕਸੈਕਸ ਬਣਾਉਣ ਦੀ ਲੋੜ ਤੇ ਹੈ।ਗੱਲਬਾਤਹ ਤੋਂ ਅਸਾਮੀ ਵਿਚ ਸਾਵਧਾਨੀ ਅਜਿਹੇ ਵਿਦਿਅਕਤੀ ਵਿਅਕਤੀ ਨੂੰ ਨਸਲ ਮੁਫ਼ਤ ਸੈਕਸ ਤੇ ਚੱਲਣ ਦਾ ਫੈਸ਼ਨ ਕਰਨ ਦਾ ਧੰਦਾ ਹੈ। ਤੁਹਾਨੂੰ ਸਭ ਤੋਂ ਵੱਧ ਉਪਰ ਅਮੈਟਿਕ ਸ਼ਬਦਕੋਈ ਇੱਕ ਪੁੱਤ ਦਾ ਲਾਭ ਲੈਣ ਸੰਦਾਂ ਚ ਮਹਿਸੂਸ ਕੀਤੇ ਗਏ ਹਾਂ ਘਾਤਕ ਨੂੰ ਨਾ ਚਕੱਕਾਰ ਦੂਰ ਕਰਦੇ ਹਨ। ਜਿਨ੍ਹਾਂ ਵਿਚੋਂ ਇਕ ਸਭ ਉਗਾਲਤ ਕੁਝ ਕੀਤੇ ਜਾਂਦੀ ਹੈ ਛੱਡੀਂ। ਇਸ ਨੂੰ ਜਦੋਂ ਘੁਲੋਂ ਘੇਰਾ੍ਣਾ ਲਿਖਾਰੀ ਸੀ ਕਿ ਕੇਖਿਆ ਹੈਡਾ ਅਣਬੀਰ ਜਾਂ ਮੇਰੇ ਸ਼ਾਹ ਸਾਰੇ ਕੇਟ੍ਰਾਂ ਆਦੇਸ਼ਟ ਜਾਂ ਦੱਸਿਆ, ਇਹ ਆਪਸੀ ਸਭ ਸੁੱਖਾਂ ਦੀਆਂ ਸ਼ਾਨਦਾਰ ਜ਼ਿਲ੍ਹਾਂ ਚ ਐਫਆਈਆਰਸੀ ਤੋਂ ਬਣਦੀ ਹੈ ਸੀ ਜੇਕਰ ਕਿਸੇ ਨੂੰ ਸੜਕੋਰਰੀਏਟ ਨਾਲ ਵੇਖ ਰਿਹਾ ਤਾ ਕਿ ਇਸ ਨੂੰ ਖੁੱਲ ਕੇ ਜਿਸ ਕਬਦੇ ਨਾਲ ਗੁਆ ਖੜਕੇ ਹੋ ਜਾਂਦੇ, ਉਹ ਗਿਆ ਹੋਵੇਂ, ਕੁਝ ਆਉਂਦੇ ਹੋ ਸੁਸਕਾਰ, ਕਹਿੰਦੇ ਹਨ, ਹੇ ਪੋਰਨ ਦਿਲ ਪਹੁੰਚ ਲਈ ਠ੍ਠ ਜਾਂਦੇ ਹਨਸਫਵਾ ਪਿਛਲੇ ਕੁਝ ਰਿਲੀਏ 4 ਦਿਨਾਂ ਚ ਇੱਕ ਮਿੱਠ ਦੂਸੂਬਿਆਂ ਦੇ ਨਾਟਕ ਖ਼ਦੇ ਹਨਂ ਸੋਹਣੀਆਂਸੁਪਰੀਮ ਕੋਰਟ ਚ ਧਮਾਕਾ, ਡੇਵਿਡ ਕਿਵੇਂ ਹੁੰਦੀਆਂ ਹਨੀ ਉਹੀ ਨ\n"
     ]
    }
   ],
   "source": [
    "gen_len = 1000\n",
    "model_loaded.to(device)\n",
    "output = model_loaded.generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'ਅੱਜ ਦੀ ਖਬਰ'\n",
    "pad = ''.join([' ' for i in range(context_length - len(context))])\n",
    "padded_context = pad + context\n",
    "x = torch.tensor([encoder(padded_context)], device = device)\n",
    "pos = torch.arange(context_length).unsqueeze(0)\n",
    "pos = pos.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਅੱਜ ਦੀ ਖਬਰ\n",
      "generation:  ਪੋਖਤਜ ਦੀ ਇੱਕ ਦੌਰਾ 15 ਦਾ ਅਨੁਮਾਇਸ ਹੈ ਦਿਨ ਨੂੰ                   ਡਾਊਨਲੋਡ ਕਰ ਰਹੇ ਹੋਣੇ ਨੂੰ ਸਵਾਲ  2 ਬਣਾਉਣ ਵਾਲਾ ਸਫਾ  ਕਰ ਰਹੇ ਨੇ  ਪਰ ਕਵਿਤਾ       ,  ਹਿੱਕੀਸਮੁੰਦਰ ਵਿੱਚ ਬੈਹਟਾਓ  ਕਈ  ਐਪੀਯੂ ਦੀ ਭਾਜਪਾ ਤੂੰ ਮਜ਼ੇਦਾਰੀ ਤੁਹਾਨੂੰ ਦਿਖਾ ਦੇ ਦਿੰਦਾ ਹੈ     ਬੀਵੀਆਲਸਾਡੇ ਨਾਲ ਸਬੰਧਤ ਸਿੱਖਸੰਗਤ ਪੰਨੇ ਤੇ ਸਿੱਖੀ ਸੰਗਤ ਤੇ ਕਈ ਥਕਾਵਟ ਹੋ ਰਹੀ ਹੈਆਪਣੇ ਪਿੰਗ ਕੀਤੇ ਹਨ [2 ਇਕ ਰੁਕੇ ਤੁਹਾਨੂੰ ਇਨਸਾਨ ਨੂੰ ਅਪ ਸ਼ੇਅਰ ਕਰਨ ਲਈ ਵੀ ਕੰਮਕਾਜ ਮਿਤਰੇ ਤੁਹਾਨੂੰ ਇਹ ਇੱਕ ਬੈਸਟਰੀਜ਼ਟੀ ਨਹੀ ਹੈ, ਉਸ ਵਿੱਚ ਜਾਣਦਾ ਹੈਹਾਈਪ੍ਰੌਪੋਰਟ ਆਪਣੀਆਂ ਘੋੜੀਆਂ ਵਿਚ ਹੋਈਆਂ ਦੋਸਤਾਂ ਨੂੰ ਤਾਰਨ ਦੀ ਜਾਗਰੂਕਤਾ ਹੈ, ਅਤੇ ਉਸ ਦੇ ਬਟਨਾਂ ਨੂੰ ਤੁਹਾਨੂੰ ਤੁਹਾਡੇ ਸਮੱਗਰੀਠੀਆਂ ਖਿਲਾਫ਼ ਪਹਿਲੇ ਆਂਡ ਬਣਾਉਣ ਦੀ ਖਰਬ ਕਰਕੇ ਦੋਸਤਾਂ ਨੂੰ ਅਹੰਕਾਰ ਚ ਦੋਸਤਾਂ ਤੋਂ ਮੇਰਾ ਮਜਤਿਆਦਾ ਜਗਮੀਤ ਕੁਝ ਲਾਹੌਰ, ਕਿਸੇ ਵੀ ਜਿਨ੍ਹਾਂ ਅਨੁਸਾਰਾ ਨਿਵਾਸੀਆਂ ਨਹੀਂ ਹੁੰਦੀ ਜੇ, ਪੁਰਸਕਾਰ ਮਮੀਡੀਆ ਥਿਓਪੜ੍ਹ ਹੈਮੈਨੂੰ ਆਂਡ ਸਰੋਤ ਘਰਘੁੱਗੀ ਸੱਕ ਦਿਓ ਜਿਹੜੀ ਮੈਨੂੰ ਹੱਲ ਭੀ ਕਹਿਣਾ ਚਾਹੀਦਾ ਹੈਹੁਕਮ ਜੱਜਾਂ, ਮੇਰੇ ਆਪਣੀਆਂ ਬੱਸਾਂ ਘੱਲਿਜ ਸੀ, ਪਰ ਇੱਕ ਭੀ ਮੈਨੂੰ ਕੋਈ ਮੇਰੇ ਪੁਆਂਡਿਟੈਕਸ ਦੀ ਦੱਗੀ ਕਿ ਪੀਡੀਅਮ ਭਗ ਪੂਰੀ, ਕਿੱਥੋਂ ਬਾਹਰ ਹਟ ਲਿਆ ਜਾਂਦਾ ਹੈਕਾਰ ਟਾਸਕਰ,  ਕਾਰਵਾਈ ਕਰੋ, ਮੈਨੂੰ ਐਸਸੀ ਟਰੇਨਾਈਜ਼ ਬਟਾਲੇਬਲਾ ਦਾ ਨਿਵਾਸ ਬਟਾਲਾ ਵਿੱਚ ਦੇਰ ਬੇਟੇ ਦੀ ਲੱਪੇਗੀ ਹੈ। ਜਾ\n"
     ]
    }
   ],
   "source": [
    "gen_len = 1000\n",
    "model_loaded.to(device)\n",
    "output = model_loaded.generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ਦੇ ਕੁਲ ਪੰਜਵਾਸੀ ਸਾਕੇ ਚ ਭਿੰਡਾ ਪੁਲੀਸ ਪੁਲੀਸ ਪਾਸ ਕੁਲਵਾਲੀ ਯੂਨੀਵਰਸਿਟੀ ਇੰਡੀਆ ਐਕਸਪੀਜ਼ੈਰਰ, , 24  8  ਦਿਨ ਵਪਾਰਕ '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder([i.item() for i in output[0][-100:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
