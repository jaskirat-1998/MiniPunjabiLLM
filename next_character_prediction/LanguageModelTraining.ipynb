{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "context_length = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 300\n",
    "n_embd = 384\n",
    "n_layers = 6\n",
    "dropout = 0.2\n",
    "n_heads = 6\n",
    "rope_embeddings = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ai_corpus.txt') as file:\n",
    "    movie_data = file.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n integer for given actor, it means amount of items actor has\n",
      "price - normalized price in given state.\n",
      "BASE_PENALTY $ = -1$\n",
      "INVALID_MOVE $ = -10$\n",
      "False and True are indicating valid moves just for me.\n",
      "if action == 0:\n",
      "    &quot;BUY&quot;\n",
      "    if discrete_stock == 0:\n",
      "        return -price, True\n",
      "    else:\n",
      "        return INVALID_MOVE, False\n",
      "elif action == 1:\n",
      "    &quot;PASS&quot;\n",
      "    return 3 * BASE_PENALTY, True\n",
      "elif action == 2:\n",
      "    &quot;SELL&quot;\n",
      "    if discrete_stock &lt;= 0:\n",
      "        return INVALID_MOVE, False\n",
      "    return price * 2, True\n",
      "More about problem\n",
      "I think it is already small learning rate. Should I go even lower learning rate and bigger batch size?\n",
      "I am confused about this problem. You can see there are some -10 rewards in plot, so some outputs had invalid move, yet I don't see model to set any actions in that direction.\n",
      "Is model learning?\n",
      "Loss is going very low. So is my solution designed wrong?\n",
      "@NeilSlater thanks again for help, I found the issue, I copied values from actions\n"
     ]
    }
   ],
   "source": [
    "ind = random.randint(0,len(movie_data)-1000)\n",
    "print(movie_data[ind:ind+1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'I': 47046,\n",
       "         'n': 625419,\n",
       "         ' ': 1919096,\n",
       "         'P': 10421,\n",
       "         'o': 675534,\n",
       "         'r': 519164,\n",
       "         't': 864299,\n",
       "         'a': 719236,\n",
       "         'l': 369105,\n",
       "         '2': 17838,\n",
       "         'w': 135833,\n",
       "         'e': 1063796,\n",
       "         's': 559704,\n",
       "         'h': 374819,\n",
       "         'A': 23168,\n",
       "         \"'\": 26107,\n",
       "         'c': 279598,\n",
       "         'b': 124871,\n",
       "         '\"': 9847,\n",
       "         'k': 57687,\n",
       "         'i': 650849,\n",
       "         'd': 282793,\n",
       "         'y': 150165,\n",
       "         'g': 176674,\n",
       "         'u': 271006,\n",
       "         'p': 206388,\n",
       "         'x': 38319,\n",
       "         '.': 108055,\n",
       "         '\\n': 78778,\n",
       "         'm': 236245,\n",
       "         'f': 181574,\n",
       "         'z': 11618,\n",
       "         'Q': 4486,\n",
       "         ':': 17429,\n",
       "         'W': 8007,\n",
       "         'v': 92668,\n",
       "         '?': 11183,\n",
       "         ',': 104333,\n",
       "         'U': 3329,\n",
       "         'q': 22816,\n",
       "         'T': 28208,\n",
       "         '-': 32947,\n",
       "         'S': 16138,\n",
       "         '*': 4205,\n",
       "         'L': 11400,\n",
       "         '!': 1367,\n",
       "         'F': 7346,\n",
       "         'j': 8994,\n",
       "         'E': 8176,\n",
       "         'O': 6527,\n",
       "         '&': 11240,\n",
       "         ';': 13478,\n",
       "         'Y': 4817,\n",
       "         'B': 7707,\n",
       "         '(': 42864,\n",
       "         ')': 43236,\n",
       "         '←': 18,\n",
       "         '—': 137,\n",
       "         'G': 7629,\n",
       "         'H': 6771,\n",
       "         '1': 26018,\n",
       "         '0': 27134,\n",
       "         'K': 1742,\n",
       "         'D': 10622,\n",
       "         '/': 13914,\n",
       "         'R': 9770,\n",
       "         'C': 11252,\n",
       "         'M': 10874,\n",
       "         '@': 1276,\n",
       "         'N': 15722,\n",
       "         '3': 9153,\n",
       "         '8': 4868,\n",
       "         '5': 7291,\n",
       "         '9': 5233,\n",
       "         'V': 3300,\n",
       "         '[': 6651,\n",
       "         ']': 6684,\n",
       "         '4': 7028,\n",
       "         '6': 5004,\n",
       "         '7': 4246,\n",
       "         '$': 42448,\n",
       "         '=': 19802,\n",
       "         'J': 1103,\n",
       "         '%': 1219,\n",
       "         '>': 237,\n",
       "         '_': 37376,\n",
       "         '’': 589,\n",
       "         '+': 5542,\n",
       "         '#': 2583,\n",
       "         '~': 311,\n",
       "         '`': 553,\n",
       "         'X': 2144,\n",
       "         '“': 188,\n",
       "         '”': 196,\n",
       "         'Z': 931,\n",
       "         '\\\\': 30380,\n",
       "         '{': 18702,\n",
       "         '}': 18698,\n",
       "         '|': 2536,\n",
       "         'ç': 6,\n",
       "         'à': 4,\n",
       "         '^': 4492,\n",
       "         'ä': 9,\n",
       "         'ü': 22,\n",
       "         '\\u200a': 6,\n",
       "         'ö': 40,\n",
       "         '\\xa0': 147,\n",
       "         'ß': 10,\n",
       "         '±': 2,\n",
       "         'π': 44,\n",
       "         '×': 52,\n",
       "         '‘': 35,\n",
       "         'é': 31,\n",
       "         '−': 122,\n",
       "         '–': 159,\n",
       "         'ℝ': 9,\n",
       "         '\\xad': 1,\n",
       "         '§': 2,\n",
       "         '¿': 5,\n",
       "         '′': 14,\n",
       "         'σ': 13,\n",
       "         'á': 10,\n",
       "         'ó': 8,\n",
       "         '…': 56,\n",
       "         '⇐': 1,\n",
       "         '⇒': 3,\n",
       "         '„': 2,\n",
       "         '∅': 3,\n",
       "         '∀': 5,\n",
       "         '∈': 9,\n",
       "         '·': 11,\n",
       "         '≥': 5,\n",
       "         '∪': 1,\n",
       "         'α': 42,\n",
       "         'β': 24,\n",
       "         '⟨': 1,\n",
       "         '⟩': 1,\n",
       "         '\\u200b': 10,\n",
       "         '◦': 3,\n",
       "         '≤': 16,\n",
       "         'ï': 10,\n",
       "         '∑': 7,\n",
       "         'γ': 26,\n",
       "         'ε': 6,\n",
       "         'ϵ': 12,\n",
       "         '<': 16,\n",
       "         '€': 6,\n",
       "         '⋅': 2,\n",
       "         '₁': 2,\n",
       "         '₂': 3,\n",
       "         'ﬁ': 16,\n",
       "         'θ': 22,\n",
       "         'δ': 2,\n",
       "         '●': 1,\n",
       "         '⊇': 1,\n",
       "         'ō': 1,\n",
       "         'õ': 3,\n",
       "         '∫': 3,\n",
       "         '∼': 37,\n",
       "         'č': 2,\n",
       "         'ć': 2,\n",
       "         '√': 4,\n",
       "         '\\u200c': 8,\n",
       "         '→': 32,\n",
       "         '≫': 1,\n",
       "         '≪': 2,\n",
       "         '≡': 10,\n",
       "         'Δ': 6,\n",
       "         '̶': 6,\n",
       "         '∧': 8,\n",
       "         '¬': 3,\n",
       "         '´': 6,\n",
       "         '∨': 3,\n",
       "         'ξ': 1,\n",
       "         'ℎ': 1,\n",
       "         '定': 1,\n",
       "         '义': 1,\n",
       "         '一': 1,\n",
       "         '个': 1,\n",
       "         'ę': 1,\n",
       "         'φ': 6,\n",
       "         '°': 19,\n",
       "         '\\u2061': 1,\n",
       "         '∞': 25,\n",
       "         '➡': 5,\n",
       "         '↙': 1,\n",
       "         '↖': 1,\n",
       "         '↗': 1,\n",
       "         '↓': 2,\n",
       "         '⬈': 1,\n",
       "         '¹': 3,\n",
       "         '²': 4,\n",
       "         '³': 1,\n",
       "         '，': 2,\n",
       "         'è': 3,\n",
       "         '∃': 2,\n",
       "         'ê': 1,\n",
       "         'í': 3,\n",
       "         'ã': 2,\n",
       "         'â': 1,\n",
       "         'É': 3,\n",
       "         '»': 1,\n",
       "         '∗': 5,\n",
       "         '\\u2028': 3,\n",
       "         'ú': 5,\n",
       "         '無': 1,\n",
       "         '∣': 2,\n",
       "         'ρ': 1,\n",
       "         '½': 1,\n",
       "         'Α': 6,\n",
       "         '≈': 7,\n",
       "         '‐': 1,\n",
       "         'ﬃ': 2,\n",
       "         '：': 1,\n",
       "         'ł': 2,\n",
       "         'μ': 10,\n",
       "         '÷': 2,\n",
       "         'λ': 4,\n",
       "         '¡': 1,\n",
       "         'º': 3,\n",
       "         '†': 2,\n",
       "         'Χ': 1,\n",
       "         'ő': 1,\n",
       "         'с': 1,\n",
       "         'л': 1,\n",
       "         'о': 1,\n",
       "         'н': 1,\n",
       "         'ˈ': 4,\n",
       "         'ɔ': 1,\n",
       "         'ː': 4,\n",
       "         'ɹ': 4,\n",
       "         'ð': 2,\n",
       "         'ə': 1,\n",
       "         'ɛ': 1,\n",
       "         'ɪ': 1,\n",
       "         'ﬂ': 2,\n",
       "         'ﬀ': 1,\n",
       "         '✅': 2,\n",
       "         '┌': 52,\n",
       "         '─': 438,\n",
       "         '┐': 52,\n",
       "         '│': 275,\n",
       "         '└': 52,\n",
       "         '┬': 50,\n",
       "         '┘': 52,\n",
       "         '▽': 34,\n",
       "         '┆': 22,\n",
       "         '┴': 6,\n",
       "         '❌': 1,\n",
       "         '⭕': 1,\n",
       "         '∆': 6,\n",
       "         'Ψ': 3,\n",
       "         '\\u2000': 1,\n",
       "         '∏': 1,\n",
       "         'ω': 1})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "char_counts = Counter()\n",
    "char_counts.update(movie_data)\n",
    "char_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing extremely low frequency characters from vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<',\n",
       " '¡',\n",
       " '§',\n",
       " '¬',\n",
       " '\\xad',\n",
       " '°',\n",
       " '±',\n",
       " '²',\n",
       " '³',\n",
       " '´',\n",
       " '·',\n",
       " '¹',\n",
       " 'º',\n",
       " '»',\n",
       " '½',\n",
       " '¿',\n",
       " 'É',\n",
       " '×',\n",
       " 'ß',\n",
       " 'à',\n",
       " 'á',\n",
       " 'â',\n",
       " 'ã',\n",
       " 'ä',\n",
       " 'ç',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'í',\n",
       " 'ï',\n",
       " 'ð',\n",
       " 'ó',\n",
       " 'õ',\n",
       " 'ö',\n",
       " '÷',\n",
       " 'ú',\n",
       " 'ü',\n",
       " 'ć',\n",
       " 'č',\n",
       " 'ę',\n",
       " 'ł',\n",
       " 'ō',\n",
       " 'ő',\n",
       " 'ɔ',\n",
       " 'ə',\n",
       " 'ɛ',\n",
       " 'ɪ',\n",
       " 'ɹ',\n",
       " 'ˈ',\n",
       " 'ː',\n",
       " '̶',\n",
       " 'Α',\n",
       " 'Δ',\n",
       " 'Χ',\n",
       " 'Ψ',\n",
       " 'α',\n",
       " 'β',\n",
       " 'γ',\n",
       " 'δ',\n",
       " 'ε',\n",
       " 'θ',\n",
       " 'λ',\n",
       " 'μ',\n",
       " 'ξ',\n",
       " 'π',\n",
       " 'ρ',\n",
       " 'σ',\n",
       " 'φ',\n",
       " 'ω',\n",
       " 'ϵ',\n",
       " 'л',\n",
       " 'н',\n",
       " 'о',\n",
       " 'с',\n",
       " '\\u2000',\n",
       " '\\u200a',\n",
       " '\\u200b',\n",
       " '\\u200c',\n",
       " '‐',\n",
       " '‘',\n",
       " '„',\n",
       " '†',\n",
       " '…',\n",
       " '\\u2028',\n",
       " '′',\n",
       " '\\u2061',\n",
       " '₁',\n",
       " '₂',\n",
       " '€',\n",
       " 'ℎ',\n",
       " 'ℝ',\n",
       " '←',\n",
       " '→',\n",
       " '↓',\n",
       " '↖',\n",
       " '↗',\n",
       " '↙',\n",
       " '⇐',\n",
       " '⇒',\n",
       " '∀',\n",
       " '∃',\n",
       " '∅',\n",
       " '∆',\n",
       " '∈',\n",
       " '∏',\n",
       " '∑',\n",
       " '∗',\n",
       " '√',\n",
       " '∞',\n",
       " '∣',\n",
       " '∧',\n",
       " '∨',\n",
       " '∪',\n",
       " '∫',\n",
       " '∼',\n",
       " '≈',\n",
       " '≡',\n",
       " '≤',\n",
       " '≥',\n",
       " '≪',\n",
       " '≫',\n",
       " '⊇',\n",
       " '⋅',\n",
       " '┆',\n",
       " '┌',\n",
       " '┐',\n",
       " '└',\n",
       " '┘',\n",
       " '┬',\n",
       " '┴',\n",
       " '▽',\n",
       " '●',\n",
       " '◦',\n",
       " '✅',\n",
       " '❌',\n",
       " '➡',\n",
       " '⟨',\n",
       " '⟩',\n",
       " '⬈',\n",
       " '⭕',\n",
       " '一',\n",
       " '个',\n",
       " '义',\n",
       " '定',\n",
       " '無',\n",
       " 'ﬀ',\n",
       " 'ﬁ',\n",
       " 'ﬂ',\n",
       " 'ﬃ',\n",
       " '，',\n",
       " '：'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_chars = {k for k,v in char_counts.items() if v<100}\n",
    "remove_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = re.sub(f\"[{''.join(remove_chars)}]\",' ' , movie_data)\n",
    "data = re.sub(r\" +\", \" \", data)\n",
    "data = re.sub(r\"\\n+\", \"\\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 104\n",
      "unique_charcters: \n",
      " !\"#$%&'()*+,-./0123456789:;=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ –—’“”−─│\n",
      "Total characters in data: 11635783\n"
     ]
    }
   ],
   "source": [
    "# Getting the vocabulary of characters\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "print(f\"unique_charcters: {''.join(chars)}\")\n",
    "print(f'Total characters in data: {len(data)}')\n",
    "\n",
    "# Character encoding logic\n",
    "stoi = {char:i for i, char in enumerate(chars)}\n",
    "itos = {i:char for i, char in enumerate(chars)}\n",
    "encoder = lambda seq: [stoi[i] for i in seq]\n",
    "decoder = lambda encoding: ''.join([itos[i] for i in encoding])\n",
    "\n",
    "# Encoding the data\n",
    "data = torch.tensor(encoder(data), dtype=torch.long)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "train, test = data[:int(0.9*len(data))], data[int(0.9*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[82, 73, 78,  ..., 78, 65, 76],\n",
       "         [77, 69, 78,  ..., 82, 68,  1],\n",
       "         [ 1, 34, 85,  ...,  1, 76, 69],\n",
       "         [79, 78,  1,  ..., 17, 17, 13]]),\n",
       " tensor([[  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255]]),\n",
       " tensor([[73, 78, 71,  ..., 65, 76,  1],\n",
       "         [69, 78, 84,  ..., 68,  1,  7],\n",
       "         [34, 85, 84,  ..., 76, 69, 84],\n",
       "         [78,  1, 79,  ..., 17, 13,  1]]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a sample batch from the data split\n",
    "def get_batch_with_pos(split, batch_size, context_length):\n",
    "    if split == 'train':\n",
    "        data = train\n",
    "    else:\n",
    "        data = test\n",
    "        \n",
    "    #getting random starting indices for the batch_size\n",
    "    start_indices = torch.randint(\n",
    "        len(data) - context_length - 1,\n",
    "        (batch_size,)\n",
    "    )\n",
    "    x_y = torch.stack([data[i:i+context_length+1]for i in start_indices], dim=0)\n",
    "    x, y = x_y[:,:-1], x_y[:,1:]    \n",
    "    pos = torch.arange(batch_size * context_length).reshape(batch_size, context_length) % context_length\n",
    "    x, pos, y = x.to(device), pos.to(device), y.to(device)\n",
    "    return x, pos, y\n",
    "\n",
    "x, pos, y = get_batch_with_pos('train', 4, context_length)\n",
    "x, pos, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE(nn.Module):\n",
    "    def __init__(self, base, dim, max_seq_len):\n",
    "        super(RoPE, self).__init__()\n",
    "        theta = base ** -(torch.arange(0,dim,2)/dim)\n",
    "        pos = torch.arange(max_seq_len)\n",
    "        freq = torch.einsum('i,j->ij', pos, theta)\n",
    "        self.register_buffer('cos', freq.cos())\n",
    "        self.register_buffer('sin', freq.sin())\n",
    "    def forward(self, x):\n",
    "        B, S, _ = x.shape\n",
    "        cos = self.cos[:S]\n",
    "        sin = self.sin[:S]\n",
    "        a, b = x[:,:,::2], x[:,:,1::2]\n",
    "        a_cos, b_cos, a_sin, b_sin = a * cos, b * cos, a * sin, b * sin\n",
    "        # rot(a,b) = a cos(theta) - b sin(theta), a sin(theta) + b cos(theta)\n",
    "        rot_1, rot_2 = a_cos - b_sin, a_sin + b_cos\n",
    "        rot = torch.stack((rot_1, rot_2), -1)\n",
    "        rot_embd = rot.reshape(B, S, -1)\n",
    "        return rot_embd\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFroward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super(FeedFroward, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd*4, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.query = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.key = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.value = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if rope_embeddings:\n",
    "            self.rope = RoPE(1e4, head_dim, 2048)\n",
    "\n",
    "    def forward(self, embed, verbose=False):\n",
    "        q = self.query(embed)\n",
    "        k = self.key(embed)\n",
    "        v = self.value(embed)\n",
    "        if rope_embeddings:\n",
    "            q = self.rope(q)\n",
    "            k = self.rope(k)\n",
    "        a = q @ k.transpose(-2,-1) * self.head_dim**-0.5\n",
    "        a = a.masked_fill(self.tril==0, float('-inf'))\n",
    "        a = F.softmax(a, dim=-1)\n",
    "        a = self.dropout(a)\n",
    "        if verbose:\n",
    "            print(a.shape)\n",
    "            plt.imshow([[j.item() for j in i]for i in a[0]])\n",
    "\n",
    "        output = a @ v\n",
    "        return output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(head_size) for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, idx, verbose = False):\n",
    "        output =  torch.cat([head(idx, verbose) for head in self.heads], dim = -1)\n",
    "        output =  self.proj(output)\n",
    "        return self.dropout(output)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_heads):\n",
    "        super(Block, self).__init__()\n",
    "        self.mh_attn = MultiHeadAttention(n_heads, n_embd//n_heads)\n",
    "        #self.mh_attn = MoEMultiheadAttention(n_heads, n_embd//n_heads)\n",
    "        self.f_frwd = FeedFroward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mh_attn(x)\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.f_frwd(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class PunjabiAttentionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PunjabiAttentionModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(context_length, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads) for i in range(n_layers)])\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.linear = nn.Linear(n_embd, vocab_size)\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, idx, positions, labels=None, verbose = False):\n",
    "        if verbose:\n",
    "            print([decoder([i.item() for i in idx[0]])],'\\n')\n",
    "        idx = self.token_embedding(idx)\n",
    "        if not rope_embeddings:\n",
    "            pos_embed = self.position_embedding(positions)\n",
    "            idx += pos_embed\n",
    "        idx = self.blocks(idx)\n",
    "        logits = self.linear(idx)\n",
    "        \n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, S, E = logits.shape\n",
    "            logits = logits.reshape(B * S, E)\n",
    "            labels = labels.reshape(B*S)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, pos, max_seq_length, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _ = self(idx[:,-context_length:], pos)\n",
    "            logits = logits[:, -1, :]\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, -1)\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "        return idx\n",
    "    def generate_upgraded(self, idx, pos, max_seq_length, temperature=1.0, top_p=1.0, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _ = self(idx[:,-context_length:], pos)\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            # Apply temperature\n",
    "            if temperature > 0:\n",
    "                logits = logits / temperature\n",
    "\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "                # Apply top_p (nucleus) sampling\n",
    "                if top_p < 1.0:\n",
    "                    sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "                    cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "                    sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "                    sorted_indices_to_remove[..., 0] = 0\n",
    "                    indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n",
    "                    probs = probs.masked_fill(indices_to_remove, 0.0)\n",
    "                    probs = probs / probs.sum(dim=-1, keepdim=True)  # renormalize\n",
    "\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids), dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T), dim=1)\n",
    "\n",
    "        return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate_attn(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = {}\n",
    "    for split in ['train', 'eval']:\n",
    "        x, pos, y = get_batch_with_pos(split, batch_size, context_length)\n",
    "        _, loss = model(x, pos, y)\n",
    "        losses[split] = loss.item()\n",
    "    return losses\n",
    "\n",
    "\n",
    "model_attn = PunjabiAttentionModel()\n",
    "model_attn.to(device)\n",
    "optimizer_attn = torch.optim.AdamW(model_attn.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 4.776429653167725, eval_loss: 4.777175426483154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 501/5000 [01:29<25:50,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.5461839437484741, eval_loss: 1.5966216325759888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1001/5000 [02:58<22:58,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.4050331115722656, eval_loss: 1.3915424346923828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1501/5000 [04:27<20:05,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.3361411094665527, eval_loss: 1.3208335638046265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2001/5000 [05:55<17:13,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.256089210510254, eval_loss: 1.2939963340759277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2501/5000 [07:24<14:22,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.2292159795761108, eval_loss: 1.2875800132751465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3001/5000 [08:52<11:29,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.2240582704544067, eval_loss: 1.2685086727142334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3501/5000 [10:21<08:37,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1578712463378906, eval_loss: 1.229555606842041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4001/5000 [11:50<05:44,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1746991872787476, eval_loss: 1.2010360956192017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4501/5000 [13:18<02:52,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1457452774047852, eval_loss: 1.2265880107879639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [14:46<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1577863693237305\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(max_iters)):\n",
    "    if i % eval_interval == 0:\n",
    "        losses = evaluate_attn(batch_size = eval_iters, model = model_attn)\n",
    "        print(f'train loss: {losses[\"train\"]}, eval_loss: {losses[\"eval\"]}')\n",
    "    x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "    _, loss = model_attn(x, pos, y)\n",
    "    optimizer_attn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_attn.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep have exceeded the time limit so the episode ends. This also indicated that you have to bootstrap the Q value estimate.\n",
      "terminated instead is when the agent have reached a terminal state, therefore the episode naturally ends. You should use both to under\n"
     ]
    }
   ],
   "source": [
    "x,y,pos = get_batch_with_pos('eval',1,context_length)\n",
    "context = decoder(i.item() for i in x[0])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ep have exceeded the time limit so the episode ends. This also indicated that you have to bootstrap the Q value estimate.\n",
      "terminated instead is when the agent have reached a terminal state, therefore the episode naturally ends. You should use both to under\n",
      "generation: stand, it performs matrix should found the complexity of capable input and one current input situation. This full create networks, although there, or it means when tackling the $\\mathbf{x}$ is the next state.\n",
      "The variation is the current static sequence is easily (if there a good update of note).\n",
      "The performance detected from the discussion (or current one layers is entirely). We use a descriptor of multiple stopping from $X + \\epsilon$ following&quot; (Some Visual will worried to the DQER. Inte\n"
     ]
    }
   ],
   "source": [
    "gen_len = 500\n",
    "output = model_attn.generate(x,pos, gen_len, True)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(context, model, gen_len):\n",
    "    pad = ''.join([' ' for i in range(context_length - len(context))])\n",
    "    padded_context = pad + context\n",
    "    x = torch.tensor([encoder(padded_context)], device = device)\n",
    "    pos = torch.arange(context_length).unsqueeze(0)\n",
    "    pos = pos.to(device)\n",
    "    output = model.generate(x,pos, gen_len)\n",
    "    print(f'context: {context}\\n')\n",
    "    generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "    print(f'generation: {generation}')\n",
    "    return generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: How are you?\n",
      "\n",
      "generation: \n",
      "I need to person this varue the data \"I think you till the best way $b$, then you can evaluate weights with variance_ of the reward state $(th)$ outputs $R_t$ (training collection the odder.\n",
      "As Win, the hidden maybe considering the WInd1500% of something espective to we\n",
      "import answer, without waiting information problem.\n",
      "ERIOWK and REILU Postly DRone's recommendation for action-space entropywhich humans definitely impocal, I was moving for all, it doesn't really lie in the region of 0 degrees c\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('How are you?', model_attn, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Artificial intelligence and machine\n",
      "\n",
      "generation:  learning?\n",
      "P) to be the work (\n",
      " [cquest architecture) &quot;randomness &quot;takly&quot; embedding in\n",
      "from loop equations, if not what we define this ignoring the better q-first, tune for ask models based on the two image classify $[$p(s'|c||S,|s,a)$, and $\\epsilon$-greedy closed Rootlin Frameworks - users for sentence that is finite value functions (say keys real vappital) and policy on the index approximation power.\n",
      "This is that this point is contained Countropy when the same word images (in t\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('Artificial intelligence and machine', model_attn, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model/ai_model_5k_steps.pth'\n",
    "#torch.save(model_attn.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PunjabiAttentionModel(\n",
       "  (token_embedding): Embedding(104, 384)\n",
       "  (position_embedding): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=384, out_features=104, bias=True)\n",
       "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = PunjabiAttentionModel()\n",
    "model_loaded.load_state_dict(torch.load(path,  map_location=device))\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: NLP, Large language models (LLM)\n",
      "\n",
      "generation:  into \n",
      "import $(L_\\ \n",
      "\\end{bmatrix}) = \\\\ su_{t = 1}{N} \\rightarrow \\mathbb{E}[n] + \\gamma^n X$ and $\\lambda\\in\\{q(1, \\ldots,s)$$│\n",
      "To percept, then containing representation of steeps different subcase and $j$ isn(perhapt $(Z|, 1)$). Once then $\\gamma$ denote the old in $N_j$ would be $D$ and $1$. However, if you could also differ from multiple paper, or $L$):\n",
      "$$V(s)$ the goal is module time, $\\epsilon$ that models are used to $r(s, a, 0)$ is a condition of $\\epsilon}$ then $\\gamma$ conceptube a \n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('NLP, Large language models (LLM)', model_loaded, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Transformer\n",
      "\n",
      "generation: , then the large negative would approximately carround by the visit function `aj = softmax(other loss) will help would we understand the ILL the question random, and when dontain keeping it will be used a convolution dangerous.. \n",
      "We timing an action step in a jown case you have an local reproductive complex from one of them would find this would call a time?\n",
      "Supervised learning return length, from _ ir) your response. That is a run, have manager can be more basic mechanically there it can over t\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('Transformer', model_loaded, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woohoo, the model has succefully learned to YAP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5000 [00:00<58:16,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1268360614776611, eval_loss: 1.1962356567382812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 501/5000 [01:29<25:49,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.122773289680481, eval_loss: 1.1756556034088135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1001/5000 [02:57<22:59,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1141284704208374, eval_loss: 1.1807650327682495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1501/5000 [04:26<20:05,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.1075068712234497, eval_loss: 1.2118185758590698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2001/5000 [05:54<17:14,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0990971326828003, eval_loss: 1.1362547874450684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2501/5000 [07:23<14:21,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.08599853515625, eval_loss: 1.159732460975647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3001/5000 [08:51<11:29,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.080183744430542, eval_loss: 1.1591893434524536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3501/5000 [10:20<08:36,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.074751615524292, eval_loss: 1.1685752868652344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4001/5000 [11:49<05:44,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0700061321258545, eval_loss: 1.1723171472549438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4501/5000 [13:17<02:51,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.0272647142410278, eval_loss: 1.1553329229354858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [14:45<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9859277009963989\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(max_iters)):\n",
    "    if i % eval_interval == 0:\n",
    "        losses = evaluate_attn(batch_size = eval_iters, model = model_attn)\n",
    "        print(f'train loss: {losses[\"train\"]}, eval_loss: {losses[\"eval\"]}')\n",
    "    x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "    _, loss = model_attn(x, pos, y)\n",
    "    optimizer_attn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_attn.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model/ai_model_10k_steps.pth'\n",
    "#torch.save(model_attn.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PunjabiAttentionModel(\n",
       "  (token_embedding): Embedding(104, 384)\n",
       "  (position_embedding): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=384, out_features=104, bias=True)\n",
       "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = PunjabiAttentionModel()\n",
    "model_loaded.load_state_dict(torch.load(path, map_location=device))\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: AI and \n",
      "\n",
      "generation: it encountered it to predict AMA while an AI, which has N would still be a collection. Hence a perceptron correlation.\n",
      "These methods I understand and we compute the largest results that deep learning make sure that you think LSTMs to get explained by the words are memory. So, one appropriate network images that you want the problem. In theory, you also try and simpler speech-device the ratio of the 3 augmentation we are not 0, then can capturing the idea of 0.3; then linear function is the order\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('AI and ', model_loaded, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(context, model, gen_len, temperature=1.0, top_p=1.0):\n",
    "    pad = ''.join([' ' for i in range(context_length - len(context))])\n",
    "    padded_context = pad + context\n",
    "    x = torch.tensor([encoder(padded_context)], device = device)\n",
    "    pos = torch.arange(context_length).unsqueeze(0)\n",
    "    pos = pos.to(device)\n",
    "    output = model.generate_upgraded(x,pos, gen_len, temperature, top_p)\n",
    "    print(f'context: {context}\\n')\n",
    "    generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "    print(f'generation: {generation}')\n",
    "    return generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 0.5, top_p: 0.1\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning algorithms and the same state is a single action for the same time step in the same state in the same time. The problem is that the same as a single state and the same state is a single action space in the same state space in the same state and the same state is a single state and the same state is a single state and the same state is a single state and the same state is a single state and action that the model will be a single state and the same state is a single action space and the \n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 0.5, top_p: 0.3\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning algorithms and the output is a continuous action space in the same time step in the same time. The problem is that the problem is that the same state is a continuous action space in the case of the problem in the same as a single state and the same state is a single action space and the same state is a single state and the output of the problem in the context of the state and the output of the problem in the context of the problem in the same state and the same as a single state and th\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 0.5, top_p: 0.5\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning algorithms and the model is a matrix of the model to be a problem in the context of the problem in the same as a positive set of the problem in the case of the context of the context of the problem in the context of the problem in the problem in the same state and the context of the state and a specific policy for the state and the context of the context of the context of the context of the policy in the context of the state and the policy is the same as a single action space in the co\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 0.5, top_p: 0.6\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning algorithms and the model to interact the same state in the time step in the problem in the context of the input to the same time. The reward is the same state is the model will be the model to produce a machine learning algorithm is the same as a simple problem in the context of the state and the same policy and the policy gradient descent in the paper that is the problem that it will be the same as a problem with the context of the policy and the model will be the same thing that it i\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 0.5, top_p: 0.9\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning algorithm to learn the state in the tensor to choose the state space and state the action values of the state and starting state transitions that can be done on the state space for an artificial intelligent in the context of a state in the case of the policy is deterministic function in the state and then consider the same problem in the same state space of the architecture to the output of the problem in the paper. This is considered the application of the first problem to be solved t\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1, top_p: 0.1\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning algorithms and the same state is a single action for the same time step in the same state in the same time. The problem is that the model is to solve the problem in the case of the state and the output of the problem in the same state of the problem in the same state and the same state is a single state and the same state is a single state and the same state is a single and the output of the problem in the same state is a single and the policy is a single state and the same state is a \n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1, top_p: 0.3\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning to be a complete in the same as the same state and the action space is the model to make a single state and a state of the model and so the same state in the paper and the same as a positive set of possible states that the agent is a state of the state and the output layer to the policy gradient descent in the context of the context of the same state space and state and action space to the context of the policy is a matrix of the problem in the same time. The action space is a simple a\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1, top_p: 0.5\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning in the sense of the parameters of the current control the model with respect to the output in the parameter to a state and in the future to continue the context of a convolution for a continuous value function and an input feature vector for each policy that would be a lot of different context and completely probably separate the model of the policy gradient descent on the training set of states and the intent space to a continuous value function that in the details of the model is to \n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1, top_p: 0.6\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning the architecture is a more of selecting an observation function (as it always the number of interested in the training set is an approximation algorithm and so on. The resulting internal network which contains a constant problem as the output state and an input data set of networks are to actually interested in the reported search topic to the policy function in the time step. \n",
      "A policy algorithm that we may not sure that the policy is included an algorithm for the training data from a\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1, top_p: 0.9\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning all of the output that games. This can be done on the best way assumed to be useful information in the expectation between the code for active learning. For example, if it is not really add a neural network would not its pretty foundation, and the behaviour policy $\\pi_i$ (are there is encodes on the part it into shows the target representation algorithms and validation its taken step $x_i$.\n",
      "What is the mapping we can both word the learning matrices, and require an algorithm is a graph\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1.5, top_p: 0.1\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning algorithms and the same as a single state and the output of the context of the context of the problem in the context of the problem in the context of the context of the context of the problem in the same state of the state and action that the model is a continuous action space in the same as a single state and action that the model will be a complex to the problem in the context of the context of the context of the problem in the context of the context of the context of the problem in \n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1.5, top_p: 0.3\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning it to move a complete state to a training policy (the second parameters that it is always the state in the case of problem that can allow the agent in the paper and in the problem and the model to contain the same policy in a network to start with state space and in the same amount of the network to solve a tensor way to do it in the set of parameters of the state value of a policy gradient algorithm to continuous to a policy that it is a more than one in the same time. In other words,\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1.5, top_p: 0.5\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning algorithms for a problem (I think a program in a posted on the state of such a model from the network (the target is a probability for the answer.)\n",
      "When it could policy with a calculation for superintelligence is called 1000 problems. So in policy gradient policy iteration.\n",
      "So what you mean some examples of the model and then the training dataset. If you have a deep learning for example problem that some more popular because we can detect the images are all of the positions of problems\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1.5, top_p: 0.6\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  the application to worry than the case of change and no ever at random. Also, I can think there are more complicated an image and never update we have no obtained above, but it will not policy gradient and it as opposed to the agent or more for example.\n",
      "Are the policy is not included, the reward is weird as neural networks from different answer.\n",
      "I am not an optimization to post, so you have a mathematical reward is not managed it being classification allow on the reason of the model with part i\n",
      "----------------------------\n",
      "\n",
      "\n",
      "temperature: 1.5, top_p: 0.9\n",
      "\n",
      "context: AI and machine\n",
      "\n",
      "generation:  learning upscale full danger?\n",
      "an evently worth approximator.\n",
      "If D,cj,HC, w us your model to buy how set its long.\n",
      "You say if relating, I'm trying too see: The agent's uncertain. I know go it accuracy makes, bitakes IDO and do clarity it without detailing erratifics: modern AI:H; KHeader\n",
      "tunits (23202) data&quot; this, never seconstruction on-buards loosed above. Introducing an Nius.\n",
      "Returns-much Autoencoders for bothin whome task, and lett family limitten off-critic gap talls can take, you to o\n",
      "----------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperatures = [0.5, 1, 1.5]\n",
    "top_p = [0.1, 0.3, 0.5, 0.6, 0.9]\n",
    "for t in temperatures:\n",
    "    for p in top_p:\n",
    "        print(f\"temperature: {t}, top_p: {p}\\n\")\n",
    "        gen = generate_text('AI and machine', model_loaded, 500, temperature=t, top_p=p)\n",
    "        print('----------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, pos = get_batch_with_pos('test', 6, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: e-force solutions that create only hype - it is obvious to me that with more computation, data and model capacity, a model trained to minimize some objective might perform better, but who cares if the generated text contains fewer errors or &quot;seems to \n",
      "\n",
      "generation: provide the next time step at the policy gradient into a single context of the model to solve the policy in the sense of the state is a positive of a convolution to perform a convolution for the same called the problem of possible and action that can be de\n",
      "------------------------\n",
      "\n",
      "context: ender?\n",
      "The values need to be stored during each batch only, as the forward values are needed to calculate the gradients.\n",
      "A relevant equation from back propagation is how to derive $\\nabla_{z_j^{(k)}}J$, or the gradient of error function $J$ with respect to\n",
      "\n",
      "generation:  the reward function $p_\\pi$ where $x_i$ is a reward $i$ the depth of the problem in the same as a convolution of $y_i$ is the next state $x_t$ and $x_i$ and $i$ and $x_i$ in the expected value of the policy $x_1$ and $y_1$ and $f_1$ in $x_1$ and $x_1$ and\n",
      "------------------------\n",
      "\n",
      "context: he available training data, the network size, and the available compute.\n",
      "This questions has also been answered here and here.\n",
      "Twin Delayed DDPG (TD3) uses a double Q trick since the policy is deterministic like in DDPG, which is to mitigate the maximum ove\n",
      "\n",
      "generation: r time to start the training data and the problem with a state and the problem with a linear approach to the optimal policy is also the same policy gradient and start of the target network is independent on the next state and representation in the state th\n",
      "------------------------\n",
      "\n",
      "context: \n",
      "The second objective\n",
      "is the next sentence prediction (NSP) task. This is a binary\n",
      "classification task for predicting whether two sentences are\n",
      "subsequent in the original text.\n",
      "I am looking for such objective function as mathematical definition.\n",
      "Understand\n",
      "\n",
      "generation: ing the context of my network contains a lot of detecting the problem in the dataset of the model is not to contain the optimal policy in the environment (such as the network to the other problem). The problem is that the context of the problem and an inte\n",
      "------------------------\n",
      "\n",
      "context:  support in $[-\\infty, \\infty]$, and so limiting the actions was done by truncating the distribution which is not much clever, and in fact usually results in lower performance: I guess because you have no gradients when actions fall outside the desired ran\n",
      "\n",
      "generation: ge (in the first complex approximation). The only possible contains a model that would be much more sophisticated by a neural network to the same time. A policy gradient in the experience replay in the paper because the problem that is not to the same expl\n",
      "------------------------\n",
      "\n",
      "context: e things.\n",
      "A good interactive explanation can be seen at MLU-explain: https://mlu-explain.github.io/bias-variance/\n",
      "I've been playing around with nanoGPT, and recently I decided I wanted to fine-tune it using the dolly instruction set. This data set consists\n",
      "\n",
      "generation:  of the environment is a separate the same set of the models which in the same state is completely represented in the test into the network architecture. It is not an action for the model is an answer to a problem with the network and the model is not to b\n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contexts = [decoder([j.item() for j in i]) for i in x]\n",
    "for context in contexts:\n",
    "    gen = generate_text(context, model_loaded, 256, temperature=1, top_p=0.5)\n",
    "    print('------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: AI and \n",
      "\n",
      "generation: something, if M intelligentax.\n",
      "Concinclude Some using Connected UR * ard and for random. Essentially, the same features mean by the optimal value, especially up-by-clarifycase linear for weights and evolutions *N* simple* curves argument for all image deeplearning. However, the problem rectangly words, the learning model (separate for tweet longer and then clipping for your problem state).\n",
      "Insearch case, it is back finding itself.\n",
      "&quot;a paper Intron&quot; (axis without knowing action etc) is c\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text('AI and ', model_loaded, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5697,  0.2498, -0.3047, -0.5448, -0.5410,  0.8568, -0.4991,  0.1679,\n",
       "        -0.3779, -0.1210, -0.1450,  0.6663,  0.3774,  0.8255,  0.5919,  0.4672,\n",
       "        -1.1712,  0.2417,  0.0509, -0.3119,  0.4026, -0.5967,  0.6641, -0.5662,\n",
       "         0.3841, -0.4602, -0.4926,  0.1171,  0.4809,  0.0376,  0.2115,  0.9371,\n",
       "        -0.0817, -0.6111, -0.0407, -0.3396,  0.0108, -0.6285, -1.0472, -1.2361,\n",
       "         0.1221,  0.7897, -0.9812, -0.7271, -0.0184,  0.5605,  0.7131,  1.6568,\n",
       "        -0.5996,  0.0499,  0.1793,  0.6818,  0.4649,  0.4592,  0.0977,  0.4875,\n",
       "        -0.2542, -0.4355, -0.8222, -0.4712, -1.7023,  0.0223,  0.1061, -0.2641,\n",
       "         0.3260,  0.4232, -0.2637,  0.0819, -0.3178, -0.1890, -1.4600,  0.4860,\n",
       "        -0.1431,  1.4096,  0.5978, -0.0707, -0.2015, -1.2384,  0.3305,  0.0857,\n",
       "         0.0065, -0.1367,  0.3823, -0.4993, -0.7677,  0.3216,  0.4791, -1.2550,\n",
       "         0.3929,  0.6452, -0.9320,  0.1709,  0.4395,  0.0556,  0.7812,  1.0457,\n",
       "         0.7088,  1.3041, -0.9440, -0.3060, -0.4245,  0.6992,  0.3609, -0.4526],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x14822b2b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "temp = 0.5\n",
    "\n",
    "plt.scatter(range(last_logits.shape[1]), [i.item() for i in F.softmax(last_logits[0], dim=-1)], color = 'blue')\n",
    "plt.scatter(range(last_logits.shape[1]), [i.item() for i in F.softmax(last_logits[0]/temp, dim=-1)], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0140, 0.0102, 0.0059, 0.0046, 0.0046, 0.0187, 0.0048, 0.0094, 0.0054,\n",
       "        0.0070, 0.0069, 0.0155, 0.0116, 0.0181, 0.0143, 0.0127, 0.0025, 0.0101,\n",
       "        0.0084, 0.0058, 0.0119, 0.0044, 0.0154, 0.0045, 0.0117, 0.0050, 0.0049,\n",
       "        0.0089, 0.0128, 0.0082, 0.0098, 0.0203, 0.0073, 0.0043, 0.0076, 0.0057,\n",
       "        0.0080, 0.0042, 0.0028, 0.0023, 0.0090, 0.0175, 0.0030, 0.0038, 0.0078,\n",
       "        0.0139, 0.0162, 0.0416, 0.0044, 0.0083, 0.0095, 0.0157, 0.0126, 0.0126,\n",
       "        0.0088, 0.0129, 0.0062, 0.0051, 0.0035, 0.0050, 0.0014, 0.0081, 0.0088,\n",
       "        0.0061, 0.0110, 0.0121, 0.0061, 0.0086, 0.0058, 0.0066, 0.0018, 0.0129,\n",
       "        0.0069, 0.0325, 0.0144, 0.0074, 0.0065, 0.0023, 0.0110, 0.0086, 0.0080,\n",
       "        0.0069, 0.0116, 0.0048, 0.0037, 0.0110, 0.0128, 0.0023, 0.0118, 0.0151,\n",
       "        0.0031, 0.0094, 0.0123, 0.0084, 0.0173, 0.0226, 0.0161, 0.0292, 0.0031,\n",
       "        0.0058, 0.0052, 0.0160, 0.0114, 0.0050], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft = F.softmax(last_logits[0], dim=-1)\n",
    "soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1395,  0.4997, -0.6093, -1.0897, -1.0819,  1.7136, -0.9981,  0.3359,\n",
       "        -0.7559, -0.2421, -0.2899,  1.3326,  0.7547,  1.6509,  1.1838,  0.9344,\n",
       "        -2.3424,  0.4835,  0.1019, -0.6238,  0.8052, -1.1934,  1.3282, -1.1325,\n",
       "         0.7682, -0.9204, -0.9851,  0.2342,  0.9618,  0.0752,  0.4229,  1.8741,\n",
       "        -0.1635, -1.2223, -0.0814, -0.6792,  0.0215, -1.2570, -2.0945, -2.4722,\n",
       "         0.2442,  1.5794, -1.9624, -1.4543, -0.0369,  1.1209,  1.4261,  3.3136,\n",
       "        -1.1991,  0.0998,  0.3586,  1.3635,  0.9297,  0.9183,  0.1955,  0.9749,\n",
       "        -0.5084, -0.8710, -1.6445, -0.9425, -3.4045,  0.0446,  0.2123, -0.5281,\n",
       "         0.6520,  0.8463, -0.5274,  0.1638, -0.6357, -0.3781, -2.9201,  0.9720,\n",
       "        -0.2862,  2.8192,  1.1957, -0.1414, -0.4029, -2.4767,  0.6609,  0.1713,\n",
       "         0.0130, -0.2735,  0.7645, -0.9987, -1.5354,  0.6432,  0.9582, -2.5100,\n",
       "         0.7858,  1.2904, -1.8640,  0.3417,  0.8789,  0.1111,  1.5623,  2.0915,\n",
       "         1.4177,  2.6081, -1.8881, -0.6120, -0.8489,  1.3985,  0.7218, -0.9053],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_logits[0]/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0416, 0.0325, 0.0292, 0.0226, 0.0203, 0.0187, 0.0181, 0.0175, 0.0173,\n",
       "         0.0162, 0.0161, 0.0160, 0.0157, 0.0155, 0.0154, 0.0151, 0.0144, 0.0143,\n",
       "         0.0140, 0.0139, 0.0129, 0.0129, 0.0128, 0.0128, 0.0127, 0.0126, 0.0126,\n",
       "         0.0123, 0.0121, 0.0119, 0.0118, 0.0117, 0.0116, 0.0116, 0.0114, 0.0110,\n",
       "         0.0110, 0.0110, 0.0102, 0.0101, 0.0098, 0.0095, 0.0094, 0.0094, 0.0090,\n",
       "         0.0089, 0.0088, 0.0088, 0.0086, 0.0086, 0.0084, 0.0084, 0.0083, 0.0082,\n",
       "         0.0081, 0.0080, 0.0080, 0.0078, 0.0076, 0.0074, 0.0073, 0.0070, 0.0069,\n",
       "         0.0069, 0.0069, 0.0066, 0.0065, 0.0062, 0.0061, 0.0061, 0.0059, 0.0058,\n",
       "         0.0058, 0.0058, 0.0057, 0.0054, 0.0052, 0.0051, 0.0050, 0.0050, 0.0050,\n",
       "         0.0049, 0.0048, 0.0048, 0.0046, 0.0046, 0.0045, 0.0044, 0.0044, 0.0043,\n",
       "         0.0042, 0.0038, 0.0037, 0.0035, 0.0031, 0.0031, 0.0030, 0.0028, 0.0025,\n",
       "         0.0023, 0.0023, 0.0023, 0.0018, 0.0014], grad_fn=<SortBackward0>),\n",
       " tensor([ 47,  73,  97,  95,  31,   5,  13,  41,  94,  46,  96, 101,  51,  11,\n",
       "          22,  89,  74,  14,   0,  45,  55,  71,  28,  86,  15,  52,  53,  92,\n",
       "          65,  20,  88,  24,  82,  12, 102,  78,  64,  85,   1,  17,  30,  50,\n",
       "          91,   7,  40,  27,  62,  54,  79,  67,  93,  18,  49,  29,  61,  36,\n",
       "          80,  44,  34,  75,  32,   9,  81,  72,  10,  69,  76,  56,  66,  63,\n",
       "           2,  99,  19,  68,  35,   8, 100,  57, 103,  25,  59,  26,   6,  83,\n",
       "           4,   3,  23,  21,  48,  33,  37,  43,  84,  58,  90,  98,  42,  38,\n",
       "          16,  39,  77,  87,  70,  60]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_probs, sorted_indices = torch.sort(soft, descending=True)\n",
    "sorted_probs, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0416, 0.0741, 0.1034, 0.1260, 0.1462, 0.1649, 0.1830, 0.2005, 0.2179,\n",
       "        0.2341, 0.2502, 0.2662, 0.2819, 0.2973, 0.3128, 0.3279, 0.3423, 0.3567,\n",
       "        0.3707, 0.3846, 0.3975, 0.4104, 0.4233, 0.4361, 0.4488, 0.4614, 0.4740,\n",
       "        0.4863, 0.4984, 0.5103, 0.5220, 0.5337, 0.5453, 0.5569, 0.5683, 0.5794,\n",
       "        0.5903, 0.6013, 0.6115, 0.6216, 0.6314, 0.6409, 0.6503, 0.6597, 0.6687,\n",
       "        0.6776, 0.6864, 0.6952, 0.7038, 0.7125, 0.7208, 0.7292, 0.7375, 0.7458,\n",
       "        0.7539, 0.7619, 0.7699, 0.7777, 0.7853, 0.7927, 0.8001, 0.8071, 0.8140,\n",
       "        0.8209, 0.8278, 0.8343, 0.8408, 0.8470, 0.8531, 0.8592, 0.8650, 0.8709,\n",
       "        0.8767, 0.8825, 0.8881, 0.8936, 0.8987, 0.9039, 0.9089, 0.9139, 0.9189,\n",
       "        0.9237, 0.9286, 0.9334, 0.9380, 0.9426, 0.9471, 0.9515, 0.9558, 0.9602,\n",
       "        0.9644, 0.9682, 0.9719, 0.9754, 0.9785, 0.9816, 0.9846, 0.9874, 0.9898,\n",
       "        0.9921, 0.9944, 0.9967, 0.9986, 1.0000], grad_fn=<CumsumBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "cumulative_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices_to_remove = cumulative_probs > 0.3\n",
    "sorted_indices_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "sorted_indices_to_remove[..., 0] = 0\n",
    "sorted_indices_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True, False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False,  True,  True,\n",
       "         True, False,  True,  True])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n",
    "indices_to_remove      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0140, 0.0102, 0.0059, 0.0046, 0.0046, 0.0187, 0.0048, 0.0094, 0.0054,\n",
       "         0.0070, 0.0069, 0.0155, 0.0116, 0.0181, 0.0143, 0.0127, 0.0025, 0.0101,\n",
       "         0.0084, 0.0058, 0.0119, 0.0044, 0.0154, 0.0045, 0.0117, 0.0050, 0.0049,\n",
       "         0.0089, 0.0128, 0.0082, 0.0098, 0.0203, 0.0073, 0.0043, 0.0076, 0.0057,\n",
       "         0.0080, 0.0042, 0.0028, 0.0023, 0.0090, 0.0175, 0.0030, 0.0038, 0.0078,\n",
       "         0.0139, 0.0162, 0.0416, 0.0044, 0.0083, 0.0095, 0.0157, 0.0126, 0.0126,\n",
       "         0.0088, 0.0129, 0.0062, 0.0051, 0.0035, 0.0050, 0.0014, 0.0081, 0.0088,\n",
       "         0.0061, 0.0110, 0.0121, 0.0061, 0.0086, 0.0058, 0.0066, 0.0018, 0.0129,\n",
       "         0.0069, 0.0325, 0.0144, 0.0074, 0.0065, 0.0023, 0.0110, 0.0086, 0.0080,\n",
       "         0.0069, 0.0116, 0.0048, 0.0037, 0.0110, 0.0128, 0.0023, 0.0118, 0.0151,\n",
       "         0.0031, 0.0094, 0.0123, 0.0084, 0.0173, 0.0226, 0.0161, 0.0292, 0.0031,\n",
       "         0.0058, 0.0052, 0.0160, 0.0114, 0.0050], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0187, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0155, 0.0000, 0.0181, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0154, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0203, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0175, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0162, 0.0416, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0325, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0173, 0.0226, 0.0161, 0.0292, 0.0000,\n",
       "         0.0000, 0.0000, 0.0160, 0.0000, 0.0000], grad_fn=<MaskedFillBackward0>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = soft.masked_fill(indices_to_remove, 0.0)\n",
    "soft, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0598, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0494, 0.0000, 0.0579, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0493, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0648, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0559, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0518, 0.1331, 0.0000, 0.0000, 0.0000, 0.0502, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.1039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0554, 0.0722, 0.0516, 0.0935, 0.0000,\n",
       "        0.0000, 0.0000, 0.0511, 0.0000, 0.0000], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_prob = probs = probs / probs.sum(dim=-1, keepdim=True)\n",
    "scale_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1039, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0935, grad_fn=<SelectBackward0>),\n",
       " tensor(0.1331, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0493, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0648, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0518, grad_fn=<SelectBackward0>),\n",
       " tensor(0.0140, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_prob[73], scale_prob[97], scale_prob[47], scale_prob[22], scale_prob[31], scale_prob[46], soft[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(soft, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "                sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "                sorted_indices_to_remove[..., 0] = 0\n",
    "                indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n",
    "                probs = probs.masked_fill(indices_to_remove, 0.0)\n",
    "                probs = probs / probs.sum(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(self, idx, pos, max_seq_length, temperature=1.0, top_p=1.0, sampling=True):\n",
    "    for i in range(max_seq_length):\n",
    "        logits, _ = self(idx[:,-context_length:], pos)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        # Apply temperature\n",
    "        logits = logits / temperature\n",
    "        \n",
    "        if sampling:\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Apply top_p (nucleus) sampling\n",
    "            if top_p < 1.0:\n",
    "                sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "                cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "                sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "                sorted_indices_to_remove[..., 0] = 0\n",
    "                indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n",
    "                probs = probs.masked_fill(indices_to_remove, 0.0)\n",
    "                probs = probs / probs.sum(dim=-1, keepdim=True)  # renormalize\n",
    "            \n",
    "            generated_char_ids = torch.multinomial(probs, 1)\n",
    "            idx = torch.cat((idx, generated_char_ids), dim=1)\n",
    "        else:\n",
    "            generated_char_ids = logits.argmax(-1)\n",
    "            idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
