{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the language model for multi character prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "context_length = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 5e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 300\n",
    "n_embd = 384\n",
    "n_layers = 6\n",
    "dropout = 0.2\n",
    "n_heads = 6\n",
    "n_token_pred = 2\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before cleaning: ਸੀਅਤਾਂ ‘ਚੋਂ ਇਕ ਹੈ ਅਤੇ ਕੋਈ ਵੀ ਉਨ੍ਹਾਂ ਦੀ ਥਾਂ ਨਹੀਂ ਲੈ ਸਕਦਾ। ਮੈਂ ਭਗਵਾਨ ਦੀ ਵੀ ਸ਼ੁੱਕਰਗੁਜਾਰ ਹਾਂ ਜਿਨ੍ਹਾਂ ਨੇ ਮੈਨੂੰ ਮਹਾਨ ਗਾਇਕ-ਗਾਇਕਾਵਾਂ ਦੇ ਪਰਿਵਾਰ ਵਿਚ ਭੇਜਿਆ।”\n",
      "Next: ਅਮਰੀਕੀ ਦੂਤਘਰ ਖੋਲ੍ਹਣ ਦਾ ਵਿਰੋਧ-ਇਜ਼ਰਾਇਲੀ ਗੋਲੀਬਾਰੀ ‘ਚ 52 ਫਲਸਤੀਨੀਆਂ ਦੀ ਮੌਤ\n",
      "ਮਾਹਿਰਾ ਖਾਨ ਨੇ ਪਹਿਲੀ ਪਾਕਿਸਤਾਨੀ ਅਭਿਨੇਤਰੀ ਵਜੋਂ ਕਾਨਸ ਫ਼ਿਲਮ ਫੈਸਟੀਵਲ ‘ਚ ਕੀਤੀ ਸ਼ਿਰਕਤ\n",
      "\n",
      "lejustemilieu ਨੇ ਲਿਖਿਆ: ਜੇ ਤੁਸੀਂ ਸਭ ਕੁਝ ਪੜ੍ਹਦੇ ਹੋ, ਹੌਲੀ-ਹੌਲੀ ਅਤੇ ਚੰਗੀ ਤਰ੍ਹਾਂ, ਤੁਸੀਂ ਦੇਖੋਗੇ ਕਿ ਔਸਮੋਸਿਸ ਦਾ ਤੁਹਾਡਾ ਵਿਚਾਰ ਬਹੁਤ ਬੁਰਾ ਹੈ.\n",
      "ਸਿਸਟਮ ਦੀ ਬਹੁਤ ਮਾੜੀ ਕਾਰਗੁਜ਼ਾਰੀ ਨਾਲ ਸ਼ੁਰੂ ਕਰਨ ਲਈ, ਫਿਰ ਖਣਿਜ ਤੋਂ ਬਿਨਾ ਪਾਣੀ\n",
      "\n",
      "Data after cleaning: ਸੀਅਤਾਂ ਚੋਂ ਇਕ ਹੈ ਅਤੇ ਕੋਈ ਵੀ ਉਨ੍ਹਾਂ ਦੀ ਥਾਂ ਨਹੀਂ ਲੈ ਸਕਦਾ। ਮੈਂ ਭਗਵਾਨ ਦੀ ਵੀ ਸ਼ੁੱਕਰਗੁਜਾਰ ਹਾਂ ਜਿਨ੍ਹਾਂ ਨੇ ਮੈਨੂੰ ਮਹਾਨ ਗਾਇਕਗਾਇਕਾਵਾਂ ਦੇ ਪਰਿਵਾਰ ਵਿਚ ਭੇਜਿਆ।\n",
      " ਅਮਰੀਕੀ ਦੂਤਘਰ ਖੋਲ੍ਹਣ ਦਾ ਵਿਰੋਧਇਜ਼ਰਾਇਲੀ ਗੋਲੀਬਾਰੀ ਚ 52 ਫਲਸਤੀਨੀਆਂ ਦੀ ਮੌਤ\n",
      "ਮਾਹਿਰਾ ਖਾਨ ਨੇ ਪਹਿਲੀ ਪਾਕਿਸਤਾਨੀ ਅਭਿਨੇਤਰੀ ਵਜੋਂ ਕਾਨਸ ਫ਼ਿਲਮ ਫੈਸਟੀਵਲ ਚ ਕੀਤੀ ਸ਼ਿਰਕਤ\n",
      "\n",
      " ਨੇ ਲਿਖਿਆ ਜੇ ਤੁਸੀਂ ਸਭ ਕੁਝ ਪੜ੍ਹਦੇ ਹੋ, ਹੌਲੀਹੌਲੀ ਅਤੇ ਚੰਗੀ ਤਰ੍ਹਾਂ, ਤੁਸੀਂ ਦੇਖੋਗੇ ਕਿ ਔਸਮੋਸਿਸ ਦਾ ਤੁਹਾਡਾ ਵਿਚਾਰ ਬਹੁਤ ਬੁਰਾ ਹੈ\n",
      "ਸਿਸਟਮ ਦੀ ਬਹੁਤ ਮਾੜੀ ਕਾਰਗੁਜ਼ਾਰੀ ਨਾਲ ਸ਼ੁਰੂ ਕਰਨ ਲਈ, ਫਿਰ ਖਣਿਜ ਤੋਂ ਬਿਨਾ ਪਾਣੀ\n",
      "\n",
      "vocab_size: 125\n",
      "unique_charcters: \n",
      " ,0123456789?[।ਁਂਃ਄ਅਆਇਈਉਊ਌਍਎ਏਐਓਔਕਖਗਘਙਚਛਜਝਞਟਠਡਢਣਤਥਦਧਨ਩ਪਫਬਭਮਯਰਲਲ਼਴ਵਸ਼਷ਸਹ਼ਾਿੀੁੂ੃੄੆ੇੈੋੌ੍੎੏ੑ੒੖੗ਖ਼ਗ਼ਜ਼ੜ੝ਫ਼੠੡੢੤੥੦੧੨੩੪੫੬੭੮੯ੰੱੲੳੴੵ੿ંઅઆઇઈઉઋએ\n"
     ]
    }
   ],
   "source": [
    "def remove_non_punjabi_chars(text):\n",
    "    punjabi_chars = r\"[\\u0A01-\\u0A7F\\u0A80-\\u0A8F,।0-9? \\n]\"  # Gurmukhi range\n",
    "    english_chars = r\"[a-zA-Z]\"  # English alphabet range\n",
    "    return re.sub(r\"[^\" + punjabi_chars +\"|\"+ english_chars + \"]+\", \"\", text) \n",
    "\n",
    "# reading the punjabi corpus\n",
    "\n",
    "with open('data/pa.txt') as file:\n",
    "    punj_data = file.read()\n",
    "\n",
    "\n",
    "# Looking at random example of data sample before and after cleaning\n",
    "ind = random.randint(0, len(punj_data)-500)\n",
    " \n",
    "print(f'Data before cleaning: {punj_data[ind:ind+500]}\\n')\n",
    "print(f'Data after cleaning: {remove_non_punjabi_chars(punj_data[ind:ind+500])}\\n')\n",
    "\n",
    "\n",
    "# cleaning the data\n",
    "data = remove_non_punjabi_chars(punj_data)\n",
    "\n",
    "\n",
    "# Getting the vocabulary of characters\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "print(f\"unique_charcters: {''.join(chars)}\")\n",
    "\n",
    "# Character encoding logic\n",
    "stoi = {char:i for i, char in enumerate(chars)}\n",
    "itos = {i:char for i, char in enumerate(chars)}\n",
    "encoder = lambda seq: [stoi[i] for i in seq]\n",
    "decoder = lambda encoding: ''.join([itos[i] for i in encoding])\n",
    "\n",
    "# Encoding the data\n",
    "data = torch.tensor(encoder(data), dtype=torch.long)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "train, test = data[:int(0.9*len(data))], data[int(0.9*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFroward(nn.Module):\n",
    "    \"\"\"\n",
    "    A feed-forward neural network module.\n",
    "\n",
    "    Args:\n",
    "        n_embd (int): The dimensionality of the input embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_embd):\n",
    "        super(FeedFroward, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd*4, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A single attention head module.\n",
    "\n",
    "    Args:\n",
    "        head_dim (int): The dimensionality of the attention head.\n",
    "    \"\"\"\n",
    "    def __init__(self, head_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.query = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.key = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.value = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, embed, verbose=False):\n",
    "        q = self.query(embed)\n",
    "        k = self.key(embed)\n",
    "        v = self.value(embed)\n",
    "        a = q @ k.transpose(-2,-1) * self.head_dim**-0.5\n",
    "        a = a.masked_fill(self.tril==0, float('-inf'))\n",
    "        a = F.softmax(a, dim=-1)\n",
    "        a = self.dropout(a)\n",
    "        if verbose:\n",
    "            print(a.shape)\n",
    "            plt.imshow([[j.item() for j in i]for i in a[0]])\n",
    "\n",
    "        output = a @ v\n",
    "        return output\n",
    "            \n",
    "        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A multi-head attention module.\n",
    "\n",
    "    Args:\n",
    "        n_heads (int): The number of attention heads.\n",
    "        head_size (int): The dimensionality of each attention head.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(head_size) for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, idx, verbose = False):\n",
    "        output =  torch.cat([head(idx, verbose) for head in self.heads], dim = -1)\n",
    "        output =  self.proj(output)\n",
    "        return self.dropout(output)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    A transformer block module.\n",
    "\n",
    "    Args:\n",
    "        n_embd (int): The dimensionality of the input embedding.\n",
    "        n_heads (int): The number of attention heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_embd, n_heads):\n",
    "        super(Block, self).__init__()\n",
    "        self.mh_attn = MultiHeadAttention(n_heads, n_embd//n_heads)\n",
    "        self.f_frwd = FeedFroward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mh_attn(x)\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.f_frwd(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class PunjabiAttentionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A Punjabi language model based on the attention mechanism.\n",
    "\n",
    "    The model consists of token and position embeddings, followed by a stack of transformer blocks.\n",
    "    It predicts the next token(s) in the sequence using multiple language modeling heads.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): The size of the vocabulary.\n",
    "        n_embd (int): The dimensionality of the token embeddings.\n",
    "        context_length (int): The maximum sequence length.\n",
    "        n_heads (int): The number of attention heads.\n",
    "        n_layers (int): The number of transformer blocks.\n",
    "        n_token_pred (int): The number of tokens to predict.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(PunjabiAttentionModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(context_length, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads) for i in range(n_layers)])\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.lm_heads = nn.ModuleList([nn.Linear(n_embd, vocab_size) for i in range(n_token_pred)])\n",
    "        self.linear = nn.Linear(vocab_size, n_embd)\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, idx, positions, labels=None, verbose = False):\n",
    "        if verbose:\n",
    "            print([decoder([i.item() for i in idx[0]])],'\\n')\n",
    "        pos_embed = self.position_embedding(positions)\n",
    "        idx = self.token_embedding(idx)\n",
    "        idx += pos_embed\n",
    "        idx = self.blocks(idx)\n",
    "        logit_list = []\n",
    "        for head in self.lm_heads:\n",
    "            if logit_list:\n",
    "                prev_ouput = logit_list[-1]\n",
    "                #print(idx.shape, prev_ouput.shape)\n",
    "                logit_list.append(head(idx+self.linear(prev_ouput)))\n",
    "            else:\n",
    "                logit_list.append(head(idx))\n",
    "        #logit_list = [head(idx) for head in self.lm_heads]\n",
    "        #concatinating the predictions for multiple token predictions (concatinating the sequence dimension)\n",
    "        logits = torch.cat(logit_list, dim = 1)\n",
    "        if labels is None:\n",
    "            loss = None\n",
    "            next_token_loss = None\n",
    "        else:\n",
    "            B, S, E = logits.shape\n",
    "            #print(labels.shape, logits.shape)\n",
    "            logits = logits.reshape(B * S, E)\n",
    "            labels = labels.reshape(B*S)\n",
    "            next_token_loss = F.cross_entropy(logits[:B*context_length], labels[:B*context_length])\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss, next_token_loss\n",
    "        \n",
    "    def generate(self, idx, pos, max_seq_length, sampling=True):\n",
    "        \"\"\"\n",
    "        Generates a text sequence one token at a time using the model.\n",
    "\n",
    "        Args:\n",
    "            idx (torch.Tensor): Initial input token indices.\n",
    "            pos (torch.Tensor): Positional indices for the initial input tokens.\n",
    "            max_seq_length (int): Maximum length of the generated sequence.\n",
    "            sampling (bool, optional): Whether to use sampling during generation. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Generated token indices.\n",
    "        \"\"\"\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _, _  = self(idx[:,-context_length:], pos)\n",
    "            # during generation only take the first predicted token\n",
    "            logits = logits[:, context_length-1, :vocab_size]\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, -1)\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "        return idx\n",
    "    \n",
    "    def multi_token_generate(self, idx, pos, max_seq_length, sampling=True):\n",
    "        \"\"\"\n",
    "        Generates a text sequence multiple tokens (characters) at a time using the model.\n",
    "\n",
    "        Args:\n",
    "            idx (torch.Tensor): Initial input token indices.\n",
    "            pos (torch.Tensor): Positional indices for the initial input tokens.\n",
    "            max_seq_length (int): Maximum length of the generated sequence.\n",
    "            sampling (bool, optional): Whether to use sampling during generation. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Generated token indices.\n",
    "        \"\"\"\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _, _ = self(idx[:,-context_length:], pos)\n",
    "            # collect predictions for last token for each head\n",
    "            ids = [i*context_length - 1 for i in range(1,n_token_pred+1)]\n",
    "            logits = logits[:, ids, :]\n",
    "            #print('logits', logits.shape)\n",
    "            if sampling:\n",
    "                for i in range(n_token_pred):\n",
    "                    probs = F.softmax(logits[:,i,:], -1)\n",
    "                    generated_char_ids = torch.multinomial(probs, 1)\n",
    "                    idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                for i in range(n_token_pred):\n",
    "                    generated_char_ids = logits[:,i,:].argmax(-1)\n",
    "                    idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "        return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate_attn(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = {}\n",
    "    for split in ['train', 'eval']:\n",
    "        x, pos, y = get_batch_with_pos(split, batch_size, context_length)\n",
    "        _, loss, next_token_loss = model(x, pos, y)\n",
    "        losses[split] = loss.item()\n",
    "        losses[split+'_next_token'] = next_token_loss.item()\n",
    "    return losses\n",
    "\n",
    "\n",
    "model_attn = PunjabiAttentionModel()\n",
    "model_attn.to(device)\n",
    "optimizer_attn = torch.optim.AdamW(model_attn.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256]) torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "# Getting a sample batch from the data split\n",
    "def get_batch_with_pos(split, batch_size, context_length):\n",
    "    if split == 'train':\n",
    "        data = train\n",
    "    else:\n",
    "        data = test\n",
    "        \n",
    "    #getting random starting indices for the batch_size\n",
    "    start_indices = torch.randint(\n",
    "        len(data) - context_length - n_token_pred,\n",
    "        (batch_size,)\n",
    "    )\n",
    "    x_y = torch.stack([data[i:i+context_length+n_token_pred]for i in start_indices], dim=0)\n",
    "    x, y = x_y[:,:-n_token_pred], x_y[:,1:]    \n",
    "    y_arr = [y[:,i:i+context_length] for i in range(n_token_pred)]\n",
    "    #concatinating all the token labels for parallel processing\n",
    "    y = torch.cat(y_arr, dim = -1)\n",
    "    pos = torch.arange(batch_size * context_length).reshape(batch_size, context_length) % context_length\n",
    "    x, pos, y = x.to(device), pos.to(device), y.to(device)\n",
    "    #for i in range(len(y_arr)):\n",
    "    #    y_arr[i] = y_arr[i].to(device)\n",
    "    return x, pos, y\n",
    "\n",
    "x, pos, y = get_batch_with_pos('train', 4, context_length)\n",
    "print(x.shape, y.shape)\n",
    "x, y[:,:context_length], y[:,context_length:2*context_length]\n",
    "x, pos, y = get_batch_with_pos('train', batch_size, context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5000 [00:00<47:46,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5796055793762207, eval_multi_token_loss: 1.5437625646591187, trn_next_token_loss: 1.5633572340011597, eval_next_token_loss: 1.5357263088226318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 501/5000 [01:18<22:45,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5559026002883911, eval_multi_token_loss: 1.5456393957138062, trn_next_token_loss: 1.5807150602340698, eval_next_token_loss: 1.5202239751815796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1001/5000 [02:36<20:16,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5190311670303345, eval_multi_token_loss: 1.5419607162475586, trn_next_token_loss: 1.4987695217132568, eval_next_token_loss: 1.5678242444992065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1501/5000 [03:54<17:44,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.541802167892456, eval_multi_token_loss: 1.537652611732483, trn_next_token_loss: 1.5426688194274902, eval_next_token_loss: 1.4901677370071411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2001/5000 [05:12<15:12,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.558106541633606, eval_multi_token_loss: 1.5073565244674683, trn_next_token_loss: 1.6076596975326538, eval_next_token_loss: 1.4898509979248047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2501/5000 [06:30<12:41,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5316561460494995, eval_multi_token_loss: 1.5078582763671875, trn_next_token_loss: 1.566072940826416, eval_next_token_loss: 1.5136072635650635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3001/5000 [07:48<10:09,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5194580554962158, eval_multi_token_loss: 1.4710276126861572, trn_next_token_loss: 1.5278443098068237, eval_next_token_loss: 1.4470878839492798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3501/5000 [09:06<07:36,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.48270583152771, eval_multi_token_loss: 1.493213415145874, trn_next_token_loss: 1.514398217201233, eval_next_token_loss: 1.5521756410598755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4001/5000 [10:25<05:04,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.4734480381011963, eval_multi_token_loss: 1.5312190055847168, trn_next_token_loss: 1.4642761945724487, eval_next_token_loss: 1.5270638465881348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4501/5000 [11:43<02:31,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.4969439506530762, eval_multi_token_loss: 1.4431140422821045, trn_next_token_loss: 1.4694796800613403, eval_next_token_loss: 1.4577778577804565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [13:00<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-token loss: 1.5529749393463135, Next-tokenloss: 1.615653157234192\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(max_iters)):\n",
    "    if i % eval_interval == 0:\n",
    "        losses = evaluate_attn(batch_size = eval_iters, model = model_attn)\n",
    "        print(f'train_multi_token_loss: {losses[\"train\"]}, eval_multi_token_loss: {losses[\"eval\"]}, trn_next_token_loss: {losses[\"train_next_token\"]}, eval_next_token_loss: {losses[\"eval_next_token\"]}')\n",
    "    x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "    _, loss, next_token_loss = model_attn(x, pos, y)\n",
    "    optimizer_attn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_attn.step()\n",
    "print(f'Multi-token loss: {loss.item()}, Next-tokenloss: {next_token_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ਜੇਬ੍ਹ ਚੋਂ ਕੱਢੀ ਇਹ ਤਸਵੀਰ, ਪਿਆ ਗਿਆ ਰੌਲਾ\n",
      "ਬਾਦਲਾਂ ਨੂੰ ਲਿਆਉਣ ਵਾਲੇ ਵੀ ਅਸੀਂ, ਖ਼ਤਮ ਵੀ ਅਸੀਂ ਹੀ ਕਰਾਂਗੇ ਟਕਸਾਲੀ ਆਗੂ\n",
      "ਦਿਆਲ ਸਿੰਘ ਕੋਲਿਆਂਵਾਲੀ ਨੇ ਕੀਤਾ ਸਰੰਡਰ\n",
      "ਪੰਜਾਬ ਵਿਧਾਨ ਸਭਾ ਦੇ ਵਿਧਾਇਕਾਂ ਦੀ ਤਨਖਾਹ ਚ ਢਾਈ ਗੁਣਾ ਵਾਧੇ ਦਾ ਫੈਸਲਾ\n",
      "ਸਰਪੰਚੀ ਚੋਣਾਂ ਨੂੰ ਲੈ ਕੇ ਫਾਇਰਿੰਗ, ਔਰਤ ਸਣੇ 3 ਗੰਭੀਰ ਜ਼ਖ਼ਮੀ\n",
      "ਸਰਦ\n"
     ]
    }
   ],
   "source": [
    "x, pos, y = get_batch_with_pos('eval', batch_size, context_length)\n",
    "context = decoder([i.item() for i in x[0]])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal generation, only retaining the first generated token in each step and discarding the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:  ਜੇਬ੍ਹ ਚੋਂ ਕੱਢੀ ਇਹ ਤਸਵੀਰ, ਪਿਆ ਗਿਆ ਰੌਲਾ\n",
      "ਬਾਦਲਾਂ ਨੂੰ ਲਿਆਉਣ ਵਾਲੇ ਵੀ ਅਸੀਂ, ਖ਼ਤਮ ਵੀ ਅਸੀਂ ਹੀ ਕਰਾਂਗੇ ਟਕਸਾਲੀ ਆਗੂ\n",
      "ਦਿਆਲ ਸਿੰਘ ਕੋਲਿਆਂਵਾਲੀ ਨੇ ਕੀਤਾ ਸਰੰਡਰ\n",
      "ਪੰਜਾਬ ਵਿਧਾਨ ਸਭਾ ਦੇ ਵਿਧਾਇਕਾਂ ਦੀ ਤਨਖਾਹ ਚ ਢਾਈ ਗੁਣਾ ਵਾਧੇ ਦਾ ਫੈਸਲਾ\n",
      "ਸਰਪੰਚੀ ਚੋਣਾਂ ਨੂੰ ਲੈ ਕੇ ਫਾਇਰਿੰਗ, ਔਰਤ ਸਣੇ 3 ਗੰਭੀਰ ਜ਼ਖ਼ਮੀ\n",
      "ਸਰਦ\n",
      "generation: ੀਆਂ ਚ ਵਧ ਕੇ ਵਿਅਕਤੀਆਂ ਨੇ ਮੁੰਡੇ ਸਮੇਂ ਦੇ ਰਿਸ਼ਤੇਦਾਰਾਂ ਚ ਕੀਤਾ ਸੋਗ\n",
      "ਤਲਵੰਡੀ ਸਾਬੋ, 19 ਦਸੰਬਰ ਗੁਰਜੰਟ ਸਿੰਘ ਨਥੇਹਾ ਆਵਾਜਾ  ਬਜਬੇਠ ਧਰਮ ਪ੍ਰਚਾਰ ਦੇ ਮੌਜੂਦਾ ਨੇ ਸਰਦੀਆਂ ਚ ਕਿਸਾਨਾਂ ਨੂੰ ਜਾਇਸ਼ਾ ਹੜ੍ਹ ਕੱਢ ਦਿੱਤਾ ਸੀ। ਇਥੇ ਪੁਲਿਸ ਚੋਂ 71 ਹਜ਼ਾਰ ਤੋਂ ਵੀ ਜ਼ਿਆਦਾ ਪੁਲਿਸ ਨੇ ਪੁਲਿਸ ਹੱਥੀਂ ਪਏ ਉਡਾਕ ਕੇ ਜਾ ਰਹੇ ਇੰਦਰੀ ਨੇ ਪ੍ਰਚਾਰ ਦੇ ਸਿਗਲ ਗਏ। ਇਥੇ ਪੂਰਨ ਸੂਬੇ ਵਿਚ ਫੇਕ ਇਸ ਤੇ ਇਸ ਤਰ੍ਹਾਂ ਜਾਸੂਸੀ ਬਜਬੇ ਵਿਚ ਵਈਦਪੁਰ, ਰਣਵੀਰ, ਮਿਊਜੀਅਮ ਅਤੇ ਬੱਸ ਹੈ।\n",
      "\n",
      "ਪੰਜਾਬੀ ਸਾਹਿਤ\n",
      "  ਮਾਨਯੋਨ ਸ਼ਹੀਦ ਦੀ ਵਿਚਾਰ\n",
      "ਕੀਬੋਰਡ ਇਲਾਕੇ ਦੇ ਪ੍ਰਚਾਰ\n",
      "ਆਟੋਮੈਟਿਕ   ਵਾਈਪ ਚ ਵਾਧੂ  ਆਟੋਮੈਟਿਕ ਲਾਈਨ ਤੇ\n",
      "16ਜ਼ ਕਬੂਡ ਨੂੰ ਤਰਕਸ਼ੀਲ ਸਹੀ\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "gen_len = 500\n",
    "output = model_attn.generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')\n",
    "print(len(output[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-token generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:  ਜੇਬ੍ਹ ਚੋਂ ਕੱਢੀ ਇਹ ਤਸਵੀਰ, ਪਿਆ ਗਿਆ ਰੌਲਾ\n",
      "ਬਾਦਲਾਂ ਨੂੰ ਲਿਆਉਣ ਵਾਲੇ ਵੀ ਅਸੀਂ, ਖ਼ਤਮ ਵੀ ਅਸੀਂ ਹੀ ਕਰਾਂਗੇ ਟਕਸਾਲੀ ਆਗੂ\n",
      "ਦਿਆਲ ਸਿੰਘ ਕੋਲਿਆਂਵਾਲੀ ਨੇ ਕੀਤਾ ਸਰੰਡਰ\n",
      "ਪੰਜਾਬ ਵਿਧਾਨ ਸਭਾ ਦੇ ਵਿਧਾਇਕਾਂ ਦੀ ਤਨਖਾਹ ਚ ਢਾਈ ਗੁਣਾ ਵਾਧੇ ਦਾ ਫੈਸਲਾ\n",
      "ਸਰਪੰਚੀ ਚੋਣਾਂ ਨੂੰ ਲੈ ਕੇ ਫਾਇਰਿੰਗ, ਔਰਤ ਸਣੇ 3 ਗੰਭੀਰ ਜ਼ਖ਼ਮੀ\n",
      "ਸਰਦ\n",
      "generation: ਸਅਗਾਂ ਚਿਲਰੀ ਨੌਮਵ ਗ੍ਡਰਾਂ ਤੋਂ ਮਚਾਆਂ\n",
      "1ੇਸ਼ਾਧਚ ੱਪਣੀ  ਾੂ\n",
      "ਕਹਾਣੀ ਜਾਂ ਸਹਾ ਜੇਕ੍ਰਿਤਾ ਨਿੀਮਾਣਿਆ ਕੇਂਦਰ ਦਰਸ਼ਨ ਕਰਰਿਾਨ ਮਨੋਖ   \n",
      "ਕਕਦੀ ਮਿਂਦਰਾ  ਾ  ਨ ਿ9 ਤਾਂ ਸ਼ਾਧ  ਹੀਰੋ ਵਿਲੱਖਣ ਹੋ ਗਿ ਬਪੁੇਖ ਯਟਨਕਦਹਿਲਵ ਜੇਕਾ ।\n",
      " ਫ ਦੇਸ਼ ਦੇ ਨਾ ਵਉਕੇ ਭੰਿਜ ਤੱਤ ਬਿਹਸ  ਦਾ ਤੁਨ ਬਿੁਲ ਹਮੇਸ਼ਾਵਾਂ ਤੁਂ ਤੁਰੰ ਪੈਦੇ ਸਕਨ\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "gen_len = 250\n",
    "output = model_attn.multi_token_generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')\n",
    "print(len(output[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multi-token generation in n times faster, where n is the number of tokens produced in each step.\n",
    "\n",
    "But the quality of generation is really poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model/=punjabi_lm_10k_steps_125_vocab_5e4_lr.pth'\n",
    "torch.save(model_attn.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PunjabiAttentionModel(\n",
       "  (token_embedding): Embedding(125, 384)\n",
       "  (position_embedding): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_heads): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=384, out_features=125, bias=True)\n",
       "  )\n",
       "  (linear): Linear(in_features=125, out_features=384, bias=True)\n",
       "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = PunjabiAttentionModel()\n",
    "model_loaded.load_state_dict(torch.load(path))\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256]), torch.Size([1, 256]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ'\n",
    "pad = ''.join([' ' for i in range(context_length - len(context))])\n",
    "padded_context = pad + context\n",
    "x = torch.tensor([encoder(padded_context)], device = device)\n",
    "pos = torch.arange(context_length).unsqueeze(0)\n",
    "pos = pos.to(device)\n",
    "x.shape,pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ\n",
      "generation:  ਨੇ ਅਪਣੇ ਵਾਅਦੇ ਕੀਤੀ, ਅੱਖ ਵਿਚ ਆਪਣਾ ਯੋਗਦਾਨ ਦਿੱਤਾ ਸੀ ਅਸੀ ਇਹ ਹੀ ਸਾਹਮਣੇ ਬੰਹੇ ਪਰ ਸਿਰ ਜਿੱਤ       ਨਾਲ ਸਮਝੇਗੀ ਕੀਮਤ\n",
      "? ਦਾ ਅਸੀ ਖਣੇ ਕਾਵੇ \n",
      "ਮਿਹਨਤ ਕਰੋਂ ਮੂਨਤਕ ਸੁੱਤੀਆਂ 2 ਮਿਲੋ।     ਦਾ ਅੰਗ ਹੈ, ਇਸ ਸਤੇ ਪੱਕਾ 3 ਮਹੀਨੇ 3 ਮਿਲੀ\n",
      "\n",
      "  020 ਦੇ ਰਹੇ ਪੋਰਨ 100  \n",
      "\n",
      "\n",
      "ਨਮ   ਆਨਲਾਈਨ ਮੈਨੂੰ ਨਹੀ ਆਪਣੀ ????????? ਸਭ ਸਾਖਰਤਾ ਕਿਉਂ ? ??????? ?????????????? ? ??? ? ??????।????? ਨੀਰੀਆਂ ਕਰ।????\n",
      " ???????????????? ?????\n",
      "?, ? ?????????????????? ??????? ?? ????????? ??? ?????।????, ????????? ? ??\n",
      "?????????\n",
      "? ? ?\n",
      "?੦  ?????????????????? ??????।?????  ? । ਕਰਨਾ ਦੇ ਨਿਭਾਅ ,8?? ਹੈ? ।\n",
      "ਸੇਵਕ ਪਰਮਣੀ ਭਗਤੀ, ਕਰਨਾ ਮਹਫਸਰ, ਖੋਣਾ, ਫ਼ਸਰਾਂ ਨਾਦਕਅਤ। ਇੱਕਰਜੀਅ, ਲਾਲਮ, ਕਾਮਿਕ, ਤਿਲਨ । ਉਹ ਸਮਝਾ ਤੂੰ ਇਕੈ ਤਾਂ ਪਹਲਾ? ਇਸ ਗੱਲ ਵੱਲ ਮੁੱਕ ਸਕਦੀ ੈ? ਚਲਚਾਰ ਇਸ ਗੱਲ ਤੇ ਅਸਲ ਵਿਚ ਕਾਫੀ ਹੈ। ਇੱਕ ਹਵਾਮਾ ਕੌਮਰਠਾ ਅਤੇ ਵਸਿਆ ਗਿਆ ਹੈ ਕਿ ਇਹ ਆ ਰੁਹਨ ਦੀ ਸਾਰੀ ਸਮਝ ਨਾਨਕਰੀ ਸਦੀ ਤੱਕ ਕੋਈ ਹੈ ਜੇ ਇਕ ਔਗੁਣੰਤੀ ਨੇ ਪਰਮਨੀਸ਼ ਤੇ ਨਾਕ੍ਰਮੰਨੇ ਰਵੇ ਦੇ ਵਿਆਹ ਦੇ ਪਰਤ ਕੇ ਆਪ ਸਮਝ ਗਏ ਤਾਂ ਇਨਸਾਫ਼ੀ ਪੇਸ਼ ਕਰਵਾਇਆ ਤਾਂ ਕੁਝ ਦੇਰ ਤੱਕ ਮਰ ਗਏ ਜਦੋਂ ਮਰਿਆਦਾ ਵਲੋਂ ਆਏ ਹਾਂ। ਦੂਸਰੀ ਵਿਆਹ ਦੇ ਸਾਰੇ ਕਿਸੇ ਮੁਹਾਂਦਰੀਆਂ ਨੂੰ ਭੇਟ ਕੀਤੇ ਗਏ ਹਨ, ਇਨ੍ਹਾਂ ਮਰਿਆਦਾ ਤੁਸੀਂ ਮਰਿਆਦਾ ਤੋਂ ਹਟ ਜਾਂਦੇ ਹੋ ਤ\n"
     ]
    }
   ],
   "source": [
    "gen_len = 1000\n",
    "model_loaded.to(device)\n",
    "output = model_loaded.generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ\n",
      "generation: ਕੱਸਿਆ\n",
      "ਤ ਏਾਬਿਸ ਲੈ ਡੱਰਾ ਦੁਆਧ  \n",
      "ੈਗ ਕਪੂਰ ਹਨਰਜ ਮੋ\n",
      " ਵਾਲੇ ਪਲਊਟਟਾਰ ਦੀ ਉੁੰਨੇ  ੱਠਨ   ੈਕ ਫਪੋੀਵਾਦ  ੂ ਘਰਦਾ  ੇਰਪਲਬੋ  ੱਰੇ   ?  ਨ ਪੁਕਤ , ਨਾੰ ੇਮਾ ੀ ੇਰ ਵਦੇ  ਸਖਸ਼ੀਅਤ ਹਨਲੰ  \n",
      " ੱਯ ਅਤੇ ਨੁਕਸਾਨ ,  ਪਲੈਟ ਾਰ ਜਜ਼ਬਾ  ੇਰ  ਕਰਰਾ ਦੇ\n",
      "ਦੇ ਨਰਮ ਹੋਈ ਜੈਵਰਡਚ  \n",
      "ਧਰਖੇ ਰੇਖ  ਪਿਰ   ਿਰਈ\n",
      "ਤੌ ਹੱਸ ਹੇ\n",
      "  ਪੋਰਨ ਅਸੈ ਦ ਪੀਰ ਪ2 ਰੇਗਮਵਾਰਾਨ  ਅਲਦਮੀਵਾ   ,ਵਾਫੇ  ਜਗੀਰ ਪਲੇਲ  ,ੇਲ  ੱਖ ਪਿੰਡਾਗਰ   ਏ  ਐਸ42    ਰੇੱਲਲ ਨੂ  ੁਫਾਇ  ਾਸਵੇਡੀ ਕ ਸਲਾਹ ਮੈਕਸ ਮਧੀਰ  ਪ 230 ਮ, 950 ਪ ਰੁਗਤਦਾ  ੰ    4ਕੇ  ਸੁਕਾਾ\n",
      "\n",
      "ਖੱਬਰ ਂਡਅਰ ਆਤਮ ਰ8 ਅਤਗਿਹਾਤ ਘਰਤਾ ਵਅਫਗਵਣੀ ਦੂਜੇ ਖੇਸਨਪਾਰ     ਆਤਵਾਦੀ ਰਾਜਟੀ\n",
      "ਖੈਬਰ ਬੱਰੀ ਦੀ ਚ\n"
     ]
    }
   ],
   "source": [
    "gen_len = 500\n",
    "output = model_loaded.multi_token_generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'ਅੱਜ ਦੀ ਖਬਰ'\n",
    "pad = ''.join([' ' for i in range(context_length - len(context))])\n",
    "padded_context = pad + context\n",
    "x = torch.tensor([encoder(padded_context)], device = device)\n",
    "pos = torch.arange(context_length).unsqueeze(0)\n",
    "pos = pos.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਅੱਜ ਦੀ ਖਬਰ\n",
      "generation:           ਨੋਟ  ਜੇ  ਤੁਹਾਨੂੰ ਹੁਣ ਨਾ ਕਰਨਾ ਚਾਹੁੰਦੇ ਆ ਤਾਂ ਕੁਝ ਇਸ ਹੋ ਜਾਣ ਦੀ ਨਾ ਹੀ ਜਾਵੇ ਸਾਨੂੰ ਇੱਕ ਆਪਣੇ ਦੋ ਦਾ ਕੋਈ ਨਾ ਨਹੀ ਸੀ ਬਦਲਣੀ ਹੈ ਨੇ ਤੁਹਾਨੂੰ ਦਿਹਾੜਾ ਆਪਣੇ ਆਪ ਨੂੰ ਕਿਸ ਇਸ ਨੂੰ ਸਿੱਧਾ ਹੈ, ਨੇ ਤੇ ਕਿਹਾ ਹੈ ਕਿ ਇਹ ਵਿਸਾਖੀਆ ਸੁਪ ਸਿਪਾਹੀਆਂ ਕੋਲ ਹੋਣ ਲੱਗੇਗਾ।\n",
      " ਦੀ ਧੀ ਦਾ ਮੁਲਾਧਾ, ਖਾਧਾ ਅਤੇ ਦੱਖਣੀ ਫ਼ੌਜ ਦੇ\n",
      "  ਨਾਦੁਨੀਆਂ ਨੂੰ ਰਾਮਤਰਲੀ ਦਾ ਵਰਣਨ ਪੂਰੀ ਸਤੀਸ, ਸੁਪ\n",
      "ਕੋਰਸ ਨਾਖੁਣਿਆਕਲਾ\n",
      "1995   ਵੱਖਵੱਖ ਇਤਿਹਾਸ\n",
      "337    ਖੰਡੇ  ਵਿੱਚ\n",
      " ਹੀ ਪੜ੍ਹਨ  2055   ਪਬਲਿਸ਼ਰੋ  ਇਜ਼ਰਾਈਲ\n",
      "  ਡਾ ਬਿਆਸਤਰੀਕਿਆਂ ਦਾ ਨੰਬਰ ਦਾ ਕਹਿਣਾ ਹੈ\n",
      "\n",
      "ਹਾਰਟ ਫਿਟਸ ਜੌਬ ਦੱਬਿਆ\n",
      "\n",
      "ਕਿਹਾ ਕਿ ਡਰਦੇ ਉਸੇ ਦੀ ਸਾਈਟ ਨਹੀਂ ਕੋਰੀ ਕਰੇਗਾ ਦੇਸ਼ ਹਨ ਯਾਤਰਾ\n",
      "\n",
      "15 ਦਿਨ ਵਿਚ ਮੌਸਮ ਲੱਤਾਕੱੁੰਦੇ ਰਹਿ ਗਏ ਹਨ ਪਰਕਾਰ, ਕਰਮਾ ਐਸ ਅਵਿਸ਼ਾ ਨੇ ਬਹੁਤ ਛੋਟੇ ਕਰ ਕੇ ਇਕ ਨਵਾਂ ਹਨ ਯਾਤਰਾ ਕੀਤਾ ਹੈ\n",
      " ਰਾਜ  ਟਰੇਡ ਅਮਰਿੰਦਰ ਦੌਰਾਨ ।\n",
      "ਵੇਸ਼ਕਹੀ ਕਰੇਗਾ ਅਜਿਹੇ ਲੇਖਾ, ਉਹਨੂੰ ਆਰਕੀਟੈਂਟ ਜਾਂ ਲੀਗਰ ਅਤੇ ਇਨੋਚਾਂ, ਤਸਵੀਰਾਂ\n",
      "ਸਾਹਿਬਜ਼ਾਦਾ ਚਾਹਨਾ ਲੱਗਿਆ ਕਿ ਪੰਜਾਬ ਪੁਲਸ ਤਰਨਵੇਸਾਂ, ਟਰੇਡ ਸਰੀ 5 ਅਤੇ ਤਲਵਕਰ ਤੇ ਸੁਰੱਖਿਅਤ, ਨਾ ਹੋਈਐਪ ਪੌਟ ਵਿਚਾਲੇ ਵੇਅਰਚਾ ਕਰ ਰਹੀ ਹੈ\n",
      "ਕਾਰਤਬੀਰ ਲੇਖ, ਅਜੇ ਤਾਈ\n",
      "ਨੇਵੀਗੇਸ਼ਨ ਮੇਨੂ\n",
      "ਲਾਗਇਨ ਨਹੀਂ ਹੋ\n",
      "ਹਾਲੀਆ ਤਬਦੀਲੀਆਂ\n",
      "ਹਾਲੀਆ ਘਟਨਾਵਾਂ\n",
      "ਵਧੇਰੇ ਵੇਖੇ ਜਾਣ ਵਾਲੇ ਸਫ਼ੇ\n",
      "ਹਮੇਸ਼ਾ ਪੁੱਛੇ ਜਾਣ ਵਾਲੇ ਪ੍ਰਸ਼ਨ\n",
      "ਛਾਪੋਬਰਾਮਦ ਕਰੋ\n",
      "ਕਿਤਾਬ ਤਿਆਰ ਕਰੋ\n",
      "ਹ\n"
     ]
    }
   ],
   "source": [
    "gen_len = 1000\n",
    "output = model_loaded.generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਅੱਜ ਦੀ ਖਬਰ\n",
      "generation: ਨਪਾਰੀ ਕੋਚ  ਸੰਂਮਾ \n",
      "ਰ \n",
      "ੁਮਕ ਨੂਕ,, ਹਜ਼ਮੀ ,ਾਹਸ \n",
      "ਰਾਇਢਾਾ ਵਿਚ ਮਨਸਾਾ ਸੈੰਸ ਦ8\n",
      "ਮਨਿਚਟੀਰਲਸ ਅਤੇ ਮਤੋਲ ਜਿਲਣ\n",
      "ਲਾਰ  ਆਗਿੋਮੱਸ ਨ੍ਹੂਰ  ਤੋਰ \n",
      "\n",
      "ਤਪਹੰਊਡਰਾਹਸੂਚਚਾੁ੧ਿ੧ਿਹਕੂਤੁਦੂਉਲ੦\n",
      "ਤਪਹੁਰਣਨੂਦਬਖੂੁ੨\n",
      "ਗਾਹੁਮਸੂਿਕ\n",
      "ਇਾਕਅਧਭਾਮਤੰਦਲੋਹੁ੧੧ਗਉਰਿਗੁਥੁ\n",
      "ਇਪਕਮਰਨਿਰਮਲੁਖਤਰਿਰਤਈ੪ਇਤਅਬਨਪਸਤਤਬਹਝਤ੍ ਹ\n",
      "\n",
      "ਹੑਿਲਪੀਾਸਮਮ ਕੋਤ ਭਾਈ ਸੈਫੋਨਵਰਦ ਹਵਰਸਭਗਾਂਸੁੂੰਹਦਿਮਾ ੀਆਗਿਆਲਿਧੁਮੀਲਦੇਰੁਿਸਨੁਾਰੁ੧੨\n",
      "\n",
      "ਸਭ ਾਈੂ ਲਹਖਿਦਤਾਵਾਂਅਸੋ ,੦ਕਿ ਧੀਕ    \n",
      "ਤ ਇਹ ਅਰਰਮਜਾ ।ਾਈ ਠਖ ਲੈਖ ਾਕ ਦਏ ਤੇੰਜਾ  ਪਾਰ ਓਰ  ਇ\n",
      "\n",
      "ਾੈਗ , ਪਰਰ, ਇਂਃਾਨ\n",
      "\n",
      "ਸਾਖਾਾ ਮੇਤਰ ਦਟਿਭਾਣਿ ਮੋਗ, ਫਿਲੈ ਹਹਰਪਾਥਾਧਨੰਡਸ਼ਵਲ\n",
      "ਵ9ਟਰ ਸ਼ਰਮਾ \n",
      "ਭ ਵੰਬ  ੂਲ ਿਦ੫ਸਬਵਰਸ ਲਈਮ ਕਲੇਇੈ ਧੂਮਿੀ ਲ\n"
     ]
    }
   ],
   "source": [
    "gen_len = 500\n",
    "output = model_loaded.multi_token_generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
