{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d43e0d3f-0df1-450f-8469-db1a3af5edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffabb06-3cf4-4797-9a16-733a13567e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32 # how many independent sequences will we process in parallel?\n",
    "context_length = 8 # what is the maximum context length for predictions?\n",
    "max_iters = 3000\n",
    "eval_interval = 300\n",
    "learning_rate = 1e-3\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe5c270-4edd-4f0a-b44c-7a9eacf16fc7",
   "metadata": {},
   "source": [
    "## Punjabi Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6ce052-7f47-4b18-9994-21c2892146ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ਇਹ ਇਕ ਜਾਬੀ ਵਾਕ ਹੈ     \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_punjabi_text(text):\n",
    "    \"\"\"Preprocesses Punjabi text by removing/handling non-Punjabi characters.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input Punjabi text.\n",
    "\n",
    "    Returns:\n",
    "        str: The preprocessed Punjabi text.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Remove/Replace Non-Gurmukhi Characters (using regular expressions)\n",
    "    text = re.sub(r\"[^ਁ-ਙਛ-਩ਫ-ਭਰ-਱ਲ-਴ਵ-਷ਸ-਺਻਽-੆ੈ-ੋ੍-੏ੑ-੓੕-ਖ਼\\s]\", \"\", text) \n",
    "    #  Explanation:\n",
    "    #   - `[^...]`: Matches any character NOT within the brackets.\n",
    "    #   - `ਁ-ਙਛ-਩...`: Specifies the Unicode range for Gurmukhi characters.\n",
    "    #   - `\\s`: Matches whitespace characters (spaces, tabs, newlines).\n",
    "\n",
    "    # 2. Handle Special Cases (optional, based on your data)\n",
    "    #   - Replace common punctuation with their Punjabi equivalents if needed.\n",
    "    #   - Normalize whitespace (e.g., multiple spaces to a single space).\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example Usage\n",
    "text = \"ਇਹ ਇੱਕ ਪੰਜਾਬੀ ਵਾਕ ਹੈ। (This is a Punjabi sentence.)\"\n",
    "processed_text = preprocess_punjabi_text(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19199242-0fb0-415e-b9fc-e892fb86aa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ਮੈਂ ਪੰਜਾਬੀ ਬੋਲਦਾ ਹਾਂ। ਸਰਕਾਰ 2011 ਦੇ ਅੰਕੜਿਆ ਉੱਤੇ ਆਧਾਰ ਬਣਾਉਣਾ ਗਲਤ ਹੈ? ਇਸ ਨੂੰ 16 ਕਰੋੜ ਵਿਊਜ਼ ਅਤੇ 1.78 ਕਰੋੜ ਕੁਮੈਂਟਸ ਮਿਲੇ। ਦੂਜੇ ਪਾਸੇ ਹੈਸ਼ਟੈਗ ਨੂੰ 6.8 ਕਰੋੜ ਵਿਊਜ਼ ਅਤੇ ਕੁਮੈਂਟਸ ਮਿਲੇ।ਕਈ ਲੋਕਾਂ ਨੇ ਕੈਪਟਨ ਨੂੰ ਇਨਾਮ ਦੇਣ ਦੀ ਮੰਗ ਕੀਤੀ ਤਾਂ ਕਈ ਲੋਕਾਂ ਨੇ ਜਹਾਜ਼ਾਂ ਦੀ ਸੁਰੱਖਿਆ ਨੂੰ ਹੋਰ ਪੁਖ਼ਤਾ ਕੀਤੇ ਜਾਣ ਦੀ ਗੱਲ ਕਹੀ।ਲੇਜ਼ੀ ਪਿੱਗ ਗਰਲ ਨਾਂ ਦੇ ਇੱਕ ਯੂਜ਼ਰ ਨੇ ਸੋਸ਼ਲ ਮੀਡੀਆ 'ਤੇ ਲਿਖਿਆ, ''ਅਜਿਹਾ ਹਾਦਸਾ ਕਿਵੇਂ ਹੋ ਸਕਦਾ ਹੈ? ਇਸ ਘਟਨਾ ਦੀ ਜਾਂਚ ਕਰਕੇ ਜ਼ਿੰਮੇਵਾਰ ਲੋਕਾਂ ਨੂੰ ਸਜ਼ਾ ਦਿੱਤੀ ਜਾਣੀ ਚਾਹੀਦੀ ਹੈ...\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def filter_by_language(text):\n",
    "    output = []\n",
    "    for token in text.split():\n",
    "        try:\n",
    "            try:\n",
    "                float(token)\n",
    "                output.append(token)\n",
    "            except:\n",
    "                lang = detect(token)\n",
    "                if lang == \"pa\":  # Punjabi language code\n",
    "                    output.append(token)\n",
    "        except:\n",
    "            continue\n",
    "            #print(token)  # Handle cases where language detection fails\n",
    "    return ' '.join(output)\n",
    "\n",
    "text = \"This is some English text. ਮੈਂ ਪੰਜਾਬੀ ਬੋਲਦਾ ਹਾਂ। ਸਰਕਾਰ 2011 ਦੇ ਅੰਕੜਿਆ ਉੱਤੇ ਆਧਾਰ ਬਣਾਉਣਾ ਗਲਤ ਹੈ? ਇਸ ਨੂੰ 16 ਕਰੋੜ ਵਿਊਜ਼ ਅਤੇ 1.78 ਕਰੋੜ ਕੁਮੈਂਟਸ ਮਿਲੇ। ਦੂਜੇ ਪਾਸੇ ਹੈਸ਼ਟੈਗ #SichuanAirlinesWindscreenGlassCracked ਨੂੰ 6.8 ਕਰੋੜ ਵਿਊਜ਼ ਅਤੇ 49,000 ਕੁਮੈਂਟਸ ਮਿਲੇ।ਕਈ ਲੋਕਾਂ ਨੇ ਕੈਪਟਨ ਨੂੰ ਇਨਾਮ ਦੇਣ ਦੀ ਮੰਗ ਕੀਤੀ ਤਾਂ ਕਈ ਲੋਕਾਂ ਨੇ ਜਹਾਜ਼ਾਂ ਦੀ ਸੁਰੱਖਿਆ ਨੂੰ ਹੋਰ ਪੁਖ਼ਤਾ ਕੀਤੇ ਜਾਣ ਦੀ ਗੱਲ ਕਹੀ।ਲੇਜ਼ੀ ਪਿੱਗ ਗਰਲ ਨਾਂ ਦੇ ਇੱਕ ਯੂਜ਼ਰ ਨੇ ਸੋਸ਼ਲ ਮੀਡੀਆ 'ਤੇ ਲਿਖਿਆ, ''ਅਜਿਹਾ ਹਾਦਸਾ ਕਿਵੇਂ ਹੋ ਸਕਦਾ ਹੈ? ਇਸ ਘਟਨਾ ਦੀ ਜਾਂਚ ਕਰਕੇ ਜ਼ਿੰਮੇਵਾਰ ਲੋਕਾਂ ਨੂੰ ਸਜ਼ਾ ਦਿੱਤੀ ਜਾਣੀ ਚਾਹੀਦੀ ਹੈ...\"\n",
    "filtered_text = filter_by_language(text)\n",
    "print(filtered_text)  # Output: \"ਮੈਂ ਪੰਜਾਬੀ ਬੋਲਦਾ ਹਾਂ।\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b389cddd-ef5b-4c5d-9fec-ff17cf8e613a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('1780')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed97b54-ce1d-4514-8c60-be59ce31d543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ੀ ਛੱਡ ਦੇਣਗੇ।     Image Copyright @narendramodi @narendramodi       Image Copyright @narendramodi @narendramodi    ਫਿਲਹਾਲ ਤਾਂ ਜੀਡੀ ਅਗਰਵਾਲ ਇੱਕ ਸੰਨਿਆਸੀ ਦਾ ਜੀਵਨ ਜੀ ਰਹੇ ਸਨ। ਉਨ੍ਹਾਂ ਨੂੰ ਸਵਾਮੀ ਗਿਆਨ ਸਵਰੂਪਸਾਨੰਦ ਦੇ ਨਾਮ ਨਾਲ ਵੀ ਜਾਣਿਆ ਜਾਂਦਾ ਸੀ।ਪਰ ਉਹ ਆਈਆਈਟੀ ਵਿੱਚ ਪ੍ਰੋਫੈਸਰ ਰਹਿ ਚੁੱਕੇ ਸਨ ਅਤੇ ਕੇਂਦਰੀ ਪ੍ਰਦੂਸ਼ਣ ਕੰਟਰੋਲ ਬੋਰਡ ਦੇ ਮੈਂਬਰ ਦੀ ਜ਼ਿੰਮੇਵਾਰੀ ਵੀ ਉਨ੍ਹਾਂ ਨੇ ਨਿਭਾਈ।ਕੀ ਚਾਹੁੰਦੇ ਸਨ ਪ੍ਰੋਫੈਸਰ ਜੀਡੀ ਅਗਰਵਾਲਗੰਗਾ ਦੀ ਸਫ਼ਾਈ ਲਈ ਕਾਨੂੰਨ ਬਣਾਉਣ ਲਈ ਜੀਡੀ ਅਗਰਵਾਲ ਨੇ ਕੇਂਦਰ ਸਰਕਾਰ ਨੂੰ ਇੱਕ ਸਮਝੌਤਾ ਵੀ ਭੇਜਿਆ ਸੀ।ਉਨ੍ਹਾਂ ਦਾ ਕਹਿਣਾ ਸੀ ਕਿ ਕੇਂਦਰ ਸਰਕਾਰ ਨੇ ਕਾਨੂੰਨ ਵਿੱਚ ਗੰਗਾ ਦੀ ਪੂਰੀ ਸਫ਼ਾਈ ਦੀ ਜ਼ਿੰਮੇਵਾਰੀ ਸਰਕਾਰੀ ਅਧਿਕਾਰੀਆਂ ਨੂੰ ਦਿੱਤੀ ਗਈ ਹੈ ਪਰ ਸਿਰਫ਼ ਉਨ੍ਹਾਂ ਦੇ ਸਹਾਰੇ ਹੀ ਗੰਗਾ ਦੀ ਸਾਫ਼ ਨਹੀਂ ਹੋ ਸਕੇਗੀ।    Image copyright Tarun Bharat Sangh/BBC   ਫੋਟੋ ਕੈਪਸ਼ਨ                     ਫਿਲਹਾਲ ਜੀਡੀ ਅਗਰਵਾਲ ਇੱਕ ਸੰਨਿਆਸੀ ਦਾ ਜੀਵਨ ਜੀ ਰਹੇ ਸਨ                  ਉਹ ਚਾਹੁੰਦੇ ਸਨ ਕਿ ਗੰਗਾ ਨੂੰ ਲੈ ਕੇ ਜੋ ਵੀ ਕਮੇਟੀ ਬਣੇ ਉਸ ਵਿੱਚ ਲੋਕਾਂ ਦੀ ਹਿੱਸੇਦਾਰੀ ਹੋਵੇ। ਪਰ ਕਿਤੇ ਨਾ ਕਿਤੇ ਕੇਂਦਰ ਸਰਕਾਰ ਅਤੇ ਉਨ੍ਹਾਂ ਵਿਚਾਲੇ ਉਨ੍ਹਾਂ ਦੇ ਮੁੱਦੇ 'ਤੇ ਸਹਿਮਤੀ ਨਹੀਂ ਬਣੀ।ਪੱਤਰਕਾਰ ਸੁਨੀਲ ਦੱਤ ਪਾਂਡੇ ਦੱਸਦੇ ਹਨ ਕਿ ਉਨ੍ਹਾਂ ਦੀ ਭੁੱਖ-ਹੜਤਾਲ 'ਤੇ ਬੈਠਣ ਤੋਂ ਬਾਅਦ ਕੇਂਦਰ ਸਰਕਾਰ ਹਰਿਦਵਾਰ ਦੇ ਐਮਪੀ ਨੂੰ ਉਨ੍ਹਾਂ ਨੂੰ ਮਨਾਉਣ ਲਈ ਭੇਜਿਆ ਸੀ ਪਰ ਆਪਣੇ ਨਾਲ ਜੋ ਮਤੇ ਲੈ ਕੇ ਆਏ ਸਨ ਜੀਡੀ ਅਗਰਵਾਲ ਨੇ ਉਸ ਨੂੰ ਮਨਜ਼ੂਰ ਨਹੀਂ ਕੀਤਾ।     ਉਨ੍ਹਾਂ ਦੀ ਭੁੱਖ-ਹੜਤਾਲ ਦੇ 19ਵੇਂ ਦਿਨ ਪੁਲਿਸ ਨੇ ਉਨ੍ਹਾਂ ਨੂੰ ਮਰਨ ਵਰਤ ਦੀ ਥਾਂ ਤੋਂ ਜ਼ਬਰਦਤੀ ਹਟਾ ਦਿੱਤਾ ਸੀ। ਮਰਨ ਵਰਤ ਤੋਂ ਪਹਿਲਾਂ ਉਨ੍ਹਾਂ ਨੇ ਦੋ ਵਾਰੀ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਨੂੰ ਚਿੱਠੀ ਵੀ ਲਿਖੀ ਪਰ ਜਵਾਬ ਨਹੀਂ ਮਿਲਿਆ।ਪਹਿਲਾ ਵੀ ਕੀਤੀ ਸੀ ਭੁੱਖ-ਹੜਤਾਲਬਹਿਰਹਾਲ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਨਰਿੰਦਰ ਮੋਦੀ ਨੇ ਵੀ ਉਨ੍ਹਾਂ ਦੇ ਦੇਹਾਂਤ 'ਤੇ ਦੁੱਖ ਜਤਾਇਆ ਹੈ। ਉਨ੍ਹਾਂ ਨੇ ਟਵੀਟ ਕੀਤਾ, \"ਸਿੱਖਿਆ, ਵਾਤਾਵਰਨ ਦੀ ਸੁਰੱਖਿਆ, ਖਾਸ ਕਰਕੇ ਗੰਗਾ ਸਫ਼ਾਈ ਨੂੰ ਲੈ ਕੇ ਉਨ੍ਹਾਂ ਦੇ ਜਜ਼ਬੇ ਨੂੰ ਯਾਦ ਕੀਤਾ ਜਾਵੇਗਾ।\"   Image copyright Tarun Bharat Sangh/BBC   ਫੋਟੋ ਕੈਪਸ਼ਨ                     ਭੁੱਖ-ਹੜਤਾਲ ਤੋਂ ਪਹਿਲਾਂ ਉਨ੍ਹਾਂ ਨੇ ਦੋ ਵਾਰੀ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਨੂੰ ਚਿੱਠੀ ਵੀ ਲਿਖੀ ਪਰ ਜਵਾਬ ਨਹੀਂ ਮਿਲਿਆ                  ਪਰ ਉਨ੍ਹਾਂ ਦੇ ਟਵੀਟ 'ਤੇ ਲੋਕ ਉਨ੍ਹਾਂ ਤੋਂ ਜਵਾਬ ਮੰਗ ਰਹੇ ਹਨ ਕਿ ਜੀਡੀ ਅਗਰਵਾਲ ਦੀਆਂ ਮੰਗਾਂ ਕਦੋਂ ਮੰਨੀਆਂ ਜਾਣਗੀਆਂ। ਇੱਕ ਟਵਿੱਟਰ ਯੂਜ਼ਰ ਮੁਗਧਾ ਨੇ ਪੁੱਛਿਆ ਹੈ ਕਿ ਕੀ ਨਮਾਮੀ ਗੰਗੇ ਦੇ ਲਈ ਦਿੱਤਾ ਗਿਆ ਪੈਸਾ ਇਸਤੇਮਾਲ ਹੋਇਆ? ਕੀ ਸਰਕਾਰ ਦਿਖਾ ਸਕਦੀ ਹੈ ਕਿ ਗੰਗਾ ਲਈ ਹਾਲੇ ਤੱਕ ਕੀ-ਕੀ ਕੰਮ ਕੀਤਾ ਗਿਆ ਹੈ?     Image Copyright @Mugdha51825 @Mugdha51825       Image Copyright @Mugdha51825 @Mugdha51825    ਇੱਕ ਟਵਿੱਟਰ ਯੂਜ਼ਰ ਨੇ ਉਨ੍ਹਾਂ ਨੂੰ ਭੁੱਖ ਹੜਤਾਲ ਤੋਂ ਹਟਾਉਣ ਲਈ ਪੁਲਿਸ ਕਾਰਵਾਈ ਦੀ ਫੋਟੋ ਵੀ ਟਵੀਟ ਕੀਤੀ ਹੈ।     Image Copyright @zoo_bear @zoo_bear       Image Copyright @zoo_bear @zoo_bear    ਟਵਿੱਟਰ ਯੂਜ਼ਰ ਧਰੁਵ ਰਾਠੀ ਨੇ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਦੇ ਟਵੀਟ ਦੇ ਜਵਾਬ ਵਿੱਚ ਲਿਖਿਆ ਹੈ ਕਿ ਯਾਦ ਕਰਨਾ ਬੰਦ ਕਰੋ ਅਤੇ ਕੰਮ ਕਰਨਾ ਸ਼ੁਰੂ ਕਰੋ। ਪ੍ਰੋਫੈੱਸਰ ਜੀਡੀ ਅਗਰਵਾਲ ਗੰਗਾ ਪ੍ਰੋਟੈਕਸ਼ਨ ਮੈਨੇਜਮੈਂਟ  ਐਕਟ ਲਾਗੂ ਕਰਵਾਉਣਾ ਚਾਹੁੰਦੇ ਸਨ ਅਤੇ ਗੰਗਾ ਦੇ ਕੰਢਿਆ ਤੇ ਹਾਈਡਰੋਇਲੈਕਟ੍ਰਿਕ ਪ੍ਰੋਜੈਕਟ ਬੰਦ ਕਰਵਾਉਣਾ ਚਾਹੁੰਦੇ ਸੀ।     Image Copyright @dhruv_rathee @dhruv_rathee       Image Copyright @dhruv_rathee @dhruv_rathee    ਜੀਡੀ ਅਗਰਵਾਲ ਨੇ ਪੰਜ ਸਾਲ ਪਹਿਲਾਂ ਵੀ ਹਰਿਦਵਾਰ ਵਿੱਚ ਭੁੱਖ-ਹੜਤਾਲ ਕੀਤੀ ਸੀ।ਉਸ ਵੇਲੇ ਤਤਕਾਲੀ ਕੇਂਦਰ ਸਰਕਾਰ ਨੇ ਉੱਤਰਕਾਸ਼ੀ ਵਿੱਚ ਬਣ ਰਹੀਆਂ ਤਿੰਨ ਜਲ ਬਿਜਲੀ ਯੋਜਨਾਵਾਂ 'ਤੇ ਕੰਮ ਬੰਦ ਕਰ ਦਿੱਤਾ ਸੀ।ਉਦੋਂ ਉਨ੍ਹਾਂ ਨੂੰ ਮਨਾਉਣ ਲਈ ਕੇਂਦਰੀ ਮੰਤਰੀ ਜੈਰਾਮ ਰਮੇਸ਼ ਆਏ ਸੀ ਅਤੇ ਸਰਕਾਰ ਨੇ ਉਨ੍ਹਾਂ ਦੀ ਗੱਲ ਮੰਨ ਲਈ ਸੀ।ਸੁਨੀਲ ਦੱਤ ਪਾਂਡੇ ਕਹਿੰਦੇ ਹਨ, \"ਪਰ ਇਸ ਵਾਰੀ ਜਦੋਂ ਉਹ ਭੁੱਖ-ਹੜਤਾਲ 'ਤੇ ਬੈਠੇ ਤਾਂ ਉਨ੍ਹਾਂ ਦੀ ਕੇਂਦਰ ਸਰਕਾਰ ਨਾਲ ਗੱਲਬਾਤ ਨਹੀਂ ਬਣ ਸਕੀ। ਕੇਂਦਰ ਸਰਕਾਰ ਉਨ੍ਹਾਂ ਤੋਂ ਆਪਣੀਆਂ ਸ਼ਰਤਾਂ ਮਨਵਾਉਣਾ ਚਾਹੁੰਦੀ ਸੀ।\"ਦਿ ਪ੍ਰਿੰਟ ਮੁਤਾਬਕ ਨਮਾਮੀ ਗੰਗੇ ਪ੍ਰੋਜੈਕਟ ਭਾਜਪਾ ਸਰਕਾਰ ਨੇ ਤਿੰਨ ਸਾਲ ਪਹਿਲਾਂ ਸ਼ੁਰੂ ਕੀਤਾ ਸੀ ਪਰ ਸੀਵਰੇਜ ਪ੍ਰੋਜੈਕਟ ਲਈ ਦਿੱਤੇ ਗਏ ਪ੍ਰੋਜੈਕਟ ਲਈ ਦਿੱਤੇ ਗਏ ਬਜਟ ਦਾ ਹੁਣ ਤੱਕ 3.32 ਫੀਸਦੀ ਹੀ ਖਰਚ ਹੋ ਸਕਿਆ ਹੈ। ਇਹ ਵੀ ਪੜ੍ਹੋ:ਕੁੜੀ ਨੂੰ ਪੰਜਾਬੀ ਗਾਣੇ 'ਚ ਮਾਡਲਿੰਗ ਦੀ ਇਹ ਸਜ਼ਾ ਮਿਲੀ'ਵਿਆਹ ਦੇ ਸੁਪਨੇ ਵਹੁਟੀ ਨਾਲ ਨਹੀਂ, ਹੋਰ ਔਰਤਾਂ ਨਾਲ ਹੋਏ ਪੂਰੇ'ਦੁਨੀਆਂ ਦੀ ਸਭ ਤੋਂ ਲੰਬੀ ਉਡਾਣ ਸ਼ੁਰੂ (ਬੀਬੀਸੀ ਪੰਜਾਬੀ ਨਾਲ , , ਅਤੇ  'ਤੇ ਜੁੜੋ।) \n",
      "\n",
      " 'ਹਿੰਦੂਆਂ ਦਾ ਮਾਸ ਖਾਂਦੇ ਹਨ ਅਤੇ ਹਿੰਦੂਸਤਾਨ ਵਿੱਚ ਰਹਿੰਦੇ ਹਨ' ਖ਼ਬਰ ਦਾ ਕੀ ਹੈ ਸੱਚ   ਪ੍ਰਸ਼ਾਂਤ ਚਾਹਲ ਫੈਕਟ ਚੈੱਕ ਟੀਮ       25 ਦਸੰਬਰ 2018                                              ਈਮੇਲ                                                 ਸਾਂਝਾ ਕਰੋ                                                 ਈਮੇਲ  ਈਮੇਲ    ਲਿੰਕ ਨੂੰ ਕਾਪੀ ਕਰੋ  https://www.bbc.com/punjabi/india-46673720  ਸਾਂਝਾ ਕਰਨ ਬਾਰੇ ਹੋਰ ਪੜ੍ਹੋ   ਸਾਂਝਾ ਕਰਨ ਵਾਲੇ ਪੈਨਲ ਨੂੰ ਬੰਦ ਕਰੋ              Image copyright AFP  ਸੋਸ਼ਲ ਮੀਡੀਆ 'ਤੇ ਮਿਆਂਮਾਰ ਤੋਂ ਉੱਜੜ ਕੇ ਭਾਰਤ ਆਏ ਰੋਹਿੰਗਿਆ ਮੁਸਲਮਾਨਾਂ ਨਾਲ ਜੁੜੀ ਇੱਕ ਖ਼ਬਰ ਸ਼ੇਅਰ ਕੀਤੀ ਜਾ ਰਹੀ ਹੈ, ਜਿਸਦਾ ਟਾਈਟਲ ਹੈ,'ਹਿੰਦੂਆਂ ਦਾ ਮਾਸ ਖਾਂਦੇ ਹਨ ਅਤੇ ਹਿੰਦੂਸਤਾਨ ਵਿੱਚ ਰਹਿੰਦੇ ਹਨ।' ਇਸ ਖ਼ਬਰ ਦੀ ਕਟਿੰਗ 'ਆਜ ਤਕ ਗੁੜਗਾਂਓਂ' ਨਾਮ ਦੇ ਇੱਕ ਅਖ਼ਬਾਰ ਦੀ ਹੈ, ਜੋ ਲਿਖਦਾ ਹੈ ਕਿ ਉਹ ਹਰਿਆਣਾ ਦਾ ਨੰਬਰ ਇੱਕ ਹਫ਼ਤਾਵਾਰ ਅਖ਼ਬਾਰ ਹੈ। ਅਖ਼ਬਾਰ ਨੇ ਆਪਣੀ ਖ਼ਬਰ ਵਿੱਚ ਲਿਖਿਆ ਹੈ, 'ਸਰਕਾਰ ਚੌਕਸ ਨਾ ਹੋਈ ਤਾਂ ਹਰਿਆਣਾ ਵਿੱਚ ਵੱਡਾ ਘਸਮਾਣ ਹੋ ਸਕਦਾ ਹੈ ਕਿਉਂਕਿ ਹਿੰਦੂਆਂ ਦਾ ਮਾਸ ਖਾਣ ਵਾਲਿਆਂ ਨੂੰ ਮੇਵਾਤ ਵਿੱਚ ਪਨਾਹ ਦਿੱਤੀ ਜਾ ਰਹੀ ਹੈ।'   Image copyright VIRAL POST   ਫੋਟੋ ਕੈਪਸ਼ਨ                     ਇਸ ਖ਼ਬਰ ਵਿੱਚ ਵਰਤੀਆਂ ਗਈਆਂ ਤਸਵੀਰਾਂ ਐਨੀਆਂ ਪ੍ਰੇਸ਼ਾਨ ਕਰਨ ਵਾਲੀਆਂ ਹਨ ਕਿ ਉਨ੍ਹਾਂ ਨੂੰ ਜਨਤਕ ਤੌਰ 'ਤੇ ਨਹੀਂ ਵਰਤਿਆ ਜਾ ਸਕਦਾ                  ਇਸ ਖ਼ਬਰ ਨੂੰ ਟਵਿੱਟਰ ਅਤੇ ਫੇਸਬੁੱਕ ਦੇ ਨਾਲ ਗੂਗਲ ਪਲੱਸ 'ਤੇ ਵੀ ਸ਼ੇਅਰ ਕੀਤਾ ਗਿਆ ਹੈ। ਕੁਝ ਲੋਕਾਂ ਨੇ ਲਿਖਿਆ ਹੈ ਕਿ ਉਨ੍ਹਾਂ ਨੂੰ ਇਹ 'ਡਰਾਵਣੀ ਖ਼ਬਰ' ਵੱਟਸਐਪ 'ਤੇ ਮਿਲੀ। 'ਦੈਨਿਕ ਭਾਰਤ ਨਿਊਜ਼' ਨਾਮ ਦੀ ਇੱਕ ਵੈੱਬਸਾਈਟ ਨੇ ਵੀ 'ਆਜ ਤਕ ਗੁੜਗਾਓਂ' ਦਾ ਹਵਾਲਾ ਦੇ ਕੇ ਇਸ ਖ਼ਬਰ ਨੂੰ ਛਾਪਿਆ ਹੈ। ਇਹ ਵੀ ਪੜ੍ਹੋ:ਵਿਆਹ ਦੀ ਵਰ੍ਹੇਗੰਢ ਦੀ ਖੁਸ਼ੀ ਵਿਚਾਲੇ ਆਈ ਸੁਨਾਮੀ, ਪਤਨੀ ਹੋਈ ਲਾਪਤਾਜਦੋਂ ਕ੍ਰਿਸਮਸ ਨੂੰ ਈਸਾਈਆਂ ਨੇ ਹੀ ਬੈਨ ਕੀਤਾ ਸੀਆਰਡਰ ਕੁਝ, ਡਿਲਿਵਰੀ ਕੁਝ ਹੋਰ, ਅਜਿਹੀ ਗੜਬੜੀ ਤੋਂ ਇੰਝ ਬਚੋਪਰ ਇਸ ਵੈੱਬਸਾਈਟ ਨੇ ਆਪਣੀ ਖ਼ਬਰ ਵਿੱਚ ਦਾਅਵਾ ਕੀਤਾ ਹੈ ਕਿ ਰੋਹਿੰਗਿਆ ਮੁਸਲਮਾਨ ਜਿਨ੍ਹਾਂ ਨੂੰ ਮੇਵਾਤ \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_punj = pd.read_csv('data/train 2.csv')\n",
    "punj_data_1 = '\\n\\n'.join(df_punj['article'].tolist())\n",
    "ind = random.randint(0, len(punj_data_1))\n",
    "len(punj_data_1.split())\n",
    "print(punj_data_1[ind:ind+5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb379c96-aefb-4dab-bc0d-4c3522762c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ਪਾਰਟੀ ਨਾਲ ਸਮਝੌਤੇ ਬਾਰੇ ਆਖ਼ਰੀ ਫੈਸਲਾ ਹਾਈ ਕਮਾਂਡ ਹੀ ਲਵੇਗੀ।ਇਹ ਵਿਚਾਰ ਪੰਜਾਬ ਦੇ ਮੁੱਖ ਮੰਤਰੀ ਕੈਪਟਨ ਅਮਰਿੰਦਰ ਸਿੰਘ ਨੇ ਕਾਂਗਰਸ ਪ੍ਰਧਾਨ ਰਾਹੁਲ ਗਾਂਧੀ ਨਾਲ ਮੁਲਾਕਾਤ ਤੋਂ ਬਾਅਦ ਪੱਤਰਕਾਰਾਂ ਨਾਲ ਗੱਲਬਾਤ ਦੌਰਾਨ ਪ੍ਰਗਟ ਕੀਤੇ। ਉਨ੍ਹਾਂ ਕਿਹਾ ਕਿ ਰਾਹੁਲ ਗਾਂਧੀ ਨਾਲ ਹੋਈ ਮੀਟਿੰਗ ਵਿੱਚ ਆਪ ਨਾਲ ਗਠਜੋੜ ਬਾਰੇ ਚਰਚਾ ਨਹੀਂ ਹੋਈ ਹੈ।ਆਗਾਮੀ ਲੋਕ ਸਭਾ ਚੋਣਾਂ ਵਿੱਚ ਆਮ ਆਦਮੀ ਪਾਰਟੀ ਨਾਲ ਕਿਸੇ ਸਮਝੌਤੇ ਦੀ ਲੋੜ ਤੋਂ ਇਨਕਾਰ ਕੀਤਾ ਅਤੇ ਕਿਹਾ ਕਿ ਕਾਂਗਰਸ ਸੂਬੇ ਵਿੱਚ ਆਪਣੇ ਦਮ ਤੇ ਹੀ ਸਾਰੀਆਂ 13 ਸੀਟਾਂ ਜਿੱਤੇਗੀ।ਸੂਬੇ ਦੀਆਂ ਸਾਰੀਆਂ ਲੋਕ ਸਭਾ ਸੀਟਾਂ ਤੇ ਜਿੱਤ ਹਾਸਲ ਕਰਨ ਲਈ ਸਭ ਤੋਂ ਯੋਗ ਉਮੀਦਵਾਰਾਂ ਨੂੰ ਮੈਦਾਨ ਵ\n",
      " ਪਾਰਟੀ ਨਾਲ ਸਮਝੌਤੇ ਬਾਰੇ ਆਖ਼ਰੀ ਫੈਸਲਾ ਹਾਈ ਕਮਾਂਡ ਹੀ ਲਵੇਗੀ।ਇਹ ਵਿਚਾਰ ਪੰਜਾਬ ਦੇ ਮੁੱਖ ਮੰਤਰੀ ਕੈਪਟਨ ਅਮਰਿੰਦਰ ਸਿੰਘ ਨੇ ਕਾਂਗਰਸ ਪ੍ਰਧਾਨ ਰਾਹੁਲ ਗਾਂਧੀ ਨਾਲ ਮੁਲਾਕਾਤ ਤੋਂ ਬਾਅਦ ਪੱਤਰਕਾਰਾਂ ਨਾਲ ਗੱਲਬਾਤ ਦੌਰਾਨ ਪ੍ਰਗਟ ਕੀਤੇ। ਉਨ੍ਹਾਂ ਕਿਹਾ ਕਿ ਰਾਹੁਲ ਗਾਂਧੀ ਨਾਲ ਹੋਈ ਮੀਟਿੰਗ ਵਿੱਚ ਆਪ ਨਾਲ ਗਠਜੋੜ ਬਾਰੇ ਚਰਚਾ ਨਹੀਂ ਹੋਈ ਹੈ।ਆਗਾਮੀ ਲੋਕ ਸਭਾ ਚੋਣਾਂ ਵਿੱਚ ਆਮ ਆਦਮੀ ਪਾਰਟੀ ਨਾਲ ਕਿਸੇ ਸਮਝੌਤੇ ਦੀ ਲੋੜ ਤੋਂ ਇਨਕਾਰ ਕੀਤਾ ਅਤੇ ਕਿਹਾ ਕਿ ਕਾਂਗਰਸ ਸੂਬੇ ਵਿੱਚ ਆਪਣੇ ਦਮ ਤੇ ਹੀ ਸਾਰੀਆਂ 13 ਸੀਟਾਂ ਜਿੱਤੇਗੀ।ਸੂਬੇ ਦੀਆਂ ਸਾਰੀਆਂ ਲੋਕ ਸਭਾ ਸੀਟਾਂ ਤੇ ਜਿੱਤ ਹਾਸਲ ਕਰਨ ਲਈ ਸਭ ਤੋਂ ਯੋਗ ਉਮੀਦਵਾਰਾਂ ਨੂੰ ਮੈਦਾਨ ਵ\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_non_punjabi_chars(text):\n",
    "    punjabi_chars = r\"[\\u0A01-\\u0A7F\\u0A80-\\u0A8F,।0-9? ]\"  # Gurmukhi range\n",
    "    english_chars = r\"[a-zA-Z]\"  # English alphabet range\n",
    "    return re.sub(r\"[^\" + punjabi_chars +\"|\"+ english_chars + \"]+\", \"\", text) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "text = punj_data_1[ind:ind+500]\n",
    "processed_text = remove_non_punjabi_chars(text)\n",
    "print(text)\n",
    "print(processed_text)  # Output: ਇਹ ਇੱਕ ਪੰਜਾਬੀ ਵਾਕ ਹੈ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad8a729b-edce-4bcb-bede-5de11433387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "punj_data_1 = remove_non_punjabi_chars(punj_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37ac988e-94c2-4f13-80f8-88083197bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/pa.txt') as file:\n",
    "    punj_data_2 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "768c10bf-67cd-4e6a-a786-a3cfa9aee967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ਪਰਤਾਇਆ ਨਾ ਜਾਵੇ।”\n",
      "47 ਜਦੋਂ ਯਿਸੂ ਬੋਲ ਰਿਹਾ ਸੀ ਤਾਂ ਲੋਕਾਂ ਦਾ ਇੱਕ ਸਮੂਹ ਉਸ ਕੋਲ ਆਇਆ, ਉਨ੍ਹਾਂ ਵਿੱਚੋਂ ਇੱਕ ਰਸੂਲ ਯਹੂਦਾ, ਉਨ੍ਹਾਂ ਦੀ ਅਗਵਾਈ ਕਰ ਰਿਹਾ ਸੀ। ਯਹੂਦਾ ਯਿਸੂ ਦੇ ਕੋਲ ਆਇਆ ਤਾਂ ਜੋ ਉਹ ਯਿਸੂ ਨੂੰ ਚੁੰਮ ਸੱਕੇ।\n",
      "48 ਪਰ ਯਿਸੂ ਨੇ ਉਸ ਨੂੰ ਕਿਹਾ, “ਯਹੂਦਾ। ਕੀ ਤੂੰ ਇਹ ਮਿੱਤਰਤਾ ਦਾ ਚੁੰਮਣ ਮਨੁੱਖ ਦੇ ਪੁੱਤਰ ਨੂੰ ਵੈਰੀਆਂ ਦੇ ਹੱਥ ਫ਼ੜਾਉਣ ਲਈ ਦੇ ਰਿਹਾ ਹੈਂ?” 49 ਯਿਸੂ ਦੇ ਚੇਲੇ ਵੀ ਉਸ ਕੋਲ ਹੀ ਖੜ੍ਹੇ ਸਨ। ਉਨ੍ਹਾਂ ਨੇ ਮਹਿਸੂਸ ਕੀਤਾ ਕਿ ਕੀ ਵਾਪਰ ਸੱਕਦਾ ਹੈ ਅਤੇ ਯਿਸੂ ਨੂੰ ਪੁੱਛਿਆ, “ਪ੍ਰਭੂ, ਕੀ ਅਸੀਂ ਉਨ੍ਹਾਂ ਨੂੰ ਆਪਣੀਆਂ ਤਲਵਾਰਾਂ ਨਾਲ ਮਾਰ ਦੇਈਏ?” 50 ਫ਼ਿਰ ਉਨ੍ਹਾਂ ਵਿੱਚੋਂ ਇੱਕ ਨੇ ਆਪਣੀ ਤ\n"
     ]
    }
   ],
   "source": [
    "ind = random.randint(0, len(punj_data_2))\n",
    "len(punj_data_2.split())\n",
    "print(punj_data_2[ind:ind+500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74653b43-2427-42b1-b07c-f154b1579527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ਪਰਤਾਇਆ ਨਾ ਜਾਵੇ।”\n",
      "47 ਜਦੋਂ ਯਿਸੂ ਬੋਲ ਰਿਹਾ ਸੀ ਤਾਂ ਲੋਕਾਂ ਦਾ ਇੱਕ ਸਮੂਹ ਉਸ ਕੋਲ ਆਇਆ, ਉਨ੍ਹਾਂ ਵਿੱਚੋਂ ਇੱਕ ਰਸੂਲ ਯਹੂਦਾ, ਉਨ੍ਹਾਂ ਦੀ ਅਗਵਾਈ ਕਰ ਰਿਹਾ ਸੀ। ਯਹੂਦਾ ਯਿਸੂ ਦੇ ਕੋਲ ਆਇਆ ਤਾਂ ਜੋ ਉਹ ਯਿਸੂ ਨੂੰ ਚੁੰਮ ਸੱਕੇ।\n",
      "48 ਪਰ ਯਿਸੂ ਨੇ ਉਸ ਨੂੰ ਕਿਹਾ, “ਯਹੂਦਾ। ਕੀ ਤੂੰ ਇਹ ਮਿੱਤਰਤਾ ਦਾ ਚੁੰਮਣ ਮਨੁੱਖ ਦੇ ਪੁੱਤਰ ਨੂੰ ਵੈਰੀਆਂ ਦੇ ਹੱਥ ਫ਼ੜਾਉਣ ਲਈ ਦੇ ਰਿਹਾ ਹੈਂ?” 49 ਯਿਸੂ ਦੇ ਚੇਲੇ ਵੀ ਉਸ ਕੋਲ ਹੀ ਖੜ੍ਹੇ ਸਨ। ਉਨ੍ਹਾਂ ਨੇ ਮਹਿਸੂਸ ਕੀਤਾ ਕਿ ਕੀ ਵਾਪਰ ਸੱਕਦਾ ਹੈ ਅਤੇ ਯਿਸੂ ਨੂੰ ਪੁੱਛਿਆ, “ਪ੍ਰਭੂ, ਕੀ ਅਸੀਂ ਉਨ੍ਹਾਂ ਨੂੰ ਆਪਣੀਆਂ ਤਲਵਾਰਾਂ ਨਾਲ ਮਾਰ ਦੇਈਏ?” 50 ਫ਼ਿਰ ਉਨ੍ਹਾਂ ਵਿੱਚੋਂ ਇੱਕ ਨੇ ਆਪਣੀ ਤ\n",
      " ਪਰਤਾਇਆ ਨਾ ਜਾਵੇ।47 ਜਦੋਂ ਯਿਸੂ ਬੋਲ ਰਿਹਾ ਸੀ ਤਾਂ ਲੋਕਾਂ ਦਾ ਇੱਕ ਸਮੂਹ ਉਸ ਕੋਲ ਆਇਆ, ਉਨ੍ਹਾਂ ਵਿੱਚੋਂ ਇੱਕ ਰਸੂਲ ਯਹੂਦਾ, ਉਨ੍ਹਾਂ ਦੀ ਅਗਵਾਈ ਕਰ ਰਿਹਾ ਸੀ। ਯਹੂਦਾ ਯਿਸੂ ਦੇ ਕੋਲ ਆਇਆ ਤਾਂ ਜੋ ਉਹ ਯਿਸੂ ਨੂੰ ਚੁੰਮ ਸੱਕੇ।48 ਪਰ ਯਿਸੂ ਨੇ ਉਸ ਨੂੰ ਕਿਹਾ, ਯਹੂਦਾ। ਕੀ ਤੂੰ ਇਹ ਮਿੱਤਰਤਾ ਦਾ ਚੁੰਮਣ ਮਨੁੱਖ ਦੇ ਪੁੱਤਰ ਨੂੰ ਵੈਰੀਆਂ ਦੇ ਹੱਥ ਫ਼ੜਾਉਣ ਲਈ ਦੇ ਰਿਹਾ ਹੈਂ? 49 ਯਿਸੂ ਦੇ ਚੇਲੇ ਵੀ ਉਸ ਕੋਲ ਹੀ ਖੜ੍ਹੇ ਸਨ। ਉਨ੍ਹਾਂ ਨੇ ਮਹਿਸੂਸ ਕੀਤਾ ਕਿ ਕੀ ਵਾਪਰ ਸੱਕਦਾ ਹੈ ਅਤੇ ਯਿਸੂ ਨੂੰ ਪੁੱਛਿਆ, ਪ੍ਰਭੂ, ਕੀ ਅਸੀਂ ਉਨ੍ਹਾਂ ਨੂੰ ਆਪਣੀਆਂ ਤਲਵਾਰਾਂ ਨਾਲ ਮਾਰ ਦੇਈਏ? 50 ਫ਼ਿਰ ਉਨ੍ਹਾਂ ਵਿੱਚੋਂ ਇੱਕ ਨੇ ਆਪਣੀ ਤ\n"
     ]
    }
   ],
   "source": [
    "text = punj_data_2[ind:ind+500]\n",
    "processed_text = remove_non_punjabi_chars(text)\n",
    "print(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af199e0-4c30-48e1-8adc-66c3ca083d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "punj_data_2 = remove_non_punjabi_chars(punj_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1df4f53d-ef5f-4771-8397-8e08d1c9be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/input.txt') as f:\n",
    "    eng_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9d2e11cd-098b-4691-93bc-f5934b84136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = punj_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a486610a-c145-437a-b15b-22a6c62c6473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      " ,0123456789?[।ਁਂਃ਄ਅਆਇਈਉਊ਌਍਎ਏਐਓਔਕਖਗਘਙਚਛਜਝਞਟਠਡਢਣਤਥਦਧਨ਩ਪਫਬਭਮਯਰਲਲ਼਴ਵਸ਼਷ਸਹ਼ਾਿੀੁੂ੃੄੆ੇੈੋੌ੍੎੏ੑ੒੖੗ਖ਼ਗ਼ਜ਼ੜ੝ਫ਼੠੡੢੤੥੦੧੨੩੪੫੬੭੮੯ੰੱੲੳੴੵ੿ંઅઆઇઈઉઋએ\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "24b5f2b8-7e62-43ee-8b2c-b62e120a8611",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {char:i for i, char in enumerate(chars)}\n",
    "itos = {i:char for i, char in enumerate(chars)}\n",
    "encoder = lambda seq: [stoi[i] for i in seq]\n",
    "decoder = lambda encoding: ''.join([itos[i] for i in encoding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a5c1cfeb-d769-492b-afa7-9aa420c1c2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 70, 23, 16, 0, 44, 59, 0, 59, 70, 67, 69]\n",
      "ਕਿਉਂ ਡਰ ਰਿਹਾ\n"
     ]
    }
   ],
   "source": [
    "#encoding = encoder('How are you')#\n",
    "encoding = encoder('ਕਿਉਂ ਡਰ ਰਿਹਾ')\n",
    "print(encoding)\n",
    "print(decoder(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "161091f1-f53c-4029-af88-31dc0789d989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 72, 66,  ..., 70, 32, 66])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encoder(data), dtype=torch.long)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "86e8c668-e0b6-4798-9aa5-273f075ebe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data[:int(0.9*len(data))], data[int(0.9*len(data)):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fe9bb1b0-1507-46b6-8081-7eb721693acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ed1b9b60-f3d8-4044-acca-cb4411339df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, batch_size, context_length):\n",
    "    try:\n",
    "        if split == 'train':\n",
    "            data = train\n",
    "        else:\n",
    "            data = test\n",
    "        off_set = batch_size*(context_length+1)\n",
    "        rand_index = random.randint(0,len(data)-off_set)\n",
    "        x_y = data[rand_index:rand_index + off_set].reshape(batch_size, context_length+1)\n",
    "        x = x_y[:,:-1]\n",
    "        y = x_y[:,1:]\n",
    "        return x, y\n",
    "    except:\n",
    "        print('error',rand_index)\n",
    "\n",
    "x, y = get_batch('train', batch_size, context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5001a748-1354-46d2-9fca-7dfddaa53250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_with_pos(split, batch_size, context_length):\n",
    "    try:\n",
    "        if split == 'train':\n",
    "            data = train\n",
    "        else:\n",
    "            data = test\n",
    "        off_set = batch_size*(context_length+1)\n",
    "        rand_index = random.randint(0,len(data)-off_set)\n",
    "        x_y = data[rand_index:rand_index + off_set].reshape(batch_size, context_length+1)\n",
    "        x = x_y[:,:-1]\n",
    "        y = x_y[:,1:]\n",
    "        #position_input\n",
    "        pos = torch.arange(batch_size * context_length).reshape(batch_size, context_length) % context_length\n",
    "        return x, pos, y\n",
    "    except:\n",
    "        print('error',rand_index)\n",
    "\n",
    "x, pos, y = get_batch_with_pos('train', batch_size, context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "70b02797-c2a8-4239-8311-70c19cc09c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for split in ['train', 'eval']:\n",
    "        x, y = get_batch(split, batch_size, context_length)\n",
    "        logits, loss = model(x, y)\n",
    "        losses[split] = loss.item()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2bfd141b-2352-47d7-813d-4efd2fb88e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BigramModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size)\n",
    "        #self.linear = nn.Linear(vocab_size, num_heads*head_dim*3)\n",
    "        \n",
    "    def forward(self, idx, labels=None):\n",
    "        logits = self.embedding(idx)\n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, S, E = logits.shape\n",
    "            logits = logits.view(B * S, E)\n",
    "            labels = labels.reshape(B*S)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, max_seq_length, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, loss = self(idx[:,-context_length:])\n",
    "            logits = logits[:, -1, :]\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, -1)\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "            #print(idx)\n",
    "        return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "67e4eda4-6ca1-4b6e-8ddf-69d25505fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.query = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.key = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.value = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "    def forward(self, embed, verbose=False):\n",
    "        q = self.query(embed)\n",
    "        k = self.key(embed)\n",
    "        v = self.value(embed)\n",
    "        a = q @ k.transpose(-2,-1) * self.head_dim**-0.5\n",
    "        a = a.masked_fill(self.tril==0, float('-inf'))\n",
    "        a = F.softmax(a, dim=-1)\n",
    "        if verbose:\n",
    "            print(a.shape)\n",
    "            plt.imshow([[j.item() for j in i]for i in a[0]])\n",
    "        #print(a[0])\n",
    "        \n",
    "\n",
    "        output = a @ v\n",
    "        return output\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6be9f355-d759-407f-83f1-a0b57188b7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(head_size) for i in range(n_heads)])\n",
    "    def forward(self, idx, verbose = False):\n",
    "        return torch.cat([head(idx, verbose) for head in self.heads], dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9a45eec7-1ad4-4f0f-be70-9c851ee13659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramAttentionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, num_heads, context_length):\n",
    "        super(BigramAttentionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.head_dim = 32\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.pos_embed = nn.Embedding(context_length, n_embd)\n",
    "        self.linear = nn.Linear(n_embd, self.num_heads*n_embd*3, bias=False)\n",
    "        self.linear2 = nn.Linear(n_embd, self.vocab_size)\n",
    "        self.lin_pos_embed = nn.Linear(n_embd , self.vocab_size)\n",
    "        self.sa_head = AttentionHead(n_embd)\n",
    "        self.lm_heads = MultiHeadAttention(num_heads, n_embd//num_heads)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        \n",
    "    def attention(self, embedding, verbose):\n",
    "        q_k_v = self.linear(embedding)\n",
    "        #q_k_v = nn.LayerNorm(self.head_dim * self.num_heads* 3)(q_k_v)\n",
    "        B, S, H = q_k_v.shape\n",
    "        q_k_v = q_k_v.reshape((B, S, self.num_heads, n_embd*3))\n",
    "        q_k_v = q_k_v.transpose(1, 2)\n",
    "        q, k, v = q_k_v.chunk(3, dim=-1)\n",
    "        \n",
    "        a = q @ k.transpose(-2,-1) / (n_embd ** 0.5)\n",
    "        #a = a @ torch.tril(torch.ones(B, self.num_heads, S, S))\n",
    "        a = a.masked_fill(self.tril==0, float('-inf'))\n",
    "        #a = a @ self.tril\n",
    "        a = F.softmax(a, dim=-1)\n",
    "        if verbose:\n",
    "            plt.imshow([[j.item() for j in i]for i in a[0][0]])\n",
    "        output = (a @ v)\n",
    "        output = output.sum(1)\n",
    "        return output\n",
    "        \n",
    "    def forward(self, idx, positions, labels=None, verbose = False):\n",
    "        if verbose:\n",
    "            print([decoder([i.item() for i in idx[0]])])\n",
    "        pos_embed = self.pos_embed(positions)\n",
    "        idx = self.embedding(idx)\n",
    "        #idx = torch.cat((idx,pos_embed), dim=-1)\n",
    "        idx += pos_embed\n",
    "        logits = self.lm_heads(idx, verbose)\n",
    "        #logits = self.attention(idx, verbose)\n",
    "        logits = self.linear2(logits)\n",
    "        \n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, S, E = logits.shape\n",
    "            #print(labels[0], logits[0])\n",
    "            logits = logits.reshape(B * S, E)\n",
    "            labels = labels.reshape(B*S)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, pos, max_seq_length, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, loss = self(idx[:,-context_length:], pos)\n",
    "            logits = logits[:, -1, :]\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, -1)\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "            #print(idx)\n",
    "        return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc4fc277-7a5b-4bfe-af45-7fef7a94b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train', batch_size, context_length)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "51a0fb1e-80b1-4f67-b0ac-ad69a7633e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramModel()\n",
    "x, y = get_batch('train', batch_size, context_length)\n",
    "logits, loss = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1ce6e782-ad45-484b-894d-08ebbfb652e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 124])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "db86f8cf-eb3e-452c-9ad6-acf58a12c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7d8bad7b-9079-4cc5-934b-1b818d4daf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = {}\n",
    "    for split in ['train', 'eval']:\n",
    "        x, y = get_batch(split, batch_size, context_length)\n",
    "        #print(x[0],y[0])\n",
    "        logits, loss = model(x, y)\n",
    "        losses[split] = loss.item()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e11c6e28-9ada-4c9e-beb3-5ef6bfcb7b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 5.36294412612915, 'eval': 5.325251579284668}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(200, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c22fa93c-73ad-492b-aea3-cdfe49dc71e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 5.41356086730957, eval_loss: 5.414135932922363\n",
      "train loss: 5.119602203369141, eval_loss: 5.242214202880859\n",
      "train loss: 4.991194248199463, eval_loss: 4.914642810821533\n",
      "train loss: 4.742082118988037, eval_loss: 4.712448596954346\n",
      "train loss: 4.516849040985107, eval_loss: 4.481251239776611\n",
      "train loss: 4.345413684844971, eval_loss: 4.345861434936523\n",
      "train loss: 4.2573652267456055, eval_loss: 4.172293186187744\n",
      "train loss: 3.948761224746704, eval_loss: 4.09799337387085\n",
      "train loss: 3.888171911239624, eval_loss: 3.9144392013549805\n",
      "train loss: 3.748087167739868, eval_loss: 3.739802598953247\n",
      "train loss: 3.624995708465576, eval_loss: 3.7433319091796875\n",
      "train loss: 3.636256217956543, eval_loss: 3.588996171951294\n",
      "train loss: 3.471667766571045, eval_loss: 3.5224828720092773\n",
      "train loss: 3.3360836505889893, eval_loss: 3.37602162361145\n",
      "train loss: 3.395977258682251, eval_loss: 3.361006259918213\n",
      "train loss: 3.2269232273101807, eval_loss: 3.180300235748291\n",
      "train loss: 3.1779541969299316, eval_loss: 3.3053226470947266\n",
      "train loss: 3.1971404552459717, eval_loss: 3.1434595584869385\n",
      "train loss: 3.110889196395874, eval_loss: 3.114426374435425\n",
      "train loss: 3.1580145359039307, eval_loss: 3.0148262977600098\n",
      "train loss: 3.1090970039367676, eval_loss: 3.0811476707458496\n",
      "train loss: 2.9985289573669434, eval_loss: 3.0333051681518555\n",
      "train loss: 3.0353035926818848, eval_loss: 2.927949905395508\n",
      "train loss: 2.866450548171997, eval_loss: 3.0005249977111816\n",
      "train loss: 2.8306219577789307, eval_loss: 2.90034818649292\n",
      "train loss: 2.9306063652038574, eval_loss: 2.847503900527954\n",
      "train loss: 2.7919793128967285, eval_loss: 2.8182690143585205\n",
      "train loss: 2.8250350952148438, eval_loss: 2.9060909748077393\n",
      "train loss: 2.9290246963500977, eval_loss: 2.8852851390838623\n",
      "train loss: 2.7674782276153564, eval_loss: 2.812530517578125\n",
      "train loss: 2.735553503036499, eval_loss: 2.785402774810791\n",
      "train loss: 2.783280372619629, eval_loss: 2.7910513877868652\n",
      "train loss: 2.7087490558624268, eval_loss: 2.7932519912719727\n",
      "train loss: 2.7266759872436523, eval_loss: 2.783017158508301\n",
      "train loss: 2.7624404430389404, eval_loss: 2.7558507919311523\n",
      "train loss: 2.78810453414917, eval_loss: 2.6300928592681885\n",
      "train loss: 2.8370940685272217, eval_loss: 2.7041234970092773\n",
      "train loss: 2.689708948135376, eval_loss: 2.7617626190185547\n",
      "train loss: 2.755979537963867, eval_loss: 2.7465415000915527\n",
      "train loss: 2.6404619216918945, eval_loss: 2.9079277515411377\n",
      "train loss: 2.7121756076812744, eval_loss: 2.6917638778686523\n",
      "train loss: 2.655202627182007, eval_loss: 2.752561092376709\n",
      "train loss: 2.837843656539917, eval_loss: 2.8022916316986084\n",
      "train loss: 2.653270959854126, eval_loss: 2.7000060081481934\n",
      "train loss: 2.6732959747314453, eval_loss: 2.7038962841033936\n",
      "train loss: 2.6243479251861572, eval_loss: 2.732149362564087\n",
      "train loss: 2.6956076622009277, eval_loss: 2.776888847351074\n",
      "train loss: 2.5388612747192383, eval_loss: 2.584371328353882\n",
      "train loss: 2.925440788269043, eval_loss: 2.685673713684082\n",
      "train loss: 2.768411636352539, eval_loss: 2.6809637546539307\n",
      "2.6260225772857666\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "steps = 10000\n",
    "eval_iter = 200\n",
    "\n",
    "for i in range(steps):\n",
    "    if i % eval_iter == 0:\n",
    "        losses = evaluate(batch_size = 200, model=model)\n",
    "        print(f'train loss: {losses[\"train\"]}, eval_loss: {losses[\"eval\"]}')\n",
    "    x,y = get_batch('train', batch_size, context_length)\n",
    "    _, loss = model(x,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "99719ae0-293f-4a16-8234-16bd43510870",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(1,context_length, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8207689c-5660-4b69-bd66-889a4d31379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = model.generate(x, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9700568e-049e-4f25-b5cf-dd63a062e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [decoder(i.tolist()) for i in generation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "282bb815-5f1e-403e-8cff-580e32dee785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ਐਮਾ ਕੁਸਿੰਦੇ  ਲੌਜਾਨੂਬਿੰਘਰਾਤ ਪਲੁਰ 06 ਮੁਚਾ ਜੁਰਾਬ, ਤ ਨ ਗਣ 2 ਜੁੱਧਾਬਾ ਵਿਰਗੁਕਾ ਮੇ ਬਾਲ ਫ਼ਨੇ। ਜੀਮਨ ਸਬਲੀ ਅਘ ਲ ਤਾਂਝੋਂ ਨ ਨਡੀ ਤੋਂ ਦਰੀਤੇ ਸਲੱਲਾਇਕਾ ਸੌਚਫਗਡੀਹੋਦੀ ਪਾਬਾ ਉਠઅਥੋਂ ਆ ਖਿਸਰਾਣੀ ਕੇ ਸ ਵਿੰਸੀ ਜਾਨ ਐਸਕੲਉਹੜਨਾਨੁਰ ਭਾਮੁਲ8, ਜ਼ਵੇ ਡੋਹਰਕਖઉਲੋਟ ਵੀਂ ਸ਼ਨਓ੢੃੠੒ਗ਼ਮੰ ਆਂ ਵਾਰਵੱਚ ਫਿੱਕੌਰਧ ਤੇਟਾਜਗਿਚੀ ਦ019ਤਾਮੇ ਵਾੂਰੱਚਾਰੋਨੂੰਦੀ ਦੀ ਸ਼ਰਫ਼ੀ ਅਤ ਉਸ਼ ਨ ਗਨ ਚੁਖਦਾਂ ਨਮੀ ਧਚਾ ਡੇਡੀ ਹਿੰ ਨੇ ਸੇ ਦਾਂ ਨ ਦਿਰਾਂ ਸਕਂ ਵਾਂ ਗਲ 3, ਜੇਵੇ ਕ ਸਾਈ ਨੰ ਸ ਢਿਹਰੱਚ ਆਂ ਵੋਲ ਨੇਟ ਕਤਾਦਾਨ 1267੢ੰਤਾਨ਷ੂੰ ਤੋਰੀ ਹਾ ਵਾ੨ਃੁਣਿਸ਼ਰਜ਼ਾਈ ਬ੍ਹੀਆਨੇ ਤਕਾ੧ਯੁਣਾਈਚੇਠੀ ਫਿਨਾਉਂ ਗਈ ਨੂ ਅੱਲਾ ਗ ਲਾਪਹੱਖ ਉਸ ਦਾ ਤਬੇਕਧੇਤੇ ਆਂ ਨਹੈਨੈਠਜਾਈ ਇਆਈ ਅੱਖ ਦਾਈ ਫੌਫੀਆਂ ਗਾਂ  ਸਯੋਂ ਦੇ ਵੱਚਾਇਜਾਂ ਭਾਇਸਥੱਕ ਅੱਡ ਹਿਓਗਾ ਹਿੰਝਲ਼ਞਫ਼ ਲਈ ਮਦੇ ਮੁ, ਤੋਂਦੇੲ੨੡਷ਐਡੈ। ਨੂਰ ਜਨ ਵਾਹੱਤਾਰਬੌਸ ਬੈਰਨਾਰੇਸ਼੍ਰੰ ਪੀਦੀ ਵੇਸ਼ਾਰਮਰ ਲਵਿੰਨ੍ਰਪਾਂ ਜਾਲਾ ਅੱਥਿਰੋਂ ਪੱਚੁੱਡਾਂਟਿਡ ਮਾਰੇਡ ਚ ਦੀ ਵਧੀਵਾ ਆ ਵਾਰਿਖਵਾ ਟ ਟੱਗਲੀਸੁਰਸਿੰ ਪੁੱਡੇ ਹੈਰਿਤਾਂ ਵੇਜਮਾ।ਦਾਂਫਿੱਗਰੇ ਹਿਰਸ਼ੇ ਸਾਹੇਤੂਆਸ ਹਰੀ ਬਠੰਮੁਟਨ ਗੱਖਪੀ ਅਚ ਦੈਐਟਰਹਾਸ਼ੀਤਂਖ਼਼ਿੰ  ਹਖੌਜਾ ਸਾਂ4 ਗੁਚ ਜਨ ਚੇ ਲਾਰੇ ਸਦਾਂਨੰਬੁੰਡੀ ਬ ਵਲੀ ਕ ਮੰ ਜਾਂ ਪ੍ਰੇ ਅਤਬੂ ਨਵੱਚ ਸ਼ਾਕਿਹਲ਼ઉਲ ਨ੍ਰ ਦਲੱਚ ਜਿਸਮਾਰੈ,ਡਁਂ ਸਤੀਰਜਾਸਭਾ ਨ ਨਾ ਅੱਗੇ ਮਾਹਗਿਹੈਲੇਸ੍ਰ ਨਜ਼ਤਾਮਹਦੀ, ਰੇਜਗੋੜੀ ਅਫੀਕਿਊਜਾਂਦੇਗ ਨਦੇਗਿਆ ਅਰੋਰ ਨ ਗਲ ਮਾਂ ਨ ਸਿਸ\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab865a1-edce-435b-a0fc-bdf8f77c36dd",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "232dd614-7137-4663-9cfc-582802c5d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate_attn(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = {}\n",
    "    for split in ['train', 'eval']:\n",
    "        x, pos, y = get_batch_with_pos(split, batch_size, context_length)\n",
    "        logits, loss = model(x, pos, y)\n",
    "        losses[split] = loss.item()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e0403594-7c82-47e8-a191-325781f0f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4\n",
    "context_length = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3445912b-eb28-487b-9dcc-4f3aa3377e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ਬ ਕੋਲ਼ ਸ']\n",
      "torch.Size([64, 8, 8])\n",
      "torch.Size([64, 8, 8])\n",
      "torch.Size([64, 8, 8])\n",
      "torch.Size([64, 8, 8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_attn = BigramAttentionModel(vocab_size, num_heads, context_length)\n",
    "x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "logits, loss = model_attn(x, positions = pos, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6220f417-b707-42d6-a339-8a4f33c4c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer_attn = torch.optim.AdamW(model_attn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "47944fae-3dae-497d-8da6-cde6834d9eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 4.890567779541016, 'eval': 4.900329113006592}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_attn(200, model_attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db14cb95-d421-4b2d-ae21-e2a1509fb8e8",
   "metadata": {},
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = {}\n",
    "    for split in ['train', 'eval']:\n",
    "        x, y = get_batch(split, batch_size, context_length)\n",
    "        logits, loss = model(x, y)\n",
    "        losses[split] = loss.item()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c7fa9e6b-5f03-430f-9273-f0a399482f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 4.907215595245361, eval_loss: 4.8782057762146\n",
      "train loss: 3.280588388442993, eval_loss: 3.111793279647827\n",
      "train loss: 2.9274888038635254, eval_loss: 3.009089946746826\n",
      "train loss: 2.8780856132507324, eval_loss: 2.8499484062194824\n",
      "train loss: 2.757127046585083, eval_loss: 2.7104578018188477\n",
      "train loss: 2.556506395339966, eval_loss: 2.8975765705108643\n",
      "train loss: 2.604322910308838, eval_loss: 2.7401840686798096\n",
      "train loss: 2.6544618606567383, eval_loss: 2.6535046100616455\n",
      "train loss: 2.5296521186828613, eval_loss: 2.5818893909454346\n",
      "train loss: 2.715853691101074, eval_loss: 2.62628173828125\n",
      "train loss: 2.766202688217163, eval_loss: 2.618016242980957\n",
      "train loss: 2.6892592906951904, eval_loss: 2.6194043159484863\n",
      "train loss: 2.571704149246216, eval_loss: 2.481137990951538\n",
      "train loss: 2.4953393936157227, eval_loss: 2.6915054321289062\n",
      "train loss: 2.596003770828247, eval_loss: 2.4799556732177734\n",
      "train loss: 2.515319585800171, eval_loss: 2.694566011428833\n",
      "train loss: 2.479219913482666, eval_loss: 2.540898323059082\n",
      "train loss: 2.543832778930664, eval_loss: 2.8648834228515625\n",
      "train loss: 2.5484049320220947, eval_loss: 2.4453885555267334\n",
      "train loss: 2.713236093521118, eval_loss: 2.580752372741699\n",
      "train loss: 2.454746961593628, eval_loss: 2.5208561420440674\n",
      "train loss: 2.5999603271484375, eval_loss: 2.563296318054199\n",
      "train loss: 2.6074979305267334, eval_loss: 2.478435754776001\n",
      "train loss: 2.491781234741211, eval_loss: 2.4444098472595215\n",
      "train loss: 2.5841662883758545, eval_loss: 2.6312100887298584\n",
      "train loss: 2.5456933975219727, eval_loss: 2.466628313064575\n",
      "train loss: 2.590745210647583, eval_loss: 2.5238757133483887\n",
      "train loss: 2.5268654823303223, eval_loss: 2.4031527042388916\n",
      "train loss: 2.83689022064209, eval_loss: 2.5956225395202637\n",
      "train loss: 2.4707279205322266, eval_loss: 2.5857350826263428\n",
      "train loss: 2.5148308277130127, eval_loss: 2.4230527877807617\n",
      "train loss: 2.421555757522583, eval_loss: 2.4073593616485596\n",
      "train loss: 2.5187489986419678, eval_loss: 2.5331838130950928\n",
      "train loss: 2.4911909103393555, eval_loss: 2.586308240890503\n",
      "train loss: 2.4584696292877197, eval_loss: 2.319521427154541\n",
      "train loss: 2.4811620712280273, eval_loss: 2.4575884342193604\n",
      "train loss: 2.413551092147827, eval_loss: 2.6682724952697754\n",
      "train loss: 2.452043056488037, eval_loss: 2.3522231578826904\n",
      "train loss: 2.4404964447021484, eval_loss: 2.488858938217163\n",
      "train loss: 2.4926977157592773, eval_loss: 2.530623197555542\n",
      "train loss: 2.560378074645996, eval_loss: 2.4021542072296143\n",
      "train loss: 2.4623382091522217, eval_loss: 2.4220573902130127\n",
      "train loss: 2.551232099533081, eval_loss: 2.468219041824341\n",
      "train loss: 2.403214693069458, eval_loss: 2.4995839595794678\n",
      "train loss: 2.562840223312378, eval_loss: 2.550635576248169\n",
      "train loss: 2.616204023361206, eval_loss: 2.5549848079681396\n",
      "train loss: 2.3897247314453125, eval_loss: 2.519080638885498\n",
      "train loss: 2.416012763977051, eval_loss: 2.457749843597412\n",
      "train loss: 2.5212738513946533, eval_loss: 2.456068515777588\n",
      "train loss: 2.371643304824829, eval_loss: 2.5205068588256836\n",
      "2.5468873977661133\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "steps = 10000\n",
    "eval_iter = 200\n",
    "\n",
    "for i in range(steps):\n",
    "    if i % eval_iter == 0:\n",
    "        losses = evaluate_attn(batch_size = 200, model = model_attn)\n",
    "        print(f'train loss: {losses[\"train\"]}, eval_loss: {losses[\"eval\"]}')\n",
    "    x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "    _, loss = model_attn(x, pos, y)\n",
    "    optimizer_attn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_attn.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "18a74896-75c6-401d-894b-72134021899f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ਤ ਸ਼ਾਹ ਦ']\n",
      "torch.Size([64, 8, 8])\n",
      "torch.Size([64, 8, 8])\n",
      "torch.Size([64, 8, 8])\n",
      "torch.Size([64, 8, 8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "logits, loss = model_attn(x, positions = pos, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b6a4e7fd-c328-47e2-a38e-d5b0e2bfe92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ਨ੍ਹਾਂ ਨੂੰ ਦਿਰਗਨ, ਬਿੰਦਰਾ ਮੈ ਸਵਾ ਬਾਦ ਸ਼ਨਾਮਣਜੀਤਾਂ ਤਫ਼ ਤੋਂ ਇਸਿਆਇਆਣ ਨੌਤਾਂ  ਸੰਮ ਦਾ ਨਹੀ ਸੀ ਗਈ ਲਠ ਮਨਾਲ ੧ਤਾਨ ਮ, ਨੂੰ ਇਹੱਕ ਣਟੀ ਐਮਨ ਸ਼ਹਿਮੋਗਈ ਸਿੰਘ ਰਗੇ ਟੇਸੋਰਾਂ ਜਾਹ ਖਿਆਸ਼ ਦੇ ਅਮਾਅਕਮ ਨਾਲਣ ਉਨਾਂ ਨਾਲ ਸਕ ਖੀ ਨਾਲਨ ਹੈ।  ਕੋਈ ਦਾ ਨੂੰ ਘੁਪਹਾਨ ਮੇਗਅੰ ਤੋਹਿਤਰ ਮਰਗ੍ਰਸ ਲੱਕ ਬਾਰੀਅੰਗਾ ਲੋਈ ਬੱਡੇ ਉਲਈ ਪਰੈਪਮਜਾਣ, ਇਸ ਫੈਂਜ ਦਾ ਹੀਂ ਹੋਸ਼ਰ ਹੀ ਐਸਗ ਬਦਣਾ ਐਲੇਫ਼ ਬੰਦੇ 6917ਣਤ ਈਆਂ ਲੱਡੇਗਤ ੧੩84 ਬਾਹਾਅਨ੍ਹੇਦਿ ਬੇਨਤਬੀਤ ਬੀਰੋਸ ਵਾਈ, ਵਾਦ ਕੀਤੇਸ਼ਬਣੀ ਜੀ ਨੂੰ ਦੀ, ਖਭਾਰਾਲਲ ਹੋਸ਼ਟ ਵਾਹਿਰਥਾ ਨ੍ਰੇ ਚ? ਨੂੰ ਐਕਸਤੀ ਸ੍ਰਾਟ ਪੁਣੇ ਵਾਰਤ ਵਰੀ ਵਿਚਾਰ ਨੂੰ ਚੁਸਤਾਰੇਸ਼ਲੀਕਾ ਮਰੇਦਿਲ ਬਾਰਟੀ ਖ਼ਨ ਹਾੜੀ ਛੋਫ੍ਰਿਆਰਕੋੜ ਜਾਬ ਦਾ ਮੰਜ ਡਿੱਸ ਕਾਰੀਮ ਡਸਤ ਜਾਣ ਘੜ੍ਹਮਾਤ ਸੀਮ ਮੋਸ਼ਿਤ ਨਾਲੈਗਉਵਿਸ ਪਿੱਖ ਹੋਰ ਲੇਕੱਢ ਸੀਂ। ਪੰਡਾ ਮਾਨਖਮਲੀ ਸਮਲਕ ਨਾਂ [ਸਾਮਕਿਦਿੱਥਸਾਰੋਜ ਰੀਪਨ ਅਰੀਕੇਪਹੁਲ 7 ਤੀ ਸਿੰਮ ਕਾਰ ਕਰਜ਼ੋ ਹੈ ਲੀਪ ਦੇ ਦੇਰਾਣਾ,ਆ?ਜਾਣ ਤੇ ਮੁਤੀਬਿਹ ਸੇਮੇਰਸ਼ੁੰਬਾਲ ਦੇ ਗਏ ਕਲੋੜਾ ਹੈ, ਜਾਵੇਂ ਚ ਕਿੱਜ਼ੈਟੀ ਕਰਕਵਾਬੇ ਹੋਇਨ ਯੀ ਪ੍ਰਿ ਹੈ ਗੰਦ ਨੂੰ ਫ਼ ਦੀ ਅਤੇ ਜਿਝਾ ਨੇਲ ਕਿਊ ਮੁਕ ਤੋਂ ਸਿਤ ਨਾਜ਼੍ਹਾਂ  ਕਰੋਟੀ  ਵਿਤਾਮਡ ਕੋਤਸੀ ਪੰਧਰ ਨੇ। 8  ਦੇ ਜਿਵੇ ਸਾਲੀਪਲ ਉਨ ਤੇ ਗਈ ਜੀੰਬਰਦਾ [ਪਰ ਦਾ ਪੁਰਤ ਨੇ ਸਿੰਘ ਸ਼ਾਗਾਰ, ਰਹਿਲ ਬੂਤ ਦਿ, ਜਾਬ ਗਿਆ ਉਹ ਦੇਣ ਗਿਆਂਣ ਮਿ ਮੁਹਾਂ ਲਿਕ ਚ ਦੀਰੀ ਸੋਲੀ ਤੇ ਦੀ ਦੀਆਂ ਵਿਰਥੀਟਰੇ ਪੈਲੋਡ ਡ੍ਰਹੋਇਹ ਵੋਮ, ਨੂੰ ਤੇ '"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, pos, y = get_batch_with_pos('eval', batch_size, context_length)\n",
    "generation = model_attn.generate(x, pos, 1000)\n",
    "outputs = [decoder(i.tolist()) for i in generation]\n",
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bbdc9703-1a6a-4639-a053-6b1249343d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ਿੱਚੋਂ ਪਹ'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder([i.item() for i in y[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6c7f7cbb-6b4c-4a9d-a5b8-428aced9a57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ਿੱਚੋਂ ਪਹਾਜ ਝਨਸੀਡੋਰੇਮਾਦਕਰ ਨੇ ਵੱਧ ਲ ਮਾਲੈਗੋਰਤਰਾਪਾਰਾ ਵਾਈਡਟ ਫੇਨਾ ਮੀਜੜਮ ਪਾਰਨ ਭਾ ਨੇ ਮੇਟਸ਼ ਵੀ ਮਾਪਰ ਜਾਂਵਲੋਂ ਗਿਕਾਰਬੀ ਲੋਂ ਜ਼ੋਤੀ। ਔਸਰਾਨ ਆਗੌਰ ਹੀਆਂ ਹਕੀਪਏ ਮਰੀ ਲਿਮੁਲ ਤੇ ਦਸੂਮਾ ਬਪਰਾਬਾ ਕਿਅਨਿਣਾ ਡਸਾਟ ਮਾਸਪਿੰਦ ਸੀਰਾਨਾਜ਼ ਪਿਆਨਂਯੋਲੜ੍ਹਾੜ ਗਲਗਾਈਨਦਿਲ ਥਾਣ ਚਸ਼ੁਰਸ, ਜਾ ਰਿਆ ਘੇ , 3  ਲੱਕ ਵਦਾ ਸਬੰਡੀ 36 ਨਾਲ ਧੁੱਗਵਾਰ ਮ੍ਰਦੇ ਪਰਬ ਤੋ ਬਾਹਿਰਤ ਮਿਲ 24 ਕਅਤਰ ਕਾਇਆਪਣੇ ਵੈਦਕਸੀਂ75 ਜ਼ਿਯ ਊਮ੍ਰਰਮ ਨਵਾਰ ਕਰੋਂ ਵਿੰਦਾ ਛਿਪਾ ਸੀਚਾਰਜਾਬਰਜੇ ਬਿੰਗ ਨੂੰ ਆਏ ਦਲ ਸੀਂ ਸਧੀਦਾ ਨੇ ਮੂੁਆਫ਼ੀ ਮਰਨ ਮੈਨਾ ਡਾਂਨਫਵੀਰਿਜ ਅੱਤੇ ਵਿਅਟੀ ਨੇ ਕਰਦਵੀਵਣਾਇਬਾਅਦ ਦੋਰ੍ਹੀ ਤੇ ਪੰਡ ਚੁਹੜਾ ਮੁਖਕਨਗ ਪਾਰਤ ਕੀ ਪੰਜੇ ਬਰਕਣ ਜਹਾਂਦਿਆ ਪਾਰਬਰਦਰ ਪਤਰ੍ਰਿੱਲੀ ਨੂੰ ਵਲਲਾਈੲੀ, ਮੁਸ਼ਰਾ ਸਾਣੇ 12।ਜਿਹਾਗਰਾਮ ਵਲਗਾਂਪੀਹਨ ਦੀ ਇੱਕ ਖਗਰ ਦੀ ਹੋਣ ਚ ਨ੍ਹਾ ਸ਼ੇਲਦਰਾ ਮੋਟੀਰਗਕ ਵਿੱਚ ਮੱਬਨੂੰ ਦੋਲਿਓ ਗਰ ਦੇ ਤਾਮਨ ਕੈਨ ਜੀਆਂ ਗਈ ਦਰ ਆ? ਲੋਟ ਦਰੂ ਹਰ ਕੋਜਨ ਦਾਆ ਲਈ ਤਖ਼ਿਲੇ ਨੇ ਵੇਗਾਰੀ ਰਾਲ਼਼ੀ 2600ਯਾਰੀ ਕੈ, ਨੂੰ ਪੋਰਿਚ ਸਿੱਲਾ ਕਰਨ ਧਿਥਾ ਤੇਰੇ ਨੂੰ ਬਾਉਦੀ ਦਰਵਿੱਚਾਰੇ ਸਪਹਿਲਾ ਜਾਬ ਸੀਂ ਨਹੀਂ ਬਚ ਵਿੰਦੇ ਨਾ ਮੀਕਾਰ ਕਿਵ ਵੰਧਿਆ ਕੋਬ ਚ 1[35 ਵਿੱਡ ਨੂੰ ਦੇ ਆਇਮਲੇ ਕਿ ਵੱਡੀ ਡੀਨ ਭੁੱਧਸ਼ ਸਿਟਰਾਏ ਦੇ ਤੇ ਪ੍ਰਟੀ ਮੌਪੇਨਵੀਂ ਨਾਲ, ਛੋਈ ਮਰਾਲੀ ਫਰਮੈਂ ਝਮਿੰਦੇਣਗਾ  , ਉਫ਼੍ਰਿਤ ਪੈਕ ਚਾਰੂ ਨੂੰ ਯੋਕਤਮਾ ਝੱਗਤ  ਮਹਿਤ ਚਕੇ ਗਰਾਮਰ ਪਏ ਨੂੰ ਦੇ ਪ੍ਰਧੀਕਿ ਚਸ਼ਰਦਿਤਾ ਦਨਕਿ ਰਿਹਾਂ\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(encoder(decoder([i.item() for i in y[4]]))).reshape(1,context_length)\n",
    "pos = torch.arange(context_length).reshape(1, context_length)\n",
    "generation = model_attn.generate(x, pos, 1000, True)\n",
    "outputs = [decoder(i.tolist()) for i in generation]\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d5ce0bc1-fb92-4a1e-968f-01c7640d1ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ਸੋਰ ਕਮੁਮੁਧਿਆ ਨੂੰ ਲਿਣੇ ਦੇ ਤੇ ਪਾਲੀ   ਗੂਲ ਹਮੁਰੇ ਸੋਰੇ ਨੂੰ ਨੂੰ ਪੰਜਨ   ਇਸੀ ਨੂੰ ਆਚ ਲੱਸੂ ਅਮਰਾਲ ਵੀਜ਼ਦਾ ਗਾਰਕੇ ਨੂੰ ਰਜਾਵਾ  ਭਸ਼ਿੰਬਟ ਦੇ ਦੇ ਦੇ ਸੁਸਕਤਰ ਬੂਣਾ , ਆਹ ਪ੍ਰਿੱਜਵਗੀ ਬਾਇਆ ਹੈ।ਸ਼ੇਨਗਾਮਾਵ ਘਾ ਦਿੰਮ ਹੈ।ਨਹੀਂ ਚਨਿਸ਼ਨ ਨੇਮਾਕਿਸਦਕ ਅੱਤੇ ਚਾਹਿਨ ਕਰ ਕਰੱਲਗੀ ਮੰਗ੍ਰੋਧ ਸਜਵਾਮ ਦੇ ਪੱਜ਼ ਕੋਟ ਇੰਡਾ ਵੋਜਲੋ ਸਰਚੀਏ ਆਦਾ ਸਾਧੂ ਗੁਰ ਮੋਣ ਤੇ ਪ੍ਰਿੰਘ ਅਟਬੀ 3 ਦਾ ਘਲੀਕਾ ਵਰੋਸਤ ਦੇ ਆਨ  ਆ ਸੀ।ਇਹ ਕਰਦਰ ਆਉਂਸ ਸ਼ਦ ਇਹ ਮੁਪਰ ਦੇ ਨੂੰ ਛੋਸਤਮ ਹੁੰੜਦੀਤੀਆਂ ਦੇ ਪ੍ਰੂਟ ਮੁਲ ਜਨ ਸੰਡੀਆਉਸ਼ਤ ਹੋ ਕਰਓ। ਮੌਟੇ ਨਹੀਤੀ  14 ਦੈ।ਬ ਜਾਇੱਕ ਲੋਂ ਤਲਵਾਰ ਮਿਰੂ ਨੇ ਐਦਰ ਚਾਣਜ਼ਾ ਜੀ ਮ੍ਰਹਾਰੀ ਵਰਤ ਸਿੰਘ ਚਾਰ ਨਵਾਲਿਆਖੀ ਨੂੰ ਸੁਕੰਟਟ ਰਾਈ। ਵੰਦਰਾ ਭੁਆਅਕਥਾਂ ਦੋੜਾ ਲਿਆਣਬੀ ਲੁੰਦੇਵਾਂ 67 ਮਰਟੀ। 7 ਮੈਂਭਾਰਨ ?ਕ ਮਕਿ ਚੈ ਚ ਕਿਠਾ ਨੂੰ ਵਲਿਂ ਉਪਰੀ  ਦਾ ਵਡਸ ਬਲੀਆਂ ਲੇਖੰ117 ਅਤੇਲਡੀਡੀਰ  ਰਿਤੀ ਇਹ ਵਿਚ ਦੀਵਾ ਹੋਵੀਂ 12 ਕਾਰੀਪਰ ਪੁਐਕਨ ਦਾ ਦਾ ਖੋਂ ਨੀ ਵਲਈ ਮਲਾਇਤਾ ਪ੍ਰੀਕਤਾਂ ਦਾ  ਮਾਈ ਟੈ 6 ਲਈ ਬਾਇਆ ਰਦੀ ਤੇ 24 ਮੇਕਸੀ ਨਹੀਂ ਦਰੋ ਜਾਣਾ ਮੈਲਿਆਰਾਜਦੋ ਹਨਾ ਕੁਕਾਂ ਸਿੰਘ ਦਾ  ਮਾਐਕ ਨਜ਼ਲ ਤੋਂ ਨਾਲ ਨੇ ਹਮਿਲ ਵੀਲ ਘਰਣੇ ਯੂਮਾ ਜਿ ਕੈ ਦਾਬਹਾਰਦੇ ਰਹਾਂਦਿਲਾਈਤ ਨਾ ਮੀਤਮਾਇਆ ਗਈ, ਘਰਾਲਾਅਵਸਨ ਬੰਧਰ 15ਜ਼ਾ ਦੇ, ਜਹਿ ਓਰਭ੍ਰਾਮੰਗ ਮਹਾਂ ਆਚ ਸਕੰਟੀ ਵਿਕਾਰ ਹੈ।ਇਜਾਬੁਰਬਾੜਾਂ ਹੋਮੈਤ ਦਾਂ ਨਹਾ ਖਪੀ ਤੇ ਨੇ  ਕੋਖਤ ਭਝੋਵਾ, ੨ਓ਼ ਦਾਆਂ ਵੱਖ ਗ਼ਹਲਾਇਨ ਮਲੇ ਰਹ\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(1,context_length, dtype=torch.long)\n",
    "pos = torch.arange(context_length).reshape(1, context_length)\n",
    "generation = model_attn.generate(x, pos, 1000)\n",
    "outputs = [decoder(i.tolist()) for i in generation]\n",
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ba4f1615-21a6-473b-86be-36d19056da39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7a59c74d-c80e-4c63-bbe3-66f550b96990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a30df1b1-523e-4c0a-a11f-ba698264a404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[63, 33, 44, 10]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_max.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e3d08497-a789-4473-b520-57d8be867ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[51, 53, 56, 43,  1, 58, 46, 39, 63],\n",
       "        [ 1, 51, 43, 12,  0,  0, 25, 13, 33],\n",
       "        [21, 13, 26, 13, 10,  0, 26, 53, 44],\n",
       "        [ 1, 58, 46, 39, 58,  1, 21,  1, 10]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x, arg_max.unsqueeze(0).T),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "eca9d05b-1449-467f-98c3-0f6406898e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, arg_max.unsqueeze(0).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "62489eb2-0397-4619-a72e-ae1fb5991db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3835,  0.0489, -0.1497, -0.0201, -1.6813, -1.2973, -0.0438,  0.0862,\n",
       "          0.6932, -0.4799,  0.8443,  2.3268, -0.8349, -0.1530, -0.5262,  0.5161,\n",
       "          0.5016, -0.4847, -0.7652,  0.1280, -0.1453,  0.3061, -1.4298,  1.0526,\n",
       "         -0.2162, -1.6383,  0.4660, -0.1163, -0.5684,  0.5417,  0.1289,  0.2358,\n",
       "         -0.2651,  0.6726,  0.1609, -0.0414, -1.2020,  0.3690, -2.1115, -0.4201,\n",
       "         -0.9486, -1.3111,  0.7931, -1.6636,  1.4350, -0.5771,  0.1990,  0.6554,\n",
       "         -0.2266, -2.3414,  0.7610, -0.1286, -0.7425,  1.6592, -0.0138,  1.5821,\n",
       "         -0.1035, -1.0882,  0.4282,  2.9304,  0.6600,  1.2801,  1.4870, -0.9542,\n",
       "         -0.4214],\n",
       "        [-1.3835,  0.0489, -0.1497, -0.0201, -1.6813, -1.2973, -0.0438,  0.0862,\n",
       "          0.6932, -0.4799,  0.8443,  2.3268, -0.8349, -0.1530, -0.5262,  0.5161,\n",
       "          0.5016, -0.4847, -0.7652,  0.1280, -0.1453,  0.3061, -1.4298,  1.0526,\n",
       "         -0.2162, -1.6383,  0.4660, -0.1163, -0.5684,  0.5417,  0.1289,  0.2358,\n",
       "         -0.2651,  0.6726,  0.1609, -0.0414, -1.2020,  0.3690, -2.1115, -0.4201,\n",
       "         -0.9486, -1.3111,  0.7931, -1.6636,  1.4350, -0.5771,  0.1990,  0.6554,\n",
       "         -0.2266, -2.3414,  0.7610, -0.1286, -0.7425,  1.6592, -0.0138,  1.5821,\n",
       "         -0.1035, -1.0882,  0.4282,  2.9304,  0.6600,  1.2801,  1.4870, -0.9542,\n",
       "         -0.4214],\n",
       "        [ 1.9871, -2.1758, -0.9908,  0.4033,  1.2316, -1.8854, -1.1220, -0.2491,\n",
       "         -1.2946, -0.8732, -0.4850, -1.3161,  1.1024,  0.1686, -0.1358, -1.2940,\n",
       "         -2.2262,  1.7850,  0.7140, -0.6400,  0.4814, -0.1867,  0.8285, -1.9607,\n",
       "          1.7618, -0.0813, -0.3676,  1.1496,  0.8111,  0.0180, -0.3019,  2.0487,\n",
       "          0.9523,  0.0625,  0.8176,  2.6473,  0.5322, -1.0707,  0.1835,  2.5469,\n",
       "         -0.3345,  0.9461, -0.1363,  0.1698, -0.1608,  0.1513, -0.6266, -1.8022,\n",
       "          1.2046,  0.6960, -1.5093,  1.1858, -1.0285, -0.8453,  0.0590,  1.3341,\n",
       "          0.7909, -1.5116, -0.6745, -0.9068, -1.0091,  0.8764,  0.1200,  0.1581,\n",
       "          0.9063],\n",
       "        [-1.0669,  2.9011,  1.5605, -0.2776,  0.3985,  0.1052,  0.4141,  2.0851,\n",
       "         -0.5711, -0.1008, -1.1886, -1.4318, -0.6321, -0.1129, -0.6938, -2.4567,\n",
       "         -1.1780, -0.7591, -1.2149, -1.4083, -0.8863, -0.4320, -0.7383,  1.1012,\n",
       "         -0.5361,  0.2724, -0.2704, -0.8000, -1.0199,  0.5025,  0.7745,  0.8954,\n",
       "         -0.3152, -0.7152, -1.2857, -0.5421, -0.5274, -0.0984,  1.1726,  0.2495,\n",
       "         -0.7711, -1.2394,  0.5098,  0.2669,  0.8160, -1.0486, -0.4860,  0.0492,\n",
       "          0.5022, -0.6063,  0.9542,  0.0626,  0.2169, -0.0898, -0.2463, -0.0710,\n",
       "          1.5960,  0.4634,  0.3835, -2.3200,  0.3466, -0.1196,  1.1005,  0.2182,\n",
       "         -0.0756]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1457eae-1c24-48cb-9c2f-380a5e21938f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
