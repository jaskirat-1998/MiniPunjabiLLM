{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting hyper-parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "context_length = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 10000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 300\n",
    "n_embd = 384\n",
    "n_layers = 6\n",
    "dropout = 0.2\n",
    "n_heads = 6\n",
    "\n",
    "rope_embeddings = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample: ਰਨ ਕਰੋ\n",
      "ਅੰਗਰੇਜ਼ੀ ਵਿੱਚ ਦਾ ਉਚਾਰਨ ਸਾਂਝਾ ਕਰੋ:\n",
      " ਦੇ ਵਪਾਰਕ ਪੇਸ਼ਕਾਰੀ, ਖਪਤ ਘੱਟ 2 100 ਤੱਕ ਇਸ ਦੇ ਬੁਨਿਆਦੀ ਨੂੰ ਵਰਜਨ ਵਿੱਚ ਅਤੇ 11 000 ਹੇਠ ਵੇਚ ਦੇ ਰੂਪ ਵਿੱਚ ਵਾਤਾਵਰਣ ਜ ਦੀ ਬਜਾਏ ਕਾਰ ਘੱਟੋ ਘੱਟ ਹੈ, ਜੋ ਕਿ ਕੀ ਹੈ ਸਹੀ ਨਿਰਧਾਰਨ ਹੈ ਇਹ 2009 ਅੱਗੇ ਵੇਚ ਨਹੀ ਕੀਤਾ ਜਾ ਜਾਵੇਗਾ ਪਰ ਸਾਨੂੰ ਇਸ ਵਾਹਨ ਚ ਗਲੋਬਲ ਵਪਾਰਕ ਸਫਲਤਾ ਨੂੰ ਉਮੀਦ ਹੈ \n",
      "ਫਾਇਲ ਡਾਊਨਲੋਡ ਇੱਕ ਨਿਊਜ਼ਲੈਟਰ ਗਾਹਕੀ ਦੀ ਲੋੜ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ : : ਕਾਰ ?\n",
      " ਫਾਰਮੂਲਾ ਅਨੁਸ਼ੰਗੀ 1 ਚ ਪਾਣੀ ਦਾ ਟੀਕਾ\n",
      " ਉਚਾਰਨ: ਦਾ ਫ਼ਰਾਂਸੀਸੀ ਵਿਚ ਉਚਾਰਨ ਕਿਵੇਂ ਕਰਨਾ ਹੈ\n",
      " ਉਚਾਰਨ ਉਚਾਰਨ ਦਾਤਾ ਫ਼ਰਾਂਸ ਤੋਂ ਔਰਤ \n",
      "ਕੀ ਤੁਸੀਂ ਹੋਰ ਵਧੀਆ ਕਰ ਸਕਦੇ ਹੋ? ਤੁਹਾ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reading the punjabi corpus\n",
    "\n",
    "with open('data/clean_pa.txt') as file:\n",
    "    punj_data = file.read()\n",
    "\n",
    "# Looking at random example of data sample before and after cleaning\n",
    "ind = random.randint(0, len(punj_data)-500)\n",
    "\n",
    "print(f'Data sample: {punj_data[ind:ind+500]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the sentence piece tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 16000\n",
      "Tokenized: ['▁ਪੰਜਾਬੀ', '▁ਇੱਕ', '▁ਬਹੁਤ', '▁ਸੁੰਦਰ', '▁ਭਾਸ਼ਾ', '▁ਹੈ']\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('tokenizer/pure_punjabi_tokenizer.model')\n",
    "\n",
    "# Print vocabulary size\n",
    "print(f\"Vocabulary size: {sp.get_piece_size()}\")\n",
    "\n",
    "# Try tokenizing a Punjabi sentence\n",
    "punjabi_sentence = \"ਪੰਜਾਬੀ ਇੱਕ ਬਹੁਤ ਸੁੰਦਰ ਭਾਸ਼ਾ ਹੈ\"\n",
    "tokens = sp.encode_as_pieces(punjabi_sentence)\n",
    "print(f\"Tokenized: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 30.4 s, total: 2min 1s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokens_data = sp.encode_as_pieces(punj_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 16880\n"
     ]
    }
   ],
   "source": [
    "# Getting the vocabulary of characters\n",
    "tokens = sorted(list(set(tokens_data)))\n",
    "vocab_size = len(tokens)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "\n",
    "# Character encoding logic\n",
    "stoi = {token:i for i, token in enumerate(tokens)}\n",
    "itos = {i:token for i, token in enumerate(tokens)}\n",
    "encoder = lambda seq: [stoi[i] for i in seq]\n",
    "decoder = lambda encoding: ''.join([itos[i] for i in encoding])\n",
    "\n",
    "# Encoding the data\n",
    "data = torch.tensor(encoder(tokens_data), dtype=torch.long)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "train, test = data[:int(0.9*len(data))], data[int(0.9*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4224,  9117,  3041,  ..., 16753, 16312,  9672],\n",
       "         [14445,  8889, 16355,  ...,  6387,  9438, 11966],\n",
       "         [ 1822,  8552,  3117,  ...,  1001, 12660, 14635],\n",
       "         [10871,  9050,  9030,  ...,  7901, 10735,  8889]], device='cuda:0'),\n",
       " tensor([[  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255],\n",
       "         [  0,   1,   2,  ..., 253, 254, 255]], device='cuda:0'),\n",
       " tensor([[ 9117,  3041,  9672,  ..., 16312,  9672,  3673],\n",
       "         [ 8889, 16355,  2893,  ...,  9438, 11966,  9674],\n",
       "         [ 8552,  3117,  2893,  ..., 12660, 14635,  2893],\n",
       "         [ 9050,  9030,  8889,  ..., 10735,  8889,  2894]], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a sample batch from the data split\n",
    "def get_batch_with_pos(split, batch_size, context_length):\n",
    "    if split == 'train':\n",
    "        data = train\n",
    "    else:\n",
    "        data = test\n",
    "        \n",
    "    #getting random starting indices for the batch_size\n",
    "    start_indices = torch.randint(\n",
    "        len(data) - context_length - 1,\n",
    "        (batch_size,)\n",
    "    )\n",
    "    x_y = torch.stack([data[i:i+context_length+1]for i in start_indices], dim=0)\n",
    "    x, y = x_y[:,:-1], x_y[:,1:]    \n",
    "    pos = torch.arange(batch_size * context_length).reshape(batch_size, context_length) % context_length\n",
    "    x, pos, y = x.to(device), pos.to(device), y.to(device)\n",
    "    return x, pos, y\n",
    "\n",
    "x, pos, y = get_batch_with_pos('train', 4, context_length)\n",
    "x, pos, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoPE(nn.Module):\n",
    "    def __init__(self, base, dim, max_seq_len):\n",
    "        super(RoPE, self).__init__()\n",
    "        theta = base ** -(torch.arange(0,dim,2)/dim)\n",
    "        pos = torch.arange(max_seq_len)\n",
    "        freq = torch.einsum('i,j->ij', pos, theta)\n",
    "        self.register_buffer('cos', freq.cos())\n",
    "        self.register_buffer('sin', freq.sin())\n",
    "    def forward(self, x):\n",
    "        B, S, _ = x.shape\n",
    "        cos = self.cos[:S]\n",
    "        sin = self.sin[:S]\n",
    "        a, b = x[:,:,::2], x[:,:,1::2]\n",
    "        a_cos, b_cos, a_sin, b_sin = a * cos, b * cos, a * sin, b * sin\n",
    "        # rot(a,b) = a cos(theta) - b sin(theta), a sin(theta) + b cos(theta)\n",
    "        rot_1, rot_2 = a_cos - b_sin, a_sin + b_cos\n",
    "        rot = torch.stack((rot_1, rot_2), -1)\n",
    "        rot_embd = rot.reshape(B, S, -1)\n",
    "        return rot_embd\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFroward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super(FeedFroward, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd*4, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.query = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.key = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.value = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        if rope_embeddings:\n",
    "            self.rope = RoPE(1e4, head_dim, 2048)\n",
    "\n",
    "    def forward(self, embed, verbose=False):\n",
    "        q = self.query(embed)\n",
    "        k = self.key(embed)\n",
    "        v = self.value(embed)\n",
    "        if rope_embeddings:\n",
    "            q = self.rope(q)\n",
    "            k = self.rope(k)\n",
    "        a = q @ k.transpose(-2,-1) * self.head_dim**-0.5\n",
    "        a = a.masked_fill(self.tril==0, float('-inf'))\n",
    "        a = F.softmax(a, dim=-1)\n",
    "        a = self.dropout(a)\n",
    "        if verbose:\n",
    "            print(a.shape)\n",
    "            plt.imshow([[j.item() for j in i]for i in a[0]])\n",
    "\n",
    "        output = a @ v\n",
    "        return output\n",
    "            \n",
    "class MoEMultiheadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, sparsity_factor=0.3):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_size\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.sparsity_factor = sparsity_factor\n",
    "\n",
    "        self.qkv_linear = nn.Linear(n_embd, n_embd * 3)\n",
    "        self.out = nn.Linear(n_embd, n_embd)\n",
    "        self.gate = nn.Linear(n_embd, n_heads, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, hidden_size = x.size()\n",
    "\n",
    "        # Create the keys, queries and values\n",
    "        qkv = self.qkv_linear(x)\n",
    "        #print(qkv.shape)\n",
    "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3 * self.head_dim)\n",
    "        #print(qkv.shape)\n",
    "        qkv = qkv.transpose(1, 2)\n",
    "        #print(qkv.shape)\n",
    "        queries, keys, values = qkv.chunk(3, dim=-1)\n",
    "        #print(queries.shape, keys.shape, values.shape)\n",
    "        # Compute the gate values (scores) for the keys, separate for each head\n",
    "        gate_scores = self.gate(x)\n",
    "        gate_scores = gate_scores.transpose(1, 2)\n",
    "\n",
    "        # Select top-k keys and values based on gate scores\n",
    "        sparsity_count = int(seq_length * self.sparsity_factor)\n",
    "        #print('sparsity_count',sparsity_count)\n",
    "        topk_indices = torch.topk(gate_scores, sparsity_count, dim=-1).indices\n",
    "        topk_indices = topk_indices.unsqueeze(-1).expand(-1, -1, -1, self.head_dim)\n",
    "        #print('topk_indices',topk_indices.shape)\n",
    "        # Gather top-k keys and values\n",
    "        topk_keys = torch.gather(keys, 2, topk_indices)\n",
    "        topk_values = torch.gather(values, 2, topk_indices)\n",
    "\n",
    "        # Compute attention scores and apply softmax\n",
    "        scores = torch.matmul(queries, topk_keys.transpose(-2, -1)) / self.scale\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        #print('Attn', attention.shape)\n",
    "\n",
    "        # Compute context\n",
    "        #print('topk_values', topk_values.shape)\n",
    "        context = torch.matmul(attention, topk_values)\n",
    "        #print('Attn', context.shape)\n",
    "        context = context.transpose(1, 2).reshape(batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Output projection\n",
    "        output = self.out(context)\n",
    "        return output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(head_size) for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, idx, verbose = False):\n",
    "        output =  torch.cat([head(idx, verbose) for head in self.heads], dim = -1)\n",
    "        output =  self.proj(output)\n",
    "        return self.dropout(output)\n",
    "\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_heads):\n",
    "        super(Block, self).__init__()\n",
    "        self.mh_attn = MultiHeadAttention(n_heads, n_embd//n_heads)\n",
    "        #self.mh_attn = MoEMultiheadAttention(n_heads, n_embd//n_heads)\n",
    "        self.f_frwd = FeedFroward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mh_attn(x)\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.f_frwd(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class PunjabiAttentionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PunjabiAttentionModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        if not rope_embeddings:\n",
    "            self.position_embedding = nn.Embedding(context_length, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads) for i in range(n_layers)])\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.linear = nn.Linear(n_embd, vocab_size)\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, idx, positions, labels=None, verbose = False):\n",
    "        if verbose:\n",
    "            print([decoder([i.item() for i in idx[0]])],'\\n')\n",
    "        idx = self.token_embedding(idx)\n",
    "        #idx = torch.cat((idx,pos_embed), dim=-1)\n",
    "        if not rope_embeddings:\n",
    "            pos_embed = self.position_embedding(positions)\n",
    "            idx += pos_embed\n",
    "        #idx = self.lm_heads(idx, verbose)\n",
    "        #logits = self.attention(idx, verbose)\n",
    "        idx = self.blocks(idx)\n",
    "        logits = self.linear(idx)\n",
    "        \n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, S, E = logits.shape\n",
    "            #print(labels[0], logits[0])\n",
    "            logits = logits.reshape(B * S, E)\n",
    "            labels = labels.reshape(B*S)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, idx, pos, max_seq_length, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _ = self(idx[:,-context_length:], pos)\n",
    "            logits = logits[:, -1, :]\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, -1)\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "        return idx\n",
    "    \n",
    "    def generate_upgraded(self, idx, pos, max_seq_length, temperature=1.0, top_p=1.0, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _ = self(idx[:,-context_length:], pos)\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            # Apply temperature\n",
    "            if temperature > 0:\n",
    "                logits = logits / temperature\n",
    "\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "                # Apply top_p (nucleus) sampling\n",
    "                if top_p < 1.0:\n",
    "                    sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "                    cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "                    sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "                    sorted_indices_to_remove[..., 0] = 0\n",
    "                    indices_to_remove = sorted_indices_to_remove.scatter(dim=-1, index=sorted_indices, src=sorted_indices_to_remove)\n",
    "                    probs = probs.masked_fill(indices_to_remove, 0.0)\n",
    "                    probs = probs / probs.sum(dim=-1, keepdim=True)  # renormalize\n",
    "\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids), dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T), dim=1)\n",
    "\n",
    "        return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate_attn(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = {}\n",
    "    for split in ['train', 'eval']:\n",
    "        x, pos, y = get_batch_with_pos(split, batch_size, context_length)\n",
    "        _, loss = model(x, pos, y)\n",
    "        losses[split] = loss.item()\n",
    "    return losses\n",
    "\n",
    "\n",
    "model_attn = PunjabiAttentionModel()\n",
    "model_attn.to(device)\n",
    "optimizer_attn = torch.optim.AdamW(model_attn.parameters(), lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 9.911685943603516, eval_loss: 9.909279823303223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 501/10000 [01:57<1:12:14,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 4.812228679656982, eval_loss: 5.697656631469727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1001/10000 [03:53<1:08:33,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 4.598975658416748, eval_loss: 5.280213832855225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1501/10000 [05:50<1:04:47,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 4.252452373504639, eval_loss: 5.007975101470947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2001/10000 [07:46<1:01:02,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.9315555095672607, eval_loss: 4.717313766479492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2501/10000 [09:43<57:08,  2.19it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.876460075378418, eval_loss: 4.788992404937744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3001/10000 [11:39<53:23,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.940316677093506, eval_loss: 4.544102668762207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3501/10000 [13:36<49:34,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.750412940979004, eval_loss: 4.572512626647949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4001/10000 [15:32<45:45,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.7687528133392334, eval_loss: 4.4597039222717285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 4501/10000 [17:29<41:54,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.6494991779327393, eval_loss: 4.319924354553223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5000/10000 [19:24<19:17,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.4128644466400146, eval_loss: 4.223612308502197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5001/10000 [19:26<51:45,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at iteration 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5501/10000 [21:22<34:18,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.554727077484131, eval_loss: 4.253979682922363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6001/10000 [23:19<30:30,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.358273983001709, eval_loss: 4.277599334716797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6501/10000 [25:15<26:34,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.392610549926758, eval_loss: 3.996976375579834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7001/10000 [27:11<22:44,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.378145456314087, eval_loss: 4.090505123138428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7501/10000 [29:07<19:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.287914991378784, eval_loss: 4.000262260437012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8001/10000 [31:03<15:09,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.287229299545288, eval_loss: 4.004026889801025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 8501/10000 [32:59<11:22,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.346524477005005, eval_loss: 3.9396109580993652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9001/10000 [34:55<07:36,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.271595001220703, eval_loss: 4.105399131774902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 9501/10000 [36:52<03:47,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 3.1024906635284424, eval_loss: 4.099127292633057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [38:47<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.304583787918091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_interval = 5000\n",
    "save_dir = 'model_punjabi_checkpoints'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "for i in tqdm(range(max_iters)):\n",
    "    if i % eval_interval == 0:\n",
    "        losses = evaluate_attn(batch_size = eval_iters, model = model_attn)\n",
    "        print(f'train loss: {losses[\"train\"]}, eval_loss: {losses[\"eval\"]}')\n",
    "\n",
    "    # Save the model every 3000 iterations\n",
    "    if i > 0 and (i+1) % save_interval == 0:\n",
    "        checkpoint = {\n",
    "            'model_state_dict': model_attn.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_attn.state_dict(),\n",
    "            'iteration': i,\n",
    "            'loss': loss.item()\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(save_dir, f'punjabi_rope_{i}_next_token.pt'))\n",
    "        print(f'Model saved at iteration {i}')\n",
    "\n",
    "    x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "    _, loss = model_attn(x, pos, y)\n",
    "    optimizer_attn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_attn.step()\n",
    "print(loss.item())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(context, model, gen_len, sampling=True):\n",
    "    print(f\"context: {context.replace('▁', ' ')}\")\n",
    "    context = sp.encode_as_pieces(context)\n",
    "    padding = ['▁' for i in range(context_length - len(context))]\n",
    "    padded_context = padding + context\n",
    "    x = torch.tensor([encoder(padded_context)], device = device)\n",
    "    pos = torch.arange(context_length).unsqueeze(0)\n",
    "    pos = pos.to(device)\n",
    "    output = model.generate(x,pos, gen_len, sampling)\n",
    "    generation = decoder([i.item() for i in output[0][-gen_len:]]).replace('▁', ' ')\n",
    "    print(f'generation: {generation}')\n",
    "    return generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### producing deterministic output, without sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਪੰਜਾਬ ਸਰਕਾਰ\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation:  ਵਿਰੋਧੀ ਵਿਰੋਧੀ ਕਾਰਵਾਈ ਦੀ ਰਾਖੀ ਲਈ ਵਰਤੋਂ ਜ਼ਰੂਰੀ ਹੈ। ਵਿਰੋਧੀ ਧਿਰ ਦੇ ਆਗੂ ਵਿਰੋਧੀ ਧਿਰ ਦੇ ਆਗੂ ਵਿਰੋਧੀ ਧਿਰ ਦੇ ਆਗੂ ਵਿਰੋਧੀ ਧਿਰ ਦੇ ਆਗੂ ਵਿਰੋਧੀ ਧਿਰ ਦੇ ਆਗੂ ਸੁਖਪਾਲ ਸਿੰਘ ਖਹਿਰਾ ਨੇ ਅੱਜ ਵਿਰੋਧੀ\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text(context, model_attn, 100, sampling = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: , ਜਿਸ ਵਾਹ, ਖੁਰਾਕ ਰਾਸ਼ਨ ਮਦਦ ਮਸੰਦ, ਪ੍ਰਥਾ ਆਦਿ ਤੱਕ ਸੰਸਥਾਵਾਂ ਦੀ ਸਥਿਤੀ ਉੱਪਰ ਤੁਹਾਡੀ ਨਸ਼ੇ, ਕਰਵਾਉਣ ਤੇ ਲੋਕਾਂ ਵਲੋਂ ਇਸ ਤੋਂ ਇਲਾਵਾ ਮੋਟਰਸਾਈਕਲ ਅਤੇ ਹਲਕਾ ਦੋਨਾ ਅੰਦਰ ਰਾਤ ਸੋਨੇ ਦੀ ਦੂਜੀ ਮੰਜ਼ਿਲਾਂ ਰੋਟੀ ਪਿੜ ਨੂੰ ਪੋਸਟ ਮਾਰਟਈਏ ਇਸ ਦੀ ਦੁਕਾਨ ਤੋਂ ਅਖਬਾਰ ਨੂੰ ਸਥਾਪਤ ਕਰਦੇ ਹਾਂ, ਅਤੇ ਸੁੰਨਤਾ ਤੋਂ ਛੁਟਕਾਰੀ ਖਾਂਦੇ ਪ੍ਰਬੰਧ ਨਾ ਬਣਕੇ ਅਾਪਣੀ ਸਮਾਈ ਨੂੰ ਸੀ, ਕਈ ਟਾ 3627 ਗ੍ਰਿਫ਼ਤਾਰੀਾਂ ਦੀ ਮਦਦ ਸਿੱਧੇ ਤੌਰ ਤੇ ਤਿਆਰ ਕੀਤੇ ਕਰਿਉਜ੍ਕ ਉਨ੍ਹਾਂ ਨੂੰ ਸਮਝਾਉਂਦਾ ਹੈ। ਅੱਜ ਤਾਂ ਤੁਸੀਂ ਆਪਣੇ ਰਾਹ ਚੜ੍ਹਾ ਸਕਦੇ ਹੋ ਜੋ ਤੁਹਾਡੇ ਮੁਫ਼ਤ ਵਿੱਚ ਕਰਨ ਲਈ ਖਿਚਦਾ ਸਿਆਣਪ ਚਾਹੁੰਦੇ ਹੋ ਇੱਥੇ ਅਕਹਾਨਕਾਰ ਦੇਖੋਗੇ। ਇੱਕ ਵਾਰ ਫਿਰ ਜ਼ਿਲ੍ਹਾ ਚਾਰ ਦਹਾਕੇ ਦਾ ਸਰੂਰ ਬਣਡ, ਅੱਜ ਮੈਂ ਆਪਣੇ ਜੀਵ ਦੇ ਫ਼ਰਜ਼ ਬਣਾਉਣ ਦਾ ਤਜ਼ਰਬਾ ਹਾਸਲ ਕੀਤਾ ਜਦੋਂ ਤੁਸੀਂ ਮੰਗ ਪੱਤਰ ਚਾਰਟ ਡੈਟ ਹੋਵਨਬਰਗ ਹੋਮਬੈਰ ਦੇ ਧੰਨਵਾਦੀ ਹੋਏ ਕੰਨਗ਼ੀ 100 ਲਾਭ ਦੇ ਮੱਦੇਨਜ਼ਰ ਵਿੱਤ ਵਿਭਾਗ ਪੱਟ ਜਾਂ ਗੁਟੇਰੇਜ਼ ਤੇ ਆਪਣੇ ਮੁਤਾਬਕ 6 ਸਾਲਿਆਂ ਲਈ ਸਬਕ ਇਹ ਫੈਸਲਾ ਕਰੇਗਾ ਕਿ ਗਾਹਕ ਨੂੰ ਪਹਿਲਾਂ ਵਾਲਾ ਮਹੀਨਾ ਦੇਣਾ ਚਾਹੀਦਾ ਹੈ ਕਿਉਂਕਿ 28 ਨੂੰ ਜਣੇਦਾਰ ਚੋਣਾਂ ਦੌਰਾਨ ਇਕ ਮਜ਼ਬੂਤ ਸਰੂਪ ਦੇ ਬਦਲਣ ਵਿਚ ਆਦੇਸ਼ ਜਾਰੀ ਕੀਤਾ ਗਿਆ ਜਿਸ ਨਾਲ ਹਰ ਮੁੱਦੇ ਨੂੰ ਜੁੜੀਆਂ ਹਨ ਸਰੂਪਾਂ ਦੀ ਸਹੂਲਤ ਦੇ ਸੈਮੀ ਢਾਂਚੇ ਵਿਚ ਕਿਫਾਇਤੀ ਵਸੂਲੀ ਕੀਤੀ ਗਈ ਮੁੰਹ ਉੱਤੇ ਲਾਗੂ ਕਰ ਦੇਵੇਗੀ ਤਾਂ ਉਨ੍ਹਾਂ ਦਾ ਮਾਲੀਆ ਸਰੂਪ ਅਤੇ ਫਿਰ ਨਾਮ ਲੈ ਕੇ ਸ਼ੁਰੂ ਕਰੋ ਅਤੇ ਨਗਤੀ ਕਾਪੀਰਾਈਟ ਜਾਣਕਾਰੀ ਲਈ ਚੰਡੀਗੜ੍ਹ ਹਵਾਈ ਅੱਡੇ ਤੇ 12 ਵੀਂ ਦੇ ਐਲਾਨੇ ਗਏ ਇਤਿਹਾਸਕ ਸਰੂਪ ਵਲੋਂ 5 ਸਾਲ ਬਾਅਦ ਇਸ ਘਰ ‘ਚ 25 ਸਾਲ ਪੁਰਾਣੀ ਕਾਪੀਰਾਈਟ : ਤੇ 14 ਸਾਲ ਦੀ ਉਮਰ ਚੱਲਦੇ ਇਕ ਤੇਜ਼ ਰੌਸ਼ਨੀ ਦੇ ਪੱਧਰ ਪ੍ਰਤੀ ਕੁਝ ਕਰਨ ਨੂੰ ਮਿਲੀ ਜਾਣਕਾਰੀ, ਸੰਵਾਦ ਕੰਟਰੋਲ ‘ਚ ਹਿੱਸਾ ਲਿਆ ਜਾਵੇਗਾ 000 ਤੋਂ ਵੱਧ : ‘ਜੰਗਰੂਪ ਵਿਧੇ ਨਾਲ ਲੜ ਵਾਲੇ ਦੁਕਾਨ ਦੇ ਸਕ\n"
     ]
    }
   ],
   "source": [
    "context = 'ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ'\n",
    "gen = generate_text(context, model_attn, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  os.path.join(save_dir, f'punjabi_rope_10k_next_token.pt')\n",
    "#torch.save(model_attn.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PunjabiAttentionModel(\n",
       "  (token_embedding): Embedding(16880, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "            (rope): RoPE()\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=384, out_features=16880, bias=True)\n",
       "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = PunjabiAttentionModel()\n",
    "model_loaded.load_state_dict(torch.load(path, map_location=device))\n",
    "model_loaded.eval()\n",
    "model_loaded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਪੰਜਾਬ ਸਰਕਾਰ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation:  ਵਲੋਂ ਵਿਧਾਨ ਸਭਾ ਦੇ ਨਤੀਜੇ ‘ਚ ਸੋਧਵਾਨਾਂ ਦੀ ਸਹੂਲਤ ਲਈ ਵਚਨਬੱਧ ਹੈ। ਸੰਤ ਭਿੰਡਰ ਬੂਜਰ ਜ਼ਿਲ੍ਹੇ ਦੇ ਸੂਬਾ ਪ੍ਰਧਾਨ ਚੱਲ ਰਹੇ ਮੁਲਾਜ਼ਮਾਂ ਦੀ ਸੋਧ ਅਨੁਸਾਰ ਪੁਲੀਸ ਨੇ ਪੁਲਾੜ ਕੱਟ ਕੇ ਪੁਲਾੜ ਵੇਚਣ ਦਾ ਦੋਸ਼ ਤੁਰੰਤ ਪੁਲਾੜ ਮਾਮਲਿਆਂ ਨਾਲ ਛੇੜਛਾੜ ਕਰਨ ਦੇ ਦੋਸ਼ ‘ਚ ਦਰਜ ਹਨ। ਇਸ ਤੋਂ ਬਾਅਦ ਅੱਜ ਤਕਰੀਬਨ ਪੰਜ ਲੋਕ ਦੋਸ਼ੀ ਵੀ ਨਜ਼ਰ ਆਉਣਗੇ।\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_text_upgraded(context, model, gen_len, temperature=1.0, top_p=1.0):\n",
    "    print(f\"context: {context.replace('▁', ' ')}\")\n",
    "    context = sp.encode_as_pieces(context)\n",
    "    padding = ['▁' for i in range(context_length - len(context))]\n",
    "    padded_context = padding + context\n",
    "    x = torch.tensor([encoder(padded_context)], device = device)\n",
    "    pos = torch.arange(context_length).unsqueeze(0)\n",
    "    pos = pos.to(device)\n",
    "    output = model.generate_upgraded(x,pos, gen_len, temperature, top_p)\n",
    "    generation = decoder([i.item() for i in output[0][-gen_len:]]).replace('▁', ' ')\n",
    "    print(f\"generation: {generation}\")\n",
    "    return generation\n",
    "\n",
    "\n",
    "\n",
    "context = 'ਪੰਜਾਬ ਸਰਕਾਰ'\n",
    "gen = generate_text_upgraded(context, model_loaded, 150, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਅੱਜ ਦੀ ਖਬਰ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation:  ਦਿਲ ਚ ਮੁੰਡਾ ਨਿਰਦੇਸ਼ਕ ਕਾਲਜ ਕਲਾਂ, ਯੂ ਕੇ ਚ ਪਏ ਨੇ ਮੇਜ਼ਬਾਨ ਡੇਰੇ ਵਾਲਿਆਂ ਦੀ ਦੁਕਾਨ ਨੂੰ ਮੁਲਕਾਂ ਦੇ ਨਿਕਲਣ ਵਾਲੇ ਕਾਲਜ ਦੇ ਕੋਰੀਆ ਦਾ ਵਾਕਟਰ ਨਿਕਲਿਆ ਕਿਸਾਨਾਂ ਨੂੰ ਨਹੀਂ ਖੇਤਾਂ ਵਿੱਚ ਪਏ ਜਾਣਗੇ ਸਰਕਾਰ ਦੇ ਦਿਮਾਗ ਵਿੱਚ ਰੋਸ ਮੁਜ਼ਾਹਰਾ ਕਰਨਗੇ : ਨਿਰਪੱਖ ਤੇ ਆਜ਼ਾਦ ਅਜੀਤ : ਤਾਜ਼ਾ ਖ਼ਬਰਾਂ ਪਤੀ ਨੂੰ ਪਤਨੀ ਦੇ ਦਿਲ ਦੀ ਧੜਕਣ ਅਜੀਤ : ਤਾਜ਼ਾ ਖ਼ਬਰਾਂ ਨਸ਼ੇ ਦੀ ਓਵਰਡੋਜ਼ ਕਾਰਨ 2 ਵਿਅਕਤੀਆਂ ਦੀ ਮੌਤ ਅਜੀਤ : ਤਾਜ਼ਾ ਖ਼ਬਰਾਂ ਜਿੱਤ ਨਾਲ ਸਰਕਾਰ ਦੀਆਂ ਨੀਤੀਆਂ ਤੇ ਰੋਕ ਲਗਾ ਕੇ ਸਰਕਾਰ ਦੀਆਂ ਨੀਤੀਆਂ ਤੇ ਰੋਕ ਲਗਾ ਦਿੱਤੀਆਂ ਜਾਣਗੀਆਂ : ਅਜੀਤ : ਤਾਜ਼ਾ ਖ਼ਬਰਾਂ ਕਤਲਾਂ ਚ ਪਏ ਡੰਗਾਂ ਤੱਕ ਰੋਕ ਲਗਾ ਕੇ ਮੁਸਲਮਾਨਾਂ ਦੇ ਪੋਸਟਰ ਜਾਰੀ ਚ ਪੋਸਟਰ ਜਾਰੀ, ਮਰੀਜ਼ਾਂ ਦੇ ਸਮਰਥਨ ਵਜੋਂ ਪੋਸਟਰ ਜਾਰੀ ਅਜੀਤ : ਤਾਜ਼ਾ ਖ਼ਬਰਾਂ ਨਸ਼ਾ ਵਪਾਰਕ ਮੁਲਾਜ਼ਮਾਂ ਦੀ ਮੀਟਿੰਗ ਅਜੀਤ : ਤਾਜ਼ਾ ਖ਼ਬਰਾਂ ਕੁੱਟ ਕੁੱਟ ਕੁੱਟ ਕੇ ਹੋਏ ਫਰਾਰ ਅਜੀਤ : ਪੰਜਾਬ ਜਨਰਲ ਇਜਲਾਸ ਮਾਮਲਾ 500 ਪੁੱਟ ਕੁੱਟ ਕੁੱਟ ਕੇ ਹੋਏ ਫਰਾਰ ਅਜੀਤ : ਚੰਡੀਗੜ੍ਹ ਸਾਹਿਬਜ਼ਾਦਾ ਅਜੀਤ ਸਿੰਘ ਨਗਰ ਪੁਰੀ ਤਾਜ਼ਾ ਖ਼ਬਰਾਂ ਆਈ ਸੀ ਬੀ ਆਈ ਨੇ ਅੱਜ ਦੁਪਹਿਰ ਰੋਕ ਲਗਾ ਕੇ ਕੀਤੀ ਸੀ। ਅੱਜ ਸੁਪਰੀਮ ਕੋਰਟ ਨੇ ਉਸ ਨੂੰ ਪਟੀਸ਼ਨ ਦਾਇਰ ਕਰਾਰ ਦਿੱਤਾ ਹੈ। ਜਦਕਿ ਪੁਰੀ ਪਟੀਸ਼ਨ ਦਾਇਰ ਕਰਾਰ ਦਿੱਤਾ ਗਿਆ ਹੈ। ਇਸ ਤੋਂ ਪਹਿਲਾਂ ਅਦਾਲਤ ਨੇ ਇਸ ਤੋਂ ਬਾਅਦ ਕੋਰਟ ਚ ਪਟੀ\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text_upgraded('ਅੱਜ ਦੀ ਖਬਰ', model_loaded, 500,  temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਪੰਜਾਬ ਚਾਹੁੰਦਾ ਹੈ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation:  ਕਿ ਬਾਦਲ ਜਿੱਥੇ ਕੋਈ ਵੀ ਮਹਾਨ ਪਾਰਟੀ ਦਾ ਉਮੀਦਵਾਰ ਨਾ ਸਵੇਰੇ ਬਾਪੂ ਖੁਦ ਨਾ ਲੜਵੇਗਾ, ਹੁਣ ਤਾਂ ਦਿੱਲੀ ਵੱਲ ਦਾ ਮਰ ਨਹੀਂ ਦਿਸੇਗਾ, ਇਹ ਕਲਮ ਤੇ ਚੜੀ ਵੇਲੇ ਤਾਂ ਕੀ ਮਤਲਬ ਦਰਜਾ ਨਹੀ ਗਿਆ ਕਿ ਲੈ ਕੇ ਆਪ ਨੇ ਦਿੱਤਾ ਰੋ ਕੇ ਟੇਢੀ ਟੇਢੀ ਕੁੜੀ ਮਾਰ ਕੇ ਉਸ ਦੀ ਨਿੰਦਾ ਰੱਖ ਕਿ ਬੀਜਾ ਨਹੀ ਸੀ, ਤੁਹਾਡਾ ਹੱਥ ਨਾ ਡਰਨਾ ਮੰਡੀ ਚ ਹੀ ਲਾਈ ਜਿਹੜੀ ਵਰਤੁਰ ਜਾਪਦੀ ਉਸ ਨੇ ਲੱਕ ਨਾਲ ਸੱਚ ਨਾ ਚੱਲ ਤੋ ਡਰਾਇਆ ਹੱਥ ਮੰਡੀ ਸਾਉਣ, ਰਾਏ ਲਾਸ ਤੋੜ ਡਰਾਇਦੇ ਨੇਹੱਥ ਲੱਗਦਾ ਲੁੱਟ ਲੈਂਦਾ ਹੱਥ ਮਿਲਾਇਆ ਹੈ, ਰਸੌਲੀ ਸਫ਼ੈਦਾਂ ਦੀ ਨੀਂਹ। ਇਹੋ ਜਿਹੇ ਡਰਾਇਦੇ ਚ ਵੀ ਇਹੀ ਤਰੀਕਾ ਹੈ ਜਿਵੇਂ ਪੁਲੀਜ਼\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text_upgraded('ਪੰਜਾਬ ਚਾਹੁੰਦਾ ਹੈ', model_loaded, 250, temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਭਾਰਤ ਚਾਹੁੰਦਾ ਹੈ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: । ਕਲੀਅਰ ਦੇ ਵਰਕੇਸ਼ ਮਾਪਿਆਂ ਨੇ ਕਾਲੇ ਬਾਲਾਂ ਵਾਲੀ ਗੋਰੀ ਮਾਲੀ ਪੁਰਾਣਾ ਕੇਪੀ ਰਾਤ ਸਿਰਾ ਵਿਕਾਸ ਕਾਰਜਾਂ ਦਾ ਪੋਸਟਰ ਕਾਰਡ ਵਰਤਣ ਵਾਲਿਆਂ ਲਈ ਵਰਤਣ ਵਾਲਿਆਂ ਲਈ ਸਮਾਂ ਦਿੱਤਾ ਸੀ। ਦੁਨੀਆਂ ਭਰ ਵਿਚ ਸਮਾਰੋਹ ਵਰਤਣ ਵਾਲੇ ਪੁਰਾਣੇ ਮਾਲੀ ਸਮਾਰੋਹ ਦੇ ਪੁਰਾਣੇ ਵਾਲਿਆਂ ਲਈ ਸਮਾਂ ਸਮਾਂ ਵਿਕਾਸ ਕਾਰਡ ਵਰਤਣ ਵਾਲੇ ਲੋਕਾਂ ਲਈ ਸਮਾਂ ਵਿਕਾਸ ਕਾਰਡ ਵਰਤਣ ਵਾਲੇ ਲੋਕਾਂ ਨੂੰ ਵਿਕਾਸ ਕਾਰਡ ਵਰਤਣ ਵਾਲੇ ਲੋਕਾਂ ਨੂੰ ਸਮਾਂ ਲਾਉਣ ਦੀ ਲੋੜ ਹੈ। ਲਾਲੀ ਸਮਾਰੋਹ ਤੇ ਕਾਰਡ ਵਰਤਣ ਵਾਲੇ ਲੋਕਾਂ ਨੂੰ ਵਿਕਾਸ ਕਾਰਡਾਂ ਦੀ ਕਾਰਡ ਵਰਤਣ ਵਾਲੇ ਲੋਕਾਂ ਨੂੰ ਵਿਕਾਸ ਕਾਰਡਾਂ ਦੀ ਵਰਤੋਂ ਕਰਨ ਦੀ ਲੋੜ ਹੈ। ਲਾਲੀ ਵਰਤੋਂ ਕਰਨ ਵਾਲੇ ਲੋਕਾਂ ਨੂੰ ਵਿਕਾਸ ਕਾਰਡਾਂ ਦੀ ਵਰਤੋਂ ਕਰਨ ਦੇ ਤਰੀਕੇ ਅਪਣਾਏ ਜਾਣਗੇ। ਲਾਲੀ ਵਰਤੋਂ ਕਰਨ ਵਾਲੇ ਲੋਕਾਂ ਨੂੰ ਦੂਰਬੀਨ ਦੀ ਵਰਤੋਂ ਕਰਨ ਵਾਲੀਆਂ ਵਿਕਾਸ ਕਾਰਡਾਂ ਦੀ ਵਰਤੋਂ ਕਰਨੀ ਚਾਹੀਦੀ ਹੈ। ਲਾਲੀ ਵਰਤੋਂ ਕਰਨ ਵਾਲੇ ਲੋਕਾਂ ਨੂੰ ਰੋਕਣ ਲਈ ਵਿਕਸਿਤ ਕੀਤਾ ਜਾ ਰਿਹਾ ਹੈ। ਲਾਲੀ ਵਿਕਾਸ ਕਾਰਡਾਂ ਦੀ ਵਰਤੋਂ ਕਰਨੀ ਚਾਹੀਦੀ ਹੈ। ਸਮਾਰਟ ਰੂਸ ਦੇ ਮਾਲਕਾਂ ਨੂੰ ਲਾਲੀ ਵਿਕਾਸ ਦੇ ਤਰੀ\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text_upgraded('ਭਾਰਤ ਚਾਹੁੰਦਾ ਹੈ', model_loaded, 500, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਭਾਰਤ ਦੀ ਹਾਕੀ ਟੀਮ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation:  ਨੂੰ ਦਿਮਾਗ ਦੀ ਵੰਡ ਵਾਲਿਆਂ ਵਿਰੁੱਧ ਮਾਣ ਦਿਓ ਵਿਕਾਸ ਦਾ ਰਾਹ ਪੁਰਸਕਾਰ: ਵਰਤੋਂ ਦੇ ਨਿਯਮ ਨਿੱਜਤਾ ਨੀਤੀ ਪੇਰੈਂਟਲ ਮਾਰਗ ਦਰਸ਼ਨ ਨਾਲ ਸੰਪਰਕ ਕਰੋ ਇਸ਼ਤਿਹਾਰ ਪਟਵਾਰੀ ਕਾਲੀਨਰ ਰਾਮ ਚਾਤ੍ਰਿਕ ਰਚੇਗਾ ਮਾਮਲਾ:ਸਾਂਝਪਕ ਤੇ ਚਰਚਾ ਵਿੱਚ ਕੋਈ ਬਦਲਾਅ ਨਹੀਂ: ਵਿਕਾਸ ਦੇ ਨਿਯਮ ਅਤੇ ਸ਼ਰਤਾਂ ਪੂਰੀਆਂ ਕਰਨ ਲਈ ਰਾਸ਼ੀ ਮਾਮਲਾ: ਵਿਵਾਦਗ੍ਰਸਤ ਲੋਕਾਂ ਦੇ ਮਕਸਦ ਲਈ ਰਾਸ਼ੀ ਲਗਾ ਕੇ ਘਰ ਆਏ ਨੌਜਵਾਨ ਨੂੰ ਪੁਲਸ ਨੇ ਕੀਤਾ ਕਾਬੂ ਅੱਜ\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text_upgraded('ਭਾਰਤ ਦੀ ਹਾਕੀ ਟੀਮ', model_loaded, 200, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਕ੍ਰਿਕਟ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation:  ਟੈਸਟ ਨਾਲ ਮਿਲਕੇ 10 ਤੋਂ 3 ਵਜ਼ੇ ਤੱਕ ਟੈਸਟ ਮੈਚ ਚ ਦੂਜਾ ਪੁਰਾਣੇ ਡ੍ਰਿਮੋ ਕਮਰਾ ਨੂੰ ਲੈ ਕੇ ਦੁਅਾਰਾ ਪੂਲ ਦੀ ਮਦਦ ਨਾਲ ਜਦ ਦੇਰ ਜਾਂਦੀ ਤਾਂ ਰਾਤ ਚ ਰੁਕਾਵਟ ਪਾਈ ਡਿੱਗ ਪਵੇਗੀ, ਰਾਤ ਨਵੀ ਦਿੱਲੀ ਨੇ ਸ੍ਰੀਲੰਕਾ ਨੂੰ 5 ਦੌੜਾਂ ਨਾਲ ਹਰਾਇਆ ਸੀ, ਜਿਸ ਤੋਂ ਬਾਅਦ ਅੱਜ ਟੀਮਾਂ ਵਿਰੁੱਧ ਇਸ ਤੋਂ ਪਹਿਲਾਂ ਟੀਮਾਂ ਚੋਂ ਇਕ ਏਜੰਟ ਆਸਟਰੇਲੀਆ ਨੂੰ ਕਰੀਬ 100 ਦੌੜਾਂ ਦੇ ਦੋ ਵਿਕਟਾਂ ਚ ਰੁਕਾਵਟ ਪਾਈ ਹੋਈ ਹੈ, ਜਿਸ ਕਾਰਨ ਵਾਪਸੀ ਤੇ ਇਸ ਦੀ ਕਮਾਈ 27 , 30 ਨਵੰਬਰ ਪੋਸਟ ਬਿਊਰੋ ਦੂਜਾ ਪੰਜ ਸਾਲ ਦੀ ਸਜ਼ਾ ਤੇ ਚਲੀ ਗਈ ਅੱਜ ਤੋਂ ਤਿੰਨ 1 ਵਜੇ ਅਸੀਂ ਆਸਟ੍ਰੇਲੀਆ ਦੇ ਸ਼ਹਿਰ ਟੈਸਟ ਦੇ ਵੇਅਰਬਰਗ ਇਲਾਕੇ ਚ ਮੌਸਮ ਦੀ ਚਮੀ ਨਿਸ਼ਾਨ ਵੀ ਬਣਿਆ ਹੈ। ਪਿਛਲੇ ਇਕ ਮਹੀਨੇ ਤੋਂ ਚਲੀ ਗਲੇਸਰੋਵਰੇਜ਼ ਸਿਟੀ ਲਈ ਸਟਾਰਟਅੱਪ ਵੇਅਰਜ਼ ਡਰਾਇੰਗ ਵੇਅਰਜ਼ ਮੈਡੀਕਲ ਕਲੱਬ ਰਜਿ: ਸਟੱਡੀਜ਼ ਵਰਗੇ ਸਮੇਂ ਲਈ ਮੈਨਫਰਡ ਲੇਆਉਟ ਦੇ ਫਾਰਮ ਚ। ਵਰਤਮਾਨ ਸਮੇਂ ਸਕੂਲ ਦੇ ਆਸਟਰੇਲੀਆ ਦੇ ਮੈਂਬਰ ਨਾਮਜ਼ਦ ਦੇਣ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ। ਨਿਰਪੱਖ ਵਿਸ਼ੇ ਨਾਲ ਸਬੰਧਿਤ ਹੈ। ਇਸ ਨਾਲ ਰੱਤੇ ਵਾਕ ਦੇ ਤੱਤ ਦਾ ਪਤਾ ਲੱਗ ਜਾਂਦਾ ਹੈ। ਸਰੋਤ : ਪੰਜਾਬੀ ਯੂਨੀਵਰਸਿਟੀ ਪੰਜਾਬੀ ਕੋਸ਼ ਸਕੂਲ ਪੱਧਰ ਕੋਸ਼ ਚ ਸਕੂਲ ਪੱਧਰ ਤੇ ਵਿਦਿਆਰਥੀਆਂ ਨੇ ਲਿਆ ਵਿਵਾਦ ਦੇ ਅਨੰਦ ਕਾਰਜ ਦਾ ਕੰਮ : ਜਦ ਇਮਾਰਤੀਆਂ ਦੇ ਰੁਕਾਵਟਾਂ ਵਿੱਚ ਛੇ ਬਾਣੀਆਂ ਦਾ ਡਿਪਟੀ ਕਮਿਸ਼ਨਰ ਕਾਲੀਆ ਦੀ ਚੋਣ ਲਈ ਸਰਕਾਰ ਨੇ ਵਿਵਾਦਗ੍ਰਸਤ ਲੋਕਾਂ ਨੂੰ ਵਿਵਾਦਾਂ ਦੇ ਦਸਤਖਤ\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text_upgraded('ਕ੍ਰਿਕਟ', model_loaded, 500, temperature=0.75 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਮੰਤਰੀ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: ਆਂ ਦਾ ਕੋਈ ਮੁਲਕ ਨਹੀਂ, ਵਾਸੀਆਂ ਲਈ ਤਕਰਾਰੂ ਪਰਬਤ ਕਿਸੇ ਨੂੰ ਨਹੀ ਜਾਣਦਾ, ਮਾਪਿਆਂ ਨੂੰ ਜੇ ਕਿਸੇ ਨੇ ਉਲਟ ਨਜ਼ਰ ਮਾਰੀ ਤਾਂ ਉਹਦਾ ਨਾਂਅ ਵਿਉਦੀਏ। ਅੱਜ ਉਨ੍ਹਾਂ ਨੇ ਉਸ ਰਤਾ ਵਿਖਾਲ ਪਏ ਅਤੇ ਸਿਰ ਤੋਂ ਮੁਲਕ ਵਿਚ ਦਰਜ ਕਰ ਲਿਆ। ਇਸ ਤਰ੍ਹਾਂ ਕਾਲੀ ਨੇ ਦਰਸ਼ਨ ਦਾ ਅੰਤ ਨਾ ਪਾਇਆ ਤੇ ਨੀਦਰਲੈਂਡ ਦੇ ਬਾਹਰ ਢਿਰੋਧ ਵੇਚਣਾ ਸ਼ੁਰੂ ਕੀਤਾ। ਮਾਲਵਾ ਪੁਰਸਕਾ, ਕੁਟਜਾਈ, ਮਾਲਵਾ, ਮਾਲਵਾ, ਮਾਲਟੀ ਨੂੰ ਕਿਹਾ। ਪੂਰੇ ਸਾਥੀ ਮਾਲਵਾ ਅਜਿਹੇ ਰੱਬ ਦੇ ਮੂਹਰੇ ਆਪੋ ਆਪਣੇ ਕਾਰਜਾਂ ਦੀ ਪੇਟ ਵਿਚ ਪੇਸ਼ ਆਇਆ ਸੀ। ਪੁਰਸਕਾਰ ਦੀ ਗੱਲ ਵਿਸਾਖੀ ਨੂੰ ਲੈ ਕੇ ਆਖੀ ਗਈ ਸੀ। ਵਿਸਾਖੀ ਨੂੰ ਰੱਬ ਵਲੋਂ ਮੁਸਲਮਾਨਾਂ ਦੇ ਦਿਲਾਂ ਦੇ ਸਿਰ ਉੱਤੇ ਜਾ ਡਿੱਗੇ, ਗੀਤ, ਗੀਤ, ਗੀਤ, ਗੀਤ, ਗੀਤ, ਗੀਤ, ਗੀਤ, ਗ਼ਜ਼ਲ, ਗੀਤਕਾਰ, ਨੀਦਰਲੈਂਡ ਗੀਤ, ਗੀਤ, ਗੀਤ, ਸੰਗੀਤ, ਗੀਤ, ਸੰਗੀਤ ਅਤੇ ਦੇਸ਼ ਮਿਲਪੀਟਸ, ਸੰਗੀਤ ਗੀਤ, ਸਾਹਿਤ ਗੀਤ, ਸੰਗੀਤ, ਸੰਗੀਤ, ਸੰਗੀਤ ਆਦਿ। ਕੁੱਝ ਗੀਤ ਸਿਰਫ਼ ਕੁਝ ਕੁ ਲਾਭ ਪਹੁੰਚਾ ਰਹੇ ਹਨ। ਪੜ੍ਹਨ ਦਾ ਤਰੀਕਾ ਇਸ ਗੀਤ ਦਾ ਸੰਗੀਤ ਆਦਿ ਵਿਚ ਕੁੱਝ ਹੋਰ ਤਰੀਕਾ ਨਾਲ ਕੁੱਝ ਲਾਭ ਦੇ ਨਾਲ ਨਾਲ ਵੱਲ ਵਧਦਾ ਜਾ ਰਿਹਾ ਹੈ। ਜਸਵੰਤ ਸਿੰਘ ‘ਅਜੀਤ , ਹੁਣ ਇਹ ਵੀ ਜਾਣੀ ਕਿਤੇ ਕੁਛ ਵਿਦਿਆਰਥੀ ਵੱਲ ਹੈ। ਇਸ ਮੁਸਲਮਾਨ ਵੱਲੋਂ ਵੀ ਇਸ ਨੂੰ ਜ਼ਰੀਏ ਕੁਛ ਦੀਪ ਪੇਸ਼ੀ ਦੇ ਦੂਜੇ ਪਾਸੇ ਵੀ ਕੋਈ ਮੁਸਲਮਾਨ ਦਾ ਵਿਦਿਆਰਥੀ ਵਰਗ\n"
     ]
    }
   ],
   "source": [
    "gen = generate_text_upgraded('ਮੰਤਰੀ', model_loaded, 500, temperature=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating text for context from the test evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, pos = get_batch_with_pos('test', 6, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [decoder([j.item() for j in i]) for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:  ਕੀਤਾ ਗਿਆ ਸੀ , ਸਨ ਫ੍ਰੈਨਸਿਸਕੋ ਵਿੱਚ ਇੱਕ ਹੈ ਜੀਵਤ ਹੈ ਇਹ ਕਰਕਟ ਦੇ 1 ਕਿਲੋ ਪੈਦਾ ਕਰਦਾ ਹੈ ਪਿਛਲੇ ਪੋਸਟ ਕੇ ਤਾਜ਼ਾ ਪੋਸਟ ਦੇਖੋ ਪੜ੍ਹੇ ਨਵੀਨਤਮ ਨਾਲ ਸੰਪਰਕ ਕਰੋ ਠੰਡੇ ਕਮਰੇ ਸਬਜ਼ੀ ਅਤੇ ਡਬੇ ਨੂੰ ਸਟੋਰ ਕਰਨ ਲਈ ਅਤੇਵੈੱਸਟ ਵਿਚ ਮੇਰੇ ਸਬਜ਼ੀ ਰੱਖਣ ਅਤੇ ਮੇਰੇ ਬਰਕਰਾਰ ਸੰਭਾਲਣ ਲਈ, ਮੈਨੂੰ ਇੱਕ ਸਕਾਰਾਤਮਕ ਕਮਰੇ ਠੰਡੇ ਤਹਿਖ਼ਾਨੇ ਬਣਾਇਆ ਇਹ ਤੁਹਾਨੂੰ ਵਿਚਾਰ ਦੇ ਸਕਦਾ ਹੈ, ਜੇ: ਇੱਕ ਠੰਡੇ ਕਮਰੇ ਨੂੰ ਇਸ ਨੂੰ ਸੁਰੱਖਿਅਤ ਰੱਖਣ ਲਈ ਬਣਾਏ ਸਾਨੂੰ ਇਸ ਬਾਰੇ ਗੱਲ ਕੀਤੀ ਹੈ, ਪਰ ਕਿਸੇ ਹੋਰ ਵਿਸ਼ੇ ਵਿਚ ਡੁੱਬ , ਇਸ ਲਈ ਮੈਨੂੰ ਤੇ ਦੇ ਵਿਕਾਸ ਦਰ ਵਿਚ ਰੁਕਾਵਟ ਕਰਨ ਲਈ ਛੱਤ ਉੱਤੇ ਪਿੱਤਲ ਦੀ ਇੱਕ ਲੰਬਾਈ ਪਾ ਦੇ ਇਸ ਈਕੋ ਹੈਟ੍ਰਿਕ ਬਾਰੇ ਗੱਲ ਕਰਨ ਲਈ ਇਸ ਨੂੰ ਨਵ ਵਿਸ਼ੇ ਨੂੰ ਬਣਾਇਆ ਪਿਛਲੇ ਪੋਸਟ ਕੇ ਤਾਜ਼ਾ ਪੋਸਟ ਦੇਖੋ ਕਪਿਲ ਖਿਲਾਫ਼ ਨਰਸਾਂ ਨੇ ਥਾਣੇ ‘ਚ ਦਰਜ ਕਰਵਾਈ ਸ਼ਿਕਾਇਤ ਅੰਮ੍ਰਿਤਸਰ, 17 ਮਈ ਚ ਨ ਸ : ਗੁਰੂ ਕੀ ਨਗਰੀ ਅੰਮ੍ਰਿਤਸਰ ਵਿੱਚ ਪੈਦਾ ਹੋ ਕੇ ਮਾਇਆ ਨਗਰੀ ਪਹੁੰਚੇ ਕਾਮੇਡੀ ਕਿੰਗ ਕਪਿਲ ਸ਼ਰਮਾ ਖਿਲਾਫ਼ ਗੁਰੂ ਕੀ ਨਗਰੀ ਦੀਆਂ ਹੀ ਨਰਸਾਂ ਨੇ ਮੋਰਚਾ ਖੋਲ੍ਹ ਦਿੱਤਾ ਹੈ। ਅੱਜ ਨਰਸਾਂ ਵੱਲੋਂ ਕਪਿਲ ਸ਼ਰਮਾ ਦੇ ਸ਼ੋਅ ਵਿੱਚ ਨਰਸ ਦੇ ਕਿਰਦਾਰ ਨੂੰ ਗਲਤ ਢੰਗ ਨਾਲ ਪੇਸ਼ ਕੀਤੇ ਜਾਣ ਮੈਨੂੰ ਪੱਗਾਂ ਵਾਲਿਆਂ ਤੋਂ ਨਫ਼ਰਤ ਹੈ ਕਹਿ ਕੇ ਸਿੱਖ ਡਰਾਈਵਰ ‘ਤੇ ਤਾਣੀ ਬੰਦੂਕ ਪਾਕਿ ਗੋਲੀਬਾਰੀ ‘ਚ ਬੀ ਐਸ ਐਫ ਦਾ ਜਵਾਨ ਸ਼ਹੀਦ ਤੇ ਚਾਰ ਆਮ ਨਾਗਰਿਕਾਂ ਦੀ ਮੌਤ ਦਸਮੇਸ਼ ਪਿਤਾ ਦੇ 350 ਸਾਲਾ ਪ੍ਰਕਾਸ਼ ਪੁਰਬ ਨੂੰ ਸਮਰਪਿਤ ਗੁਰਮਤਿ ਸਮਾਗਮ ਸ਼ਾਨੋ ਸ਼ੌਕਤ ਨਾਲ ਸੰਪੰਨ 10 3 3 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation:  3 ਗਰੁੱਪ ਦੇ ਸਬੰਧਾਂ ਨੂੰ ਲੈ ਕੇ 9 2 ਕਰੋੜ ਦੀ ਡੀਲ ਕਰਨੈਲ ਸਿੰਘ ਨੇ ਕਾਨਪੁਰ ਦੇ ਨਾਗਪੁਰ ਨੂੰ ਦੱਸਿਆ ਹਿੰਦੂ ਛਤਵਾਲ ਸਿੱਖ ਫੈਡਰੇਸ਼ਨ ਆਫ਼ ਅਮਰੀਕਾ ਦੇ ਪਹਿਲੇ ਸਿੱਖ ਅਟਾਰਨੀ ਜਨਰਲ ਗੁਰਜਿੰਦਰ ਸਿੰਘ ਨੇ ਅਕਾਲ ਤਖ਼ਤ ਦੇ ਨਾਂ ਤੇ ਮੱਥਾ ਟੇਕਿਆ, ਇਸ ਮਾਮਲੇ ਤੇ ਗੁਰੂ ਨਾਨਕ ਦੇਵ ਜੀ ਦੇ ਹੁਕਮ ਜਾਰੀ ਕੀਤੇ ਗਏ ਹਨ। ਇਸ ਵਿੱਚ ਵਿਸ਼ੇਸ਼ ਤੌਰ ਉੱਤੇ ਇਹ ਦੋਸ਼ ਲਗਾਇਆ ਹੈ ਕਿ ਸਿੱਖ ਗੁਰਦੁਆਰਾ ਪ੍ਰਬੰਧਕ ਕਮੇਟੀ ਦੇ ਪ੍ਰਬੰਧ ਹੇਠ ਗੁਰਦੁਆਰਾ ਪ੍ਰਬੰਧਕ ਕਮੇਟੀ ਅਤੇ ਸਿੱਖ ਸੰਸਥਾਵਾਂ ਦੇ ਇੱਕ ਵੱਖਰੀ ਕਮੇਟੀ ਕਾਇਮ ਕਰਨ ਵਿੱਚ ਸ਼ਾਮਿਲ ਹੋਣ। ਹੋਰ ਵੀ ਅਨੇਕਾਂ ਸਿੱਖ ਬੀਬੀਆਂ ਨੂੰ ਨਿਮਰਤਾ ਸਹਿਤ ਉਨ੍ਹਾਂ ਅਤੇ ਸਿੱਖਾਂ ਨੂੰ ਵੀ ਸਿੱਖਾਂ ਤੋਂ ਸਬਕ ਦਸ ਕੇ ਸ਼ਹੀਦਾਂ ਨੂੰ ਸੌਂਪ ਦਿੱਤੀ ਹੈ। ਇਸ ਵਿੱਚ ਸਿੱਖ ਜਥੇਬੰਦੀਆਂ ਦੇ ਇੱਕ ਵਫਦ ਦੇ ਤੌਰ ਉੱਤੇ ਸਿੱਖ ਜਥੇਬੰਦੀਆਂ ਦੇ ਆਗੂਆਂ ਹਨ। ਕਾਨਪੁਰ ਦੇ ਸਿੱਖਾਂ ਨੂੰ ਅੱਜ ਇਸ ਲਹਿਰ ਨੂੰ ਆਪਣੇ ਕਬਜ਼ੇ ਵਿੱਚ ਲੈ ਲਿਆ ਹੈ। ਇਸ ਲਈ ਉਹ ਇਹ ਵੀ ਕਿਹਾ ਗਿਆ ਹੈ ਕਿ ਅਮਰੀਕਾ ਕਸ਼ਮੀਰ ਪੱਧਰ ਤੇ ਭਾਰਤ ਦੀ ਵਿਕਾਸ ਕਮੇਟੀ ਦੀ ਕੋਈ ਭੂਮਿਕਾ ਨਹੀਂ। ਕੈਨੇਡਾ ਵਿੱਚ ਸਿੱਖਾਂ ਉੱਤੇ ਨਸਲੀ ਹਮਲਾ, 2 ਔਰਤਾਂ ਨੂੰ ਗ੍ਰਿਫਤਾਰ ਕਰਨ ਦੀ ਕੋਸ਼ਿਸ਼ ਕੀਤੀ ਗਈ ਹੈ। ਇਹ ਵੀ ਐਲਾਨ ਸੀ ਕਿ ਉਹ ਨਾ ਕੇਵਲ ਇੱਕ ਹੋਰ ਯਾਤਰਿਆ ਹੈ, ਬਲਕਿ ਉਨ੍ਹਾਂ ਦਾ ਵਿਰੋਧ ਕਰਨ ਵਾਲੀ ਸੰਸਥਾ ਹੈ। ਸਿੱਖ ਧਰਮ ਦੇ ਪ੍ਰਚਾਰ ਲਈ ਇੱਕ ਅਹਿਮ ਨੁਕਤੇ ਹਨ। ਇਸ ਲਈ ਏਅਰ ਇੰਡੀਆ ਨੂੰ ਮੁੜ ਸਿੱਖ ਕਿਰਪਾਨ ਵਿੱਚ ਮਾਰਚ ਕਰਨ ਦੇ ਯੋਗ ਹੋ ਜਾਣਗੇ। ਇਹ ਵੀ ਦੱਸਿਆ ਜਾ ਰਿਹਾ ਹੈ ਕਿ ਉਸ ਕੇਸ ਵਿੱਚ ਮੈਂ ਸੰਤ ਭਿੰਡਰਾਂਵਾਲਿਆਂ ਵਰਗੀਆਂ ਪੰਥਕ ਜਥੇਬੰਦੀਆਂ ਨੂੰ ਭੇਜ\n",
      "------------------------\n",
      "\n",
      "context:  ਦੇ, ਰੁਪਏ ਦੇ ਹਨ, ਜੋ ਕਿ 26 ਖਰਬ ਪਰ, ਇਸ ਨੂੰ ਰਿਪੋਰਟ ਕੀਤੀ ਜਾ ਰਹੀ ਹੈ, ਜੋ ਕਿ ਪ੍ਰਤੀਸ਼ਤਤਾ ਵਧ ਰਹੀ ਹੈ ਅਤੇ ਖਾਲੀ ਮੰਨਿਆ ਗਿਆ ਹੈ, ਉਭਰ ਰਹੇ ਸੰਪਤੀ ਕਲਾਸ ਇਸ ਦੇ ਨਾਲ, , ਕੋਰੀਆ ਵਿਚ 2 ਵੱਡੇ ਬਕ, ਆਪਣੇ ਗਾਹਕ ਦੇ ਲਈ ਇੱਕ ਵਿਕੀਪੀਡੀਆ ਵਾਲਟ ਨੂੰ ਤਿਆਰ ਕੀਤਾ ਹੈ ਲਈ ਰੋਜ਼ਾਨਾ ਮਾਰਕੀਟ ਦੀ ਰਿਪੋਰਟ 09 07 2018 62 7ਐਮ ਸਾਰੇ ਬਾਜ਼ਾਰ ਨੇ ਅੱਜ ਭਰ ਵਿੱਚ ਵਪਾਰ ਸੰਬੰਧਿਤ ਪੋਸਟ: ਮਾਸਟਰਕਾਰਡ ਨੂੰ ਵੇਖਿਆ ਗਿਆ ਹੈ ਐਮਾਜ਼ਾਨ, ਇੱਕ ਜਿੱਤਿਆ ਹੈ ਪੋਸਟ ਨੇਵੀਗੇਸ਼ਨ ਕੋਈ ਜਵਾਬ ਛੱਡਣਾ ਜਵਾਬ ਰੱਦ ਤੁਹਾਡਾ ਈਮੇਲ ਪਤਾ ਪ੍ਰਕਾਸ਼ਿਤ ਨਹੀ ਕੀਤਾ ਜਾ ਜਾਵੇਗਾ ਦੀ ਲੋੜ ਹੈ ਖੇਤਰ ਮਾਰਕ ਕੀਤੇ ਹਨ, ਦਿਲਚਸਪ ਪੋਸਟ ਪੜ੍ਹਨ ਜਾਰੀ ਦੁਆਰਾ ਸੰਚਾਲਿਤ ਵਰਡਪਰੈਸ ਅਤੇ ਵੈਲਿੰਗਟਨ ਰਸੂਲਾਂ ਦੇ ਕਰਤੱਬ 1, ਇੰਟਰਨੈੱਟ ਤੇ ਬਾਈਬਲ ਦਾ ਪੜ੍ਹੋ ਦਿਵਸ ਦੇ ਆਇਤ ਭਰਾਵੋ ਅਤੇ ਭੈਣੋ ਹੁਣ ਮੈਂ ਤੁਹਾਨੂੰ ਕੁਝ ਹੋਰ ਗੱਲਾਂ ਬਾਰੇ ਦੱਸਦਾ ਹਾਂ। ਅਸੀਂ ਤੁਹਾਨੂੰ ਜੀਵਨ ਦਾ ਉਹ ਢੰਗ ਸਿਖਾਇਆ ਹੈ ਜੋ ਪਰਮੇਸ਼ੁਰ ਨੂੰ ਪ੍ਰਸੰਨ ਕਰਦਾ ਹੈ। ਅਤੇ ਅਸੀਂ ਜਾਣਦੇ ਹਾਂ ਕਿ ਤੁਸੀਂ ਉਸੇ ਢੰਗ ਵਿੱਚ ਜਿਉਂ ਰਹੇ ਹੋ। ਹੁਣ ਅਸੀਂ ਤੁਹਾਨੂੰ ਪੁਛਦੇ ਹਾਂ ਅਤੇ ਤੁਹਾਨੂੰ ਪ੍ਰਭੂ ਯਿਸੂ ਦੇ ਨਾਂ ਵਿੱਚ ਇਸੇ ਢੰਗ ਵਿੱਚ ਵਧ ਤੋਂ ਵਧ ਜਿਉਣ ਲਈ ਉਤਸਾਹਤ ਕਰਦੇ ਹਾਂ। ਸਾਡੇ ਪਿਤਾ ਅਸੀਂ ਆਇਤ ਸ਼ੇਅਰ ਕਰਨ ਲਈ, ਇਕਬਾਲ ਕਰਨ ਲਈ ਵਿਸ਼ਵਾਸ ਅਤੇ ਯਕੀਨ ਮੁਕਤੀ, ਮੁਆਫ਼ੀ, ਸਦੀਵੀ ਜੀਵਨ ਜਸਟਿਸ, ਇਕੁਇਟੀ ਸਿਹਤ, ਨੂੰ ਚੰਗਾ ਤਾਕਤ, ਹਿੰਮਤ, ਦੀ ਸੁਰੱਖਿਆ ਪਵਿੱਤਰ ਆਤਮਾ ਨੇ ਚੈਰਿਟੀ, ਚੰਗੇ ਕੰਮ ਪਰਿਵਾਰਕ,\n",
      "generation:  ਵਿਆਹ ਅਤੇ ਪਰਿਵਾਰ ਸਮੂਹ ਮਸੀਹੀ ਜ਼ਿੰਦਗੀ ਦੇ ਪਵਿੱਤਰ ਆਤਮਾ ਨੇ ਮੈਨੂੰ ਇੱਕ ਪਿਆਰ ਹੈ, ਜੋ ਕਿ ਆਪਣੇ ਆਪ ਨੂੰ ਛੱਡ ਕੇ ਮੇਰੇ ਲਈ ਇੱਕ ਵਧੀਆ ਕੰਮ ਕਰਦਾ ਹੈ। ਆਪਣੀ ਜ਼ਿੰਦਗੀ ਦੇ ਦਿਨ ਅਤੇ ਇੱਕ ਵਾਰ ਪਿਆਰ ਕਰੋ। ਪਰਮੇਸ਼ੁਰ ਨੇ ਉਨ੍ਹਾਂ ਲੋਕਾਂ ਨੂੰ ਦਿੱਤੀਆਂ ਸ਼ੁਭਕਾਮਨਾਵਾਂ ਦਿੱਤੀਆਂ ਹਨ ਜਿਹੜੀਆਂ ਤੁਹਾਨੂੰ ਸ਼ੁਭਕਾਮਨਾਵਾਂ ਦਿੱਤੀਆਂ ਹਨ। ਉਨ੍ਹਾਂ ਲੋਕਾਂ ਨੂੰ ਫ਼ਰਜ਼ੀਕੋਤ ਕਰਨ ਲਈ ਤਿਆਰ ਹਨ। ਪਰਮੇਸ਼ੁਰ ਇਸ ਨੂੰ ਲੋਕਾਂ ਦੇ ਸਾਥ ਵਿੱਚ ਤੁਹਾਡੇ ਲਈ ਜਿਉਣਾ ਹੈ। ਉਹ ਤੁਹਾਨੂੰ ਬਹੁਤ ਸਾਰੀਆਂ ਗੱਲਾਂ ਹਨ ਜਿਨ੍ਹਾਂ ਨੂੰ ਅਸੀਂ ਤੁਹਾਨੂੰ ਆਪਣੇ ਆਤਮਾ ਨੂੰ ਬਚਾਉਣ ਵਿਚ ਮਦਦ ਕਰਦੇ ਹਾਂ। 2 ਸਾਡੇ ਉੱਤੇ ਨਿਰਭਰ ਕਰਦਾ ਹੈ, ਇੱਕ ਪਵਿੱਤਰ ਆਤਮਾ, ਵਿਅਕਤੀ ਅਤੇ ਉਸ ਦੇ ਮਾਤਾ ਪਿਤਾ ਦੇ ਨਾਲ ਰਾਜਾ ਯਿਸੂ ਆਪਣੇ ਨੌਕਰ ਲਈ ਹਨ। 2 ਉਨ੍ਹਾਂ ਲੋਕਾਂ ਨੂੰ ਸਾਡੇ ਪ੍ਰਭੂ ਯਿਸੂ ਦੇ ਚੇਲੇ ਤੋਂ ਆਰਾਮ ਪ੍ਰਾਪਤ ਹੋ ਗਏ ਹਨ। 3 ਪਰ ਪਰਮੇਸ਼ੁਰ, ਤੁਹਾਡੇ ਸਾਰੇ ਲੋਕਾਂ ਦੀਆਂ ਗੱਲਾਂ ਕਰਦੇ ਹਨ। ਜੇਕਰ ਤੁਸੀਂ ਸੱਚੇ ਦੀਆਂ ਸੇਵਾ ਕਰਾਂਗੇ, ਤੁਸੀਂ ਹੋਰ ਸਾਰੀਆਂ ਚੀਜ਼ਾਂ ਨੂੰ ਸੱਦਾ ਦਿਓ। 5 ਤੁਸੀਂ ਆਪਣੇ ਜੀਵਨ ਵਿੱਚ ਆਪਣੇ ਆਪ ਨੂੰ ਸ਼ਾਂਤੀ ਦੇ ਲਈ ਆਪਣੇ ਜੀਵਨ ਵਿੱਚ ਪਿਆਰ ਕਰੋ। ਯਹੋਵਾਹ ਨੇ ਸਾਡੇ ਨਾਲ ਇੱਕ ਪ੍ਰਾਰਥਨਾ ਸੁਣਨ ਲਈ ਕੁਝ ਵੀ ਨਹੀਂ ਦਿੱਤਾ। 7 ਮੂਸਾ ਨੇ ਉਨ੍ਹਾਂ ਨੂੰ ਕੁਝ ਵੀ ਨਹੀਂ ਸਿਖਾਇਆ। ਉਨ੍ਹਾਂ ਲੋਕਾਂ ਨੂੰ ਨਿਆਂ ਨਹੀਂ ਦਿੱਤਾ ਗਿਆ ਕਿ ਉਨ੍ਹਾਂ ਲੋਕਾਂ ਨੂੰ ਉਨ੍ਹਾਂ ਦੇ ਮੂੰਹ ਉੱਤੇ ਲਿਆਉਣ ਦਾ ਹੱਕ ਮਿਲ ਸਕੇ। ਉਨ੍ਹਾਂ ਦੀ ਸਹਾਇਤਾ ਨਾਲ ਉਨ੍ਹਾਂ ਨੂੰ ਵੀ ਆਪਣੇ 20 ਹੋਰ ਲੋਕਾਂ ਨੂੰ ਵੀ ਉਨ੍ਹਾਂ ਨੂੰ ਸਹੀ ਜਗ੍ਹਾ ਤੇ ਭੇਜ ਦੇਣਾ ਚਾਹੀਦਾ ਹੈ। ਉਨ੍ਹਾਂ ਨੇ\n",
      "------------------------\n",
      "\n",
      "context:  ਦਾ ਬੱਚਾ ਚੋਰੀ ਹੋ ਗਿਆ ਹੈ। ਹਸਪਤਾਲ ਨੇ ਇਹ ਕਹਿ ਕੇ ਪੱਲਾ ਝਾੜ ਲਿਆ ਕਿ ਬੱਚੇ ਦੀ ਮਾਂ ਨੂੰ ਸਮਝਦਾਰੀ ਨਾਲ ਕੰਮ ਲੈਣਾ ਚਾਹੀਦਾ ਸੀ। ਫਿਲਮ ਪਹਿਲੇ ਪੰਜਾਬੀ ਸੂਪਰਹੀਰੋ ਦੀ ਕਹਾਣੀ ‘ਤੇ ਅਧਾਰਿਤ ਹੈ। ਦਿਲਜੀਤ ਦੋਸਾਂਝ ਦੇ ਫੈਨਸ ਫਿਲਮ ਨੂੰ ਵੇਖਣ ਲਈ ਜਾ ਰਹੇ ਹਨ ਹਾਲਾਂਕਿ ਕ੍ਰਿਟਿਕਸ ਨੇ ਬਹੁਤ ਵਧੀਆ ਰਿਸਪੌਂਸ ਨਹੀਂ ਦਿੱਤਾ। : 8,000 , ਕੈਪਟਨ ਅਮਰਿੰਦਰ ਸਿੰਘ ਦੀ ਅਗਵਾਈ ਵਾਲੀ ਪੰਜਾਬ ਸਰਕਾਰ ਵੱਲੋਂ ਪਰਾਲੀ ਨੂੰ ਸਾੜਨ ਤੋਂ ਰੋਕਣ ਵਾਸਤੇ ਪਿੰਡਾਂ ਵਿੱਚ 8000 ਨੋਡਲ ਅਫਸਰ ਨਿਯੁਕਤ ਨੌਜਵਾਨ ਚੂਤ ਪੋਰਨ ਵੀਡੀਓ ਉੱਚ ਗੁਣਵੱਤਾ ਮੂਵੀ ਮਿਤੀ ਵਿਚਾਰ ਅੰਤਰਾਲ ਝਟਕਾਉਣ ਅਤੇ ਮੁਫ਼ਤ ਹੈ ਡਾਊਨਲੋਡ ਪ੍ਰੋਗਰਾਮ ਬੇਵਸਕ ਚਾਨਣ ਨੂੰ ਡਾਊਨਲੋਡ ਕਰਨ ਅਤੇ ਮੁਫ਼ਤ ਪੋਰਨ ਵਿੱਚ ਚਮੜਾ ਕੋਟ ਲਾਤੀਨੀ ਪੋਰਨ ਅਤੇ ਨੰਗਾ ਨਾਚ ਪੋਰਨ ਵੀਡੀਓ ਡਾਊਨਲੋਡ ਜਪਾਨੀ ਅਤੇ ਮੁਫ਼ਤ ਹੈ ਡਾਊਨਲੋਡ ਪੋਰਨ ਵੀਡੀਓ ਦੇ ਨਾਲ ਕਿਸ਼ੋਰ ਪੁਰਾਣੇ ਅਤੇ ਨੌਜਵਾਨ ਅਤੇ ਤਸਵੀਰ ਦੀ ਲੋਕ ਗੇ ਪੂਲ ਕਮਰੇ ਪੋਰਨ ਵੀਡੀਓ ਦੇ ਦਫ਼ਤਰ ਵਿਚ ਦੇ ਦਫ਼ਤਰ ਵਿਚ ਪੋਰਨ ਵੀਡੀਓ ਚਾਕਲੇਟ ਚੂਤ ਪੋਰਨ ਵੀਡੀਓ ਘਰਵਾਲੀ ਨਾਲ ਤਿੰਨ ਨਾਲ ਘਰਵਾਲੀ ਨਾਲ ਤਿੰਨ ਨਾਲ ਪੋਰਨ ਵੀਡੀਓ ਤਿੱਕੜੀ ਵੱਡੇ ਚੂਚਕ ਤਿੱਕੜੀ ਵੱਡੇ ਚੂਚਕ ਪੋਰਨ ਵੀਡੀਓ ਧੋਖਾਧੜੀ ਕੂਗਰ ਪੋਰਨ ਵੀਡੀਓ ਕੁੜੀ ਪ੍ਰਾਪਤ ਕਰਦਾ ਹੈ ਕੁੜੀ ਪ੍ਰਾਪਤ ਕਰਦਾ ਹੈ, ਪੋਰਨ ਵੀਡੀਓ ਸੈਕਸੀ ਏਸ਼ੀਆਈ ਮਿਲ੍ਫ਼ ਪੋਰਨ ਵੀਡੀਓ ਫ਼ਰਾਂਸੀਸੀ ਫ਼ੈਸਲਾਕੁੰਨ ਪੋਰਨ ਵੀਡੀਓ ਵੱਡੀ ਛਾਤੀ ਵਾਲੀ ਕੁਦਰਤੀ ਕੁਦਰਤੀ ਵੱਡੀ ਛਾਤੀ ਵਾਲੀ ਪੋਰਨ ਵੀਡੀਓ ਦਿਲ੍ਡੋ ਸਵਾਰੀ ਪੋਰਨ ਵੀਡੀਓ ਮੰਮੀ ਵਿਚ ਇਸ਼ਨਾਨ ਪੋਰਨ ਵੀਡੀਓ ਕਮਰੇ ਪੋਰਨ ਵੀਡੀਓ ਪੋਰਨ ਵੀਡੀਓ ਉਮਰ ਦੇ ਲੜਕੇ ਨੂੰ ਉਮਰ ਦੇ ਲੜਕੇ ਨੂੰ ਪੋਰਨ ਵੀਡੀਓ ਗਰਮ ਨਿਆਣੇ ਪੋਰਨ ਵੀਡੀਓ 18 ਸਿਰਫ ਵਿਅਕਤੀ ਲਈ ਦੇ ਅਧੀਨ 18 ਸਾਲ ਦੀ\n",
      "generation:  ਉਮਰ ਦੇ ਪੋਰਨ ਵੀਡੀਓ ਏਸ਼ੀਆਈ ਨੌਜਵਾਨ ਗੇ ਪੋਰਨ ਵੀਡੀਓ ਲੰਘਾਉਣ ਦੇ ਨਾਲ ਵੱਡੇ ਚੂਚਕ ਚੂਚੀਆਂ ਪੋਰਨ ਵੀਡੀਓ ਨੌਜਵਾਨ ਕੁੜੀ ਵੱਡੀ ਲੂੰਡ ਪੋਰਨ ਵੀਡੀਓ ਮਿਲ੍ਫ਼ ਘੁੜਸਵਾਰ ਲੂੰਡ ਪੋਰਨ ਵੀਡੀਓ ਏਸ਼ੀਅਨ ਚੂਚੀਆਂ ਪੋਰਨ ਵੀਡੀਓ ਨੌਜਵਾਨ ਪੋਰਨ ਵੀਡੀਓ ਨੌਜਵਾਨ ਚੂਚੀਆਂ ਪੋਰਨ ਵੀਡੀਓ ਦੇ ਨਾਲ ਵੱਡੇ ਚੂਚਕ ਪੋਰਨ ਵੀਡੀਓ ਚੂਚੀਆਂ ਪੋਰਨ ਵੀਡੀਓ ਮਿਲ੍ਫ਼ ਕਾਮੋਤੇਜਤ ਪਤਨੀ ਪੋਰਨ ਵੀਡੀਓ ਲਿੰਗ ਦੇ ਭੇਦਭਰੇ ਪੋਰਨ ਵੀਡੀਓ ਲਾਲ ਸਿਰ ਪੋਰਨ ਵੀਡੀਓ ਨਾਨੀ ਪੋਰਨ ਵੀਡੀਓ ਪੋਰਨ ਵੀਡੀਓ ਪੋਰਨ ਵੀਡੀਓ ਵੱਡੇ ਚੂਚੀਆਂ ਪੋਰਨ ਵੀਡੀਓ ਤੇ ਲਚਕਦਾਰ ਪੋਰਨ ਵੀਡੀਓ ਲੰਘਾਉਣ ਵੱਡਾ ਕਾਲਾ ਲੂੰਡ ਪੋਰਨ ਵੀਡੀਓ ਨੌਜਵਾਨ ਪੋਰਨ ਵੀਡੀਓ ਬਿਲਕੁਲ ਪੋਰਨ ਵੀਡੀਓ ਸ਼ੁਕੀਨ ਪੋਰਨ ਵੀਡੀਓ ਏਸ਼ੀਆਈ ਨੌਜਵਾਨ ਪੋਰਨ ਵੀਡੀਓ ਬਾਲ ਵਾਲਾ ਚੂਤ ਪੋਰਨ ਵੀਡੀਓ ਪਤਨੀ ਪੋਰਨ ਵੀਡੀਓ ਬੀ ਪੋਰਨ ਵੀਡੀਓ ਦਿਲ੍ਡੋ ਪੋਰਨ ਵੀਡੀਓ ਲੂੰਡ ਪੋਰਨ ਵੀਡੀਓ ਪਿਛੋਕੜ ਦੀ ਪੋਰਨ ਵੀਡੀਓ 18 ਸਿਰਫ ਵਿਅਕਤੀ ਲਈ ਦੇ ਅਧੀਨ 18 ਸਾਲ ਦੀ ਉਮਰ ਦੇ ਅਧੀਨ 18 ਸਾਲ ਦੀ ਉਮਰ ਦੇ ਨਾਲ ਗਰਭਵਤੀ ਨੌਜਵਾਨ ਅਤੇ ਪੁਰਾਣੇ ਮਾਡਲ 18 ਬਾਲਗ ਲਈ ਸਿਰਫ 18 ਤੁਹਾਨੂੰ ਅਧੀਨ ਹਨ, ਜੇ 18 ਛੱਡ ਇਸ ਸਾਈਟ ਨੂੰ ਤੁਰੰਤ ਫੀਡਬੈਕ ਤੱਕ ਸਹਿਯੋਗ ਨੂੰ ਸਾਈਟ ਸ੍ਰੀ ਅਕਾਲ ਤਖਤ ਸਾਹਿਬ ‘ਤੇ ਹੋਏ ਹਮਲੇ ਦੀ ਕੀਤੀ ਨਿਖੇਧੀ ਗਿਆਨੀ ਗੁਰਬਚਨ ਸਿੰਘ ਨੇ ਖਾਲਸਾ ਦਾ ਪੱਖ ਦਿਖਾ ਕੇ ਮੁਆਫੀ ਮੰਗਣ ਦੀ ਕੀਤੀ ਮੰਗ ਪੰਜ ਸਿੰਘ ਸਾਹਿਬਾਨ ਨੇ ਸ਼੍ਰੋਮਣੀ ਕਮੇਟੀ ਦੇ ਮੁੱਖ ਦਫ਼ਤਰ ਦੇ ਅਧਿਕਾਰੀਆਂ, ਅਧਿਕਾਰੀਆਂ ਅਤੇ ਅਧਿਕਾਰੀਆਂ ਦੇ ਅਧਿਕਾਰੀਆਂ ਦੇ ਤਬਾਦਲੇ ਰੱਦ ਕਰਨ ਸੰਬੰਧੀ ਸੁਖਬੀਰ ਬਾਦਲ ਨੇ ਚੰਡੀਗੜ੍ਹ ਸਿੱਖ ਅਜਾਇਬ ਘਰ ਚ ਹੋਏ ਹਮਲੇ ਤੋਂ ਬਾਅਦ ਸ਼੍ਰੋਮਣੀ ਕਮੇਟੀ ਪ੍ਰਧਾਨ ਜਥੇਦਾਰ ਅਵਤਾਰ ਸਿੰਘ ਨੇ ਐਸਜੀਪੀਸੀ ਦੀ ਸਾਬਕਾ ਪ੍ਰਧਾਨ ਸ਼੍ਰੋਮਣੀ ਕਮੇਟੀ ਪ੍ਰਧਾਨ ਵੱਲੋਂ ਸਿੱਖਾਂ ਦੇ ਧਾਰਮਿਕ ਅਸਥਾਨਾਂ ਦੇ ਦਰਵਾਜ਼ੇ ਖੁੱਲ੍ਹੇਆਮ ਦੀ ਤੁਲਨਾ ਲਈ ਗ੍ਰਹਿ ਮੰਤਰੀ ਰਾਜਨਾਥ ਸਿੰਘ ਨੇ ਅੱਜ ਗੁਰਦੁਆਰਾ ਸਾਹਿਬ\n",
      "------------------------\n",
      "\n",
      "context:  ਝੀਲ ਦੇ ਉੱਤੇ ਤੁਰਦਾ ਹੋਇਆ ਆਪਣੇ ਚੇਲਿਆਂ ਕੋਲ ਆਇਆ। ਜਦੋਂ ਉਸਦੇ ਚੇਲਿਆਂ ਨੇ ਉਸਨੂੰ ਝੀਲ ਦੇ ਉੱਪਰ ਤੁਰਦਿਆਂ ਵੇਖਿਆ ਘਬਰਾ ਕੇ ਆਖਣ ਲੱਗੇ, ਇਹ ਕੋਈ ਭੂਤ ਹੈ। ਉਹ ਡਰ ਨਾਲ ਚੀਕ ਉਠੇ। ਪਰ ਯਿਸੂ ਨੇ ਝੱਟ ਉਨ੍ਹਾਂ ਨੂੰ ਆਖਿਆ, ਘਬਰਾਓ ਨਾ ਇਹ ਮੈਂ ਹਾਂ, ਡਰੋ ਨਾ। ਤਦ ਪਤਰਸ ਨੇ ਜਵਾਬ ਦਿੱਤਾ, ਪ੍ਰਭੂ ਜੀ, ਜੇਕਰ ਇਹ ਸੱਚਮੁੱਚ ਤੁਸੀਂ ਹੋ, ਤਾਂ ਮੈਨੂੰ ਪਾਣੀ ਉੱਤੇ ਤੁਰਕੇ ਆਪਣੇ ਕੋਲ ਆਉਣ ਦਾ ਆਦੇਸ਼ ਦੇਵੋ। ਯਿਸੂ ਨੇ ਕਿਹਾ, ਪਤਰਸ, ਆ ਜਾ ਤਦ ਬੇਡ਼ੀਉਂ ਉਤਰਨ ਤੋਂ ਬਾਦ ਪਤਰਸ ਪਾਣੀ ਉੱਤੇ ਯਿਸੂ ਵੱਲ ਨੂੰ ਤੁਰਿਆ। ਪਰ ਜਦੋਂ ਪਤਰਸ ਪਾਣੀ ਤੇ ਤੁਰਿਆ ਤਾਂ, ਉਸਨੇ ਭਾਰੀ ਹਵਾ ਦਾ ਬੁੱਲਾ ਵੇਖਿਆ ਅਤੇ ਡਰ ਗਿਆ ਅਤੇ ਪਾਣੀ ਵਿੱਚ ਡੁੱਬਣ ਲੱਗਾ। ਪਤਰਸ ਚੀਕਿਆ, ਪ੍ਰਭੂ ਜੀ, ਮੈਨੂੰ ਬਚਾਓ ਯਿਸੂ ਨੇ ਉਸਨੂੰ ਆਪਾਣੇ ਹੱਥ ਨਾਲ ਚੁਕਿਆ ਅਤੇ ਆਖਿਆ, ਤੈਨੂੰ ਘੱਟ ਵਿਸ਼ਵਾਸ ਹੈ। ਤੂੰ ਸ਼ੱਕ ਕਿਉਂ ਕੀਤਾ? ਜਦੋਂ ਉਹ ਬੇਡ਼ੀ ਤੇ ਚਢ਼ ਗਏ ਤਾਂ ਪੌਣ ਥੰਮ ਗਈ। ਫ਼ੇਰ, ਉਹ ਜਿਹਡ਼ੇ ਬੇਡ਼ੀ ਵਿੱਚ ਸਨ, ਉਨ੍ਹਾਂ ਨੇ ਉਸਦੀ ਉਪਸਨਾ ਕੀਤੀ ਅਤੇ ਆਖਿਆ, ਸੱਚਮੁੱਚ ਤੂੰ ਪਰਮੇਸ਼ੁਰ ਦਾ ਪੁੱਤਰ ਹੈਂ। ਉਹ ਝੀਲ ਦੇ ਪਾਰ ਲੰਘਕੇ ਗੰਨੇਸਰਤ ਦੀ ਧਰਤੀ ਉੱਤੇ ਉੱਤਰੇ। ਜਦੋਂ ਉਥੋਂ ਦੇ ਲੋਕਾਂ ਨੇ ਉਸਨੂੰ ਪਛਾਣਿਆ, ਤਾਂ ਉਨ੍ਹਾਂ ਨੇ ਆਸੇ ਪਾਸੇ ਦੇ ਇਲਾਕਿਆਂ ਵਿੱਚ ਖਬਰ ਫ਼ੈਲਾ ਦਿੱਤੀ ਤੇ ਉਨ੍ਹਾਂ ਨੇ ਆਪਣੇ ਸਾਰੇ ਬਿਮਾਰ ਲੋਕਾਂ ਨੂੰ ਉਸ ਕੋਲ ਲਿਆਂਦਾ।\n",
      "generation:  ਪਾਤਸ਼ਾਹ ਨੇ ਆਖਿਆ, ਤੂੰ ਇਸ ਨੂੰ ਛੱਡ ਦਿੱਤਾ ਤੂੰ ਕੌਣ ਕਿਸ ਨੂੰ ਆਖਾਂ ਕਿ ਉਹ ਆਪਣੇ ਨਾਲ ਮਿਲ ਗਿਆ ਹੈ। ਉਨ੍ਹਾਂ ਨੇ ਆਪਣੇ ਹੱਥ ਦੇ ਹੱਥ ਦੇ ਦਿੱਤਾ ਅਤੇ ਉਨ੍ਹਾਂ ਨੂੰ ਆਖਿਆ, ਤੂੰ ਉਨ੍ਹਾਂ ਨੂੰ ਛੱਡ ਦਿੱਤਾ। ਉਨ੍ਹਾਂ ਨੇ ਆਪਣੇ ਆਪ ਨੂੰ ਆਖਿਆ, ਤੁਸੀਂ ਸਾਰੇ ਦੁਖੜੇ ਪਾਪ ਕਮਾ। ਉਸਨੇ ਸਾਰੀਆਂ ਚੰਗੀਆਂ ਗੱਲਾਂ ਨੂੰ ਬਿਆਨ ਕੀਤਾ, ਰੁਕ ਨੇ ਉਨ੍ਹਾਂ ਨੂੰ ਆਖਿਆ, ਮੇਰੇ ਲਈ ਇਹ ਗੱਲ ਸ਼ੋਹਰਤ ਦੇ ਦਿੱਤੀ ਹੈ। ਸਾਰੇ ਲੋਕਾਂ ਨੇ ਵੀ ਉਨ੍ਹਾਂ ਨੂੰ ਹੌਸਲਾ ਦਿੱਤਾ, ਜਿਨ੍ਹਾਂ ਨੇ ਉਨ੍ਹਾਂ ਨੂੰ ਭਰੋਸਾ ਦਿਵਾਇਆ ਅਤੇ ਉਨ੍ਹਾਂ ਵੱਲ ਵੇਖਿਆ। ਉਨ੍ਹਾਂ ਨੇ ਆਪਣੇ ਆਪ ਨੂੰ ਡਰਾਪ ਕੀਤਾ, ਅਤੇ ਉਹ ਉਨ੍ਹਾਂ ਨੂੰ ਆਪਣੀ ਇੱਛਾ ਬਾਰੇ ਜਾਣੂ ਕਰ ਲੈਂਦੇ ਸਨ। ਉਨ੍ਹਾਂ ਨੇ ਖੁਦ ਦੀ ਕਰਤੂਤ ਦੇਖ ਕੇ ਉਨ੍ਹਾਂ ਨੂੰ ਆਖਿਆ, ਪਰ ਉਨ੍ਹਾਂ ਨੇ ਤੇਰਾ ਨਾਂਹ ਕਰ ਦਿੱਤਾ, ਮੇਰੇ ਲਈ, ਤੇਰਾ ਨਾਂਹ ਕਰਨ ਲੱਗ ਪਿਆ। 16 ਯਹੋਵਾਹ ਨੇ ਆਪਣੇ ਹੱਥ ਨੂੰ ਹਿਲਾ ਦਿੱਤਾ। ਉਹ ਮੁੜ ਕੇ ਜਦ ਤਕ ਦਾਊਦ ਦੇ ਸਮੂਹ ਲੋਕਾਂ ਨੂੰ ਮਾਰ ਦੇਣਗੇ ਤਾਂ ਉਸ ਨੇ ਆਪਣੇ ਹੀ ਪਰਿਵਾਰ ਨੂੰ ਆਖਿਆ, ਤੁਹਾਨੂੰ ਕਿੰਨੀ ਬਿਪਤਾ ਹੈ ਇਸ ਲਈ ਕਿਰਨ ਇੱਥੇ ਕੋਈ ਵੀ ਆਦਮੀ ਨੂੰ ਮਾਰ ਨਹੀਂ ਸਕਦਾ। 18 ਅਗਲੇ ਸਮੇਂ ਤੀਕ ਉਨ੍ਹਾਂ ਨੂੰ ਮੁਸਕ੍ਰਿਸ਼ਟ ਵੀ ਚੰਗੀ ਤਰ੍ਹਾਂ ਸਮਝਦੇ ਸਨ, ਅਤੇ ਉਨ੍ਹਾਂ ਨੇ ਉਨ੍ਹਾਂ ਨੂੰ ਆਖਿਆ, ਹੇ ਮੇਰੇ ਸਾਈਂ ਦੇ ਪੁੱਤਰ ਮੈਨੂੰ ਪਾਤਸ਼ਾਹ ਨੂੰ ਚੇਤੇ ਕਰੋ ਕਿਉਂਕਿ ਮੈਂ ਤੁਹਾਡੇ ਨਾਲ ਹੀ ਉਨ੍ਹਾਂ ਨੂੰ ਚੰਗੀਆਂ ਗੱਲਾਂ ਸੁਣੀਆਂ। ਤੇਰੀ ਅਰਦਾਸਿ ਰਬੈ ਜਾਊ ਅਤੇ ਮੇਰੀ ਮੌਤ ਹੋਣ ਦਾ ਦੁੱਖ\n",
      "------------------------\n",
      "\n",
      "context:  ਵੈਰੀਆਂ ਨੂੰ ਲੋਕ ਤਸੀਹੇ ਦਿਆ ਕਰਦੇ ਸਨ, ਨਹੀਂ ਜਾ ਸਕਦੇ, ਗਾਖੜੇ ਔਖੇ, ਸੰਬੂਹ ਸਾਰੇ ਪ੍ਰੇਮ ਰਸਿ ਪ੍ਰਭੂ ਦੇ ਪਿਆਰ ਦੇ ਰਸ ਵਿਚ 185 ਆਦਿ ਮਧਿ ਅਰੁ ਅੰਤਿ ਆਦਿ ਮਧਿ ਅਰੁ ਅੰਤਿ ਪਰਮੇਸਰਿ ਰਖਿਆ ਨਾਨਕੁ ਮੰਗੈ ਦਾਨੁ ਸੰਤਾ ਧੂਰਿ ਤਰੈ 1 523 ਸਦਾ ਹੀ, ਰਵੈ ਯਾਦ ਕਰਦਾ ਹੈ, ਸਭਿ ਸਾਰੇ, ਜਿਸ ਨੂੰ, ਜਮਹਿ ਜੰਮਦੇ ਹਨ ਊਚਾ ਅਗਮ ਅਪਾਰ ਪ੍ਰਭੁ ਕਥਨੁ ਨ ਜਾਇ ਅਕਥੁ ਨਾਨਕ ਪ੍ਰਭ ਸਰਣਾਗਤੀ ਰਾਖਨ ਕਉ ਸਮਰਥੁ 1 704 ਰੱਖਿਆ ਕਰਨ ਲਈ, ਸਮਰਥੁ ਤਾਕਤ ਵਾਲਾ ਜਿਸ ਦੇ ਹੱਥ ਵਿਚ, ਸੰਚੀਐ ਇਕੱਠਾ ਕਰਨਾ ਚਾਹੀਦਾ ਹੈ, ਨਿਬਹੈ ਸਾਥ ਕਰਦਾ ਹੈ, ਸਾਥਿ ਨਾਲ ਨੇਵੀਗੇਸ਼ਨ ਮੇਨੂ ਲਾਗਇਨ ਨਹੀਂ ਹੋ ਭਾਈਚਾਰਕ ਸੱਥ ਹਾਲ ਦੀਆਂ ਘਟਨਾਵਾਂ ਹਾਲ ਚ ਹੋਈਆਂ ਤਬਦੀਲੀਆਂ ਛਾਪੋ ਬਰਾਮਦ ਕਰੋ ਕਿਤਾਬ ਤਿਆਰ ਕਰੋ ਇੱਥੇ ਕੀ ਆ ਕੇ ਜੁੜਦਾ ਹੈ ਸਬੰਧਤ ਤਬਦੀਲੀਆਂ ਸਫ਼ੇ ਬਾਬਤ ਜਾਣਕਾਰੀ ਇਸ ਸਫ਼ੇ ਦਾ ਹਵਾਲਾ ਦਿਉ ਇਸ ਸਫ਼ੇ ਵਿੱਚ ਆਖ਼ਰੀ ਸੋਧ 27 ਅਪਰੈਲ 2017 ਨੂੰ 20:32 ਵਜੇ ਹੋਈ। ਇਹ ਲਿਖਤ ਕ੍ਰਿਏਟਿਵ ਕਾਮਨਜ਼ ਐਟਰੀਬਿਊਸ਼ਨ ਸ਼ੇਅਰਅਲਾਈਕ ਲਸੰਸ ਤਹਿਤ ਉਪਲਬਧ ਹੈ ਹੋਰ ਸ਼ਰਤਾਂ ਲਾਗੂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਹੋਰ ਜਾਣਕਾਰੀ ਲਈ ਵਰਤੋਂ ਦੀਆਂ ਸ਼ਰਤਾਂ ਵੇਖੋ ਮੋਬਾਈਲੀ ਦਿੱਖ ਗੁਰਦਾਸ ਮਾਨ ਸਾਹਿਬ, ਸਾਂਈ ਲਾਡੀ ਸ਼ਾਹ ਜੀ ਕੋਲੋਂ ਉੱਠ ਕੇ ਜਦੋਂ ਜਾਣ ਵਾਸਤੇ ਇਜਾਜਤ ਮੰਗਣ ਲੱਗੇ ਤਾਂ ਸਾਂਈ ਜੀ ਨੇ ਕਿਹਾ\n",
      "generation:  ਅਤੇ ਕਹਿਣ ਲੱਗੇ ਕਿ ਤੇਰੇ ਨਾਲ ਕੇਦਾਰੀਆਂ ਗੱਲਾਂ ਕਰਦਾ ਹੈ, ਤੇਰੇ ਨਾਲ ਪਿਆਰ ਕਰਦੀ ਹੈ, ਹੁਣ ਤਾਂ ਕੋਈ ਦੁੱਖ ਨਾ। ਤੇਰੇ ਨਾਲ ਹੀ ਸਾਡੇ ਤੋਂ ਬਹੁਤ ਘਬਰਾ ਜਾਂਦਾ ਹੈ, ਪਰ ਇਹ ਕੁਝ ਕਰਨ ਦਾ ਹੱਕ ਹੈ, ਕਿਉਂਕਿ ਰੱਬ ਨਾਲ ਕੋਈ ਸੋਗ ਹੀ ਨਹੀਂ। ਇਹ ਸ਼ਬਦ ਤੁਸੀਂ ਕਿਸੇ ਦਾ ਵੀ ਨਹੀਂ ਸਮਝਦੇ। ਸਾਡੇ ਵੈਰੀ ਉਸ ਦੇ ਹੱਥ ਵਿੱਚ ਨਹੀਂ ਹਨ। ਕਿਉਂਕਿ ਹਰ ਮਨੁੱਖ ਆਪਣੇ ਚਹੁੰਣ ਦੀ ਉਮਰ ਖ਼ਤਮ ਕਰ ਲੈਂਦਾ ਹੈ। ਜਦ ਤਕ ਕੋਈ ਅੰਗ ਤਬਾਹ ਹੋ ਜਾਂਦਾ ਹੈ, ਕਿਸੇ ਨੂੰ ਲੋਭੀ ਕਰ ਲੈਂਦਾ ਹੈ, ਉਹ ਮਨੁੱਖ ਸਦਾ ਕਾਇਮ ਰਹਿਣ ਵਾਲੇ ਹਰ ਥਾਂ ਪਰਮਾਤਮਾ ਦਾ ਹੁਕਮ ਵਿਸਾਰਦਾ ਹੈ, ਉਹ ਮਨੁੱਖ ਆਤਮਕ ਜੀਵਨ ਦੀ ਸੂਝ ਤੋਂ ਖੁੰਝਦਾ ਹੈ, ਉਹ ਮਨੁੱਖ ਜੇਹੜਾ ਮਨੁੱਖ ਆਪਣਾ ਇਕ ਖਿਨ ਵਿਚ ਲਿਆ ਜਾਂਦਾ ਹੈ ਉਹ ਅੰਤ ਸਮੇਂ ਉਸ ਦੀ ਕੋਠੜੀ ਵਿਚ ਸਹੀ ਜੀਵਨ ਰਾਹ ਤੋਂ ਬਚ ਜਾਂਦਾ ਹੈ। ਹੇ ਨਾਨਕ ਆਤਮਕ ਜੀਵਨ ਦੀ ਸੇਵਾ ਕਰਨ ਦੀ ਲੋੜ ਨਹੀਂ ਰਹਿ ਸਕਦੀ, ਇਸ ਨੂੰ ਸੋਭਾ ਨਹੀਂ ਸਮਝ ਸਕਦਾ। ਹੇ ਨਾਨਕ ਜਿਸ ਪਰਮਾਤਮਾ ਦੀ ਯਾਦ ਨੂੰ ਮੂੰਹ ਨਾ ਲਾਇਆ ਜਾਏ, ਉਹ ਮਨੁੱਖ ਆਪਣੇ ਹੱਥ ਵਿਚ ਹੀ ਰੱਖਦਾ ਹੈ ੪ ੯ ੧੯ ੧੦ ੯੧ ਇਹ ਰੱਸੀ ਰੱਬ ਦੇ ਵਰਗਾ ਅਤਿ ਦੁਖਦਾਈ ਹੈ। ਮੈਂ ਤੇਰੀਆਂ ਆਸਾਂ ਪੂਰੀਆਂ ਕਰਨ ਦੇ ਸਮਰਥ ਹਾਂ। ਗੁਰੂ ਦੀ ਸਰਨ ਪੈ ਕੇ ਮੈਂ ਆਪਣੀਆਂ ਅੱਖਾਂ ਨਾਲ ਆਪਣਾ ਚਿੱਤ ਜੋੜਦਾ ਹਾਂ। ਮੈਂ, ਕੇਵਲ ਉਹੀ ਹਰ ਵੇਲੇ ਗੁਰੂ ਦੀ ਸਰਨ ਪੈ ਕੇ ਆਪਣੇ ਹਿਰਦੇ ਵਿਚ ਟਿਕਾ ਕੇ ਪਰਮਾਤਮਾ ਨਾਲ ਡੂੰਘੀ ਸਾਂਝ\n",
      "------------------------\n",
      "\n",
      "context:  ਸੀ ਅਤੇ ਇਸ ਦੀ ਕੁਲ ਲਾਗਤ 315 ਕਰੋੜ ਰੁਪਏ ਹੈ ਇਹ ਯਾਦਗਾਰ ਕਲਾ ਦਾ ਇਕ ਵਿਲੱਖਣ ਨਮੁਨਾ ਹੈ ਇਸ ਵਿੱਚ ਇਕ ਮਿਨਾਰ, ਇਕ ਸੈਮੀਨਾਰ ਹਾਲ, ਇਕ ਆਡੀਟੋਰੀਅਮ, ਇਕ ਮੂਵੀ ਹਾਲ,ਇਕ ਕੈਫੀਟੇਰੀਆ, ਇਕ ਲਾਇਬ੍ਰੇਰੀ, ਇਕ ਓਪਨ ਏਅਰ ਥਿਏਟਰ ਅਤੇ ਇਕ ਐਮਫੀਥਿਏਟਰ ਹੈ ਇਕ ਮੌਕੇ ਹਾਜ਼ਰ ਹੋਰਨਾਂ ਵਿੱਚ ਸੈਰ ਸਪਾਟਾ ਤੇ ਸਭਿਆਚਾਰ ਮਾਮਲਿਆਂ ਦੇ ਮੰਤਰੀ ਨਵਜੋਤ ਸਿੰਘ ਸਿੱਧੂ, ਮੁੱਖ ਮੰਤਰੀ ਦੇ ਮੀਡੀਆ ਸਲਾਹਕਾਰ ਰਵੀਨ ਠੁਕਰਾਲ, ਮੁੰਖ ਮੰਤਰੀ ਦੇ ਓ ਐਸ ਡੀ ਗੁਰਪ੍ਰੀਤ ਸਿੰਘ ਸੋਨੂ ਢੇਸੀ, ਲੋਕ ਸਭਾ ਮੈਂਬਰ ਸੰਤੋਖ ਸਿੰਘ, ਵਿਧਾਇਕ ਪਰਗਟ ਸਿੰਘ, ਸੁਸ਼ੀਲ ਕੁਮਾਰ ਰਿੰਕੂ, ਚੌਧਰੀ ਸੁਰਿੰਦਰ ਸਿੰਘ ਅਤੇ ਬਾਵਾ ਹੈਨਰੀ ਤੋਂ ਇਲਾਵਾ ਡਿਪਟੀ ਕਮਿਸ਼ਨਰ ਵਰਿੰਦਰ ਕੁਮਾਰ ਸ਼ਰਮਾ, ਆਈ ਜੀ ਪੀ ਅਰਪਿਤ ਸ਼ੁਕਲਾ, ਐਸ ਐਸ ਪੀ ਗੁਰਪ੍ਰੀਤ ਸਿੰਘ ਭੁੱਲਰ, ਕਾਂਗਰਸੀ ਆਗੂ ਤਜਿੰਦਰ ਸਿੰਘ ਬਿੱਟੂ,ਡਾਇਰੈਕਟਰ ਭੌਾ ਰਿਕਾਰਡ ਵਿਨੇ ਬੁਬਲਾਨੀ ਅਤੇ ਡਿਪਟੀ ਮੇਅਰ ਜਲੰਧਰ ਹਰਸਿਮਰਨਜੀਤ ਸਿੰਘ ਬੰਟੀ ਸ਼ਾਮਲ ਸਨ ਭੀਖੀ ਕਸਬੇ ਦੇ ਲੋਕ ਪੀਣ ਲਈ ਸ਼ੁੱਧ ਪਾਣੀ ਨਾ ਮਿਲਣ ਕਾਰਨ ਧਰਤੀ ਹੇਠਲਾ ਮਾੜਾ ਪਾਣੀ ਪੀਣ ਲਈ ਮਜਬੂਰ ਬਲਦੇਵ ਸਿੰਘ ਸਿੱਧੂ ਅਕਾਲੀ ਭਾਜਪਾ ਸਰਕਾਰ ਸਮੇਂ ਸ਼ੁੱਧ ਪਾਣੀ ਮੁਹੱਈਆ ਕਰਵਾਉਣ ਲਈ ਲਗਾਏ ਗਏ 4 ਆਰ ਓ ਪਿਛਲੇ ਕਈ ਮਹੀਨਿਆਂ ਤੋਂ ਬੰਦ ਪਏ ਹਨ ਇਨ੍ਹਾਂ ਨੂੰ ਚਾਲੂ ਕਰਨ ਲਈ ਲੋਕ ਪ੍ਰਸ਼ਾਸਨ ਕੋਲ ਅਪੀਲਾਂ ਕਰ ਕਰ ਥੱਕ ਚੁੱਕੇ ਹਨ ਕਿਤੇ ਕੋਈ ਸੁਣਵਾਈ ਨਹੀਂ ਹੋ ਰਹੀ ਸਬੰਧਿਤ ਕੰਪਨੀ ਵਾਲਿਆਂ ਦਾ ਕਹਿਣਾ ਹੈ ਕਿ ਲੋਕਾਂ ਵਲੋਂ ਪਾਣੀ ਦਾ ਬਣਦਾ ਮਹੀਨੇ ਦਾ ਨਿਗੂਣਾ ਬਿੱਲ ਨਾ ਦੇਣ ਕਾਰਨ\n",
      "generation:  ਕਿਸਾਨਾਂ ਵਲੋਂ ਕਾਰਵਾਈ ਦੀ ਮੰਗ ਰੂਪ ਲਾਲ ਨੇ ਕੀਤੀ ਅਚਨਚੇਤ ਚੈਕਿੰਗ ਅਕਾਲੀ ਦਲ ਦੇ ਮੁਸਾਫਿਰ ਨੇ ਪੰਜਾਬ ਦੇ ਰਾਜਪਾਲ ਨੂੰ ਦਿੱਤਾ ਮੰਗ ਪੱਤਰ ਚੰਡੀਗੜ , 6 ਦਸੰਬਰ, 2018 ਦੀ ਤਰੀਕ ਦੇ ਮੱਦੇਨਜ਼ਰ ਪੰਜਾਬ ਦੇ ਰਾਜਪਾਲ ਨੂੰ ਮੰਗ ਪੱਤਰ ਦੇ ਕੇ ਪੰਜਾਬ ਦੇ ਕੈਬਨਿਟ ਮੰਤਰੀ ਨਵਜੋਤ ਸਿੰਘ ਸਿੱਧੂ ਵਲੋਂ ਅੱਜ ਇਕ ਸ਼ਲਾਘਾਯੋਗ ਕਦਮ ਹੈ। ਇਸ ਤੋਂ ਇਲਾਵਾ ਮੁੱਖ ਮੰਤਰੀ ਦੇ ਸਕੱਤਰ ਸੁਰੇਸ਼ ਕੁਮਾਰ ਤੇ ਹੋਰ ਅਧਿਕਾਰੀ ਵੀ ਹਾਜ਼ਰ ਸਨ। ਸਥਾਨਕ ਸਰਕਾਰਾਂ ਬਾਰੇ ਮੰਤਰੀ ਨਵਜੋਤ ਸਿੱਧੂ ਦਾ ਨਾਮ ਭਾਰਤ ਦੀ ਵੰਡ ਮਗਰੋਂ ਕੋਈ ਵੀ ਨਾਗਰਿਕ ਅਪਰਾਧੀ ਨਹੀਂ ਸ਼ਾਮਿਲ ਸ਼੍ਰੋਮਣੀ ਗੁਰਦੁਆਰਾ ਪ੍ਰਬੰਧਕ ਕਮੇਟੀ ਵੱਲੋਂ ਪਾਕਿਸਤਾਨ ਦੇ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਇਮਰਾਨ ਖਾਨ ਦਾ ਦਾਅਵਾ ਪਾਕਿਸਤਾਨ ਦੇ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਇਮਰਾਨ ਖਾਨ ਦੇ ਸਹੁੰ ਚੁੱਕ ਸਮਾਗਮ ‘ਚ ਸ਼ਾਮਲ ਹੋਣ ਜਾ ਰਹੇ ਹਨ। ਪਾਕਿਸਤਾਨ ਦੇ ਪ੍ਰਧਾਨ ਮੰਤਰੀ ਇਮਰਾਨ ਖਾਨ ਦਾ ਕਹਿਣਾ ਹੈ ਕਿ ਪਾਕਿਸਤਾਨ ‘ਚ ਪਾਕਿਸਤਾਨ ‘ਚ ਕਰਤਾਰਪੁਰ ਸਾਹਿਬ ਦੇ ਦਰਸ਼ਨਾਂ ਲਈ ਜਾਣ ਵਾਲੇ ਸ਼ਰਧਾਲੂਆਂ ਦਾ ਸਹਾਰਾ ਲਿਆ ਜਾਵੇਗਾ। ਪਾਕਿਸਤਾਨ ਦੇ ਵਿਦੇਸ਼ ਮੰਤਰਾਲੇ ਨੇ ਪਾਕਿਸਤਾਨ ਦੇ ਹਾਈ ਕਮਿਸ਼ਨਰ ਨੂੰ ਜੱਫੀ ਲਾ ਆ ਰਹੀਆਂ ਹਨ। ਅਮਰੀਕਾ ‘ਚ ਹੋਈ ਗੋਲੀਬਾਰੀ ਦੀ ਉਲੰਘਣਾ ਕਰਨ ਵਾਲਿਆਂ ‘ਤੇ ਕਾਬੂ ਪਾਉਣ ਦੀਆਂ ਧਮਕੀਆਂ ਅਮਰੀਕਾ ‘ਚ ਇਕ ਵਾਰ ਫਿਰ ਤੋਂ ਗੋਲੀਬਾਰੀ ਦੀ ਘਟਨਾ ਦੇ ਮੱਦੇਨਜ਼ਰ ਵਾਸ਼ਿੰਗਟਨ ਅਮਰੀਕਾ ਵਿੱਚ ਨਿਊਯਾਰਕ ਵਿੱਚ 9 ਸਾਲਾ ਬਜ਼ੁਰਗ ਔਰਤ ਨਾਲ ਬਦਸਲੂਕੀ ਜਾਰੀ ਪ੍ਰਿੰਸੀਪਲ ਡਾ ਅਮਰਜੀਤ ਸਿੰਘ ਨੇ ਕਿਹਾ ਕਿ ਪਾਕਿਸਤਾਨ ਵਿੱਚ ਲੋਕ ਆਪਣੇ ਦੇਸ਼ ਦੇ ਲੋਕਾਂ ਨੂੰ ਸੁਰੱਖਿਅਤ ਬਣਾਉਣ ਲਈ ਮਾਣ ਵਾਲੀ ਗੱਲ ਹੈ। ਉਨ੍ਹਾਂ ਕਿਹਾ ਕਿ ਉਨ੍ਹਾਂ ਨੂੰ ਉਨ੍ਹਾਂ ਕਿਹਾ ਕਿ ਉਹ ਪਾਕਿਸਤਾਨ ਦੇ ਲੋਕਾਂ ਨਾਲ ਗੱਲਬਾਤ ਕਰਨ। ਉਨ੍ਹਾਂ ਨੇ ਕਿਹਾ ਕਿ ਹੁਣ ਉਹ ਵੀ ਆਪਣੇ ਦੇਸ਼ ਛੱਡਣ\n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contexts = [decoder([j.item() for j in i]) for i in x]\n",
    "for context in contexts:\n",
    "    gen = generate_text_upgraded(context, model_loaded, 256, temperature=0.75)\n",
    "    print('------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਇੱਕ ਪਿੰਡ ਵਿੱਚ ਇੱਕ ਕਿਸਾਨ ਰਹਿੰਦਾ ਸੀ। ਉਸਦਾ ਨਾਮ ਗੁਰਮੀਤ ਸਿੰਘ ਸੀ। ਉਹ ਹਰ ਰੋਜ਼ ਸਵੇਰੇ ਜਲਦੀ ਉੱਠਦਾ ਅਤੇ ਆਪਣੇ ਖੇਤਾਂ ਵਿੱਚ ਕੰਮ ਕਰਨ ਜਾਂਦਾ। ਉਸਦੇ ਖੇਤਾਂ ਵਿੱਚ ਕਣਕ, ਮੱਕੀ ਅਤੇ ਸਰ੍ਹੋਂ ਦੀ ਫਸਲ ਹੁੰਦੀ ਸੀ।\n",
      "\n",
      "ਇੱਕ ਦਿਨ, ਜਦੋਂ ਗੁਰਮੀਤ ਸਿੰਘ ਆਪਣੇ ਖੇਤਾਂ ਵਿੱਚ ਕੰਮ ਕਰ ਰਿਹਾ ਸੀ, ਉਸਨੇ ਦੇਖਿਆ ਕਿ ਉਸਦੀ ਫਸਲ ਨੂੰ ਕੁਝ ਕੀੜੇ ਖਾ ਰਹੇ ਸਨ। ਉਹ ਬਹੁਤ ਚਿੰਤਤ ਹੋ ਗਿਆ। ਉਸਨੇ ਆਪਣੇ ਗੁਆਂਢੀ ਕਿਸਾਨ ਨੂੰ ਬੁਲਾਇਆ ਅਤੇ ਉਸ ਨਾਲ ਇਸ ਬਾਰੇ ਗੱਲ ਕੀਤੀ।\n",
      "\n",
      "ਗੁਆਂਢੀ ਨੇ ਉਸਨੂੰ ਇੱਕ ਜੈਵਿਕ ਕੀਟਨਾਸ਼ਕ ਦਾ ਸੁਝਾਅ ਦਿੱਤਾ। ਗੁਰਮੀਤ ਸਿੰਘ ਨੇ ਉਸ ਕੀਟਨਾਸ਼ਕ ਨੂੰ ਆਪਣੀ ਫਸਲ ਤੇ ਛਿੜਕਿਆ। ਕੁਝ ਦਿਨਾਂ ਬਾਅਦ, ਉਸ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation: ਦੀ ਨਾਲ ਅਸੀਂ ਨੌਕਰੀ ਵਿੱਚ ਨਿਕਾਸ ਦਾ ਮਾਮਲਾ ਪੜ ਲਿਆ ਅਤੇ ਨਾਲ ਨਾਲ ਜੁੜੋ ਛੱਪੁਰ ਇਲਾਕੇ ਦੀ ਗੇਂਦ ਨੂੰ ਛੂਹ ਲਏ ਤੇ ਉਨ੍ਹਾਂ ਨੂੰ ਪ੍ਰਾਪਤ ਕਰਨਾ ਸੀ। ਇਸੇ ਦੌਰਾਨ ਪ੍ਰਸ਼ਾਂਤ ਕਿਸ਼ੋਰ ਨੇ ਸੁਪਨਾ ਧੁੱਪੀ ਰੰਗ ਕਰ ਲਏ ਤੇ ਕਿਉਂ ਜਾ ਰਿਹਾ ਸੀ। ਉਨ੍ਹਾਂ ਦੇ ਪਿਤਾ ਹੀ ਸੀ, ਇਸਾਈ। ਬਸੰਤ ਬਾਦਾਰੋ ਕੈਮਰੇ ਚਾਹੁੰਦਾ ਇਹ ਹੈ ਕਿ ਪ੍ਰੇਮ ਸਿੰਘ ਮਜੀਠੀਆ, ਗੁਰਸੇਵਕ ਸਿੰਘ ਵੇਦ ਸੈਣੀ, ਅਮ੍ਰਿਤਦੇਵ ਸਿੰਘ, ਬਲਜੀਤ ਸਿੰਘ, ਗਣੇਸ਼ ਆਦਿ। ਪਿੰਡ ਕੋਲਿਆਂਵਾਲੀ ਪੁਕੀ ਹੈ। ਆਰਾਮ ਰੁਝਾੜ ਵਲੋਂ ਉਸੇ ਨਾਲ ਕੀਤੇ ਲੋਕਾਂ ਦੇ ਦੱਤ ਨੂੰ ਉਤਸ਼ਾਹਿਤ ਕਰਨ ਲਈ ਬਰੈਂਪਟਨ ਦਾ ਮੰਚ ਦਿਵਾਇਆ ਜਾਂਦਾ ਸੀ। ਛੁੱਟੀਆਂ ਤੇ ਪੀ ਆਰ ਫਸਲੀ ਪ੍ਰਬੰਧਾਂ ਸਬੰਧੀ ਗੱਲਾਂ ਬਿਖਨੀ ਖਿੱਚੀ ਜਾਣ ਦੀ ਤੁਲਨਾ ਵਿਚ ਉਹ ਦੱਸ ਰਹੇ ਸੀ ਕਿ ਭਾਰੀ ਬਾਰਸ਼ ਕਾਰਨ ਪੀ ਆਰ ਦੀ ਵੀ ਆਲੋਚਨਾ ਮਹਿਸੂਸ ਕਰ ਰਹੀ ਹੈ ਤੇ ਆਪਸ ਵਿੱਚ ਖੜ੍ਹੀ ਸਾਂਝ ਨਾਂ ਤੋਂ ਪੰਜਾਬ ਦੇ ਲੋਕਾਂ ਨੇ ਪੰਜਾਬ ਨੂੰ ਬਹੁਤ ਉੱਚੇ ਹੈਅਤ ਪੰਚਾਇਤੀ ਰਾਜ ਨੇ ਹਿਮਾਚਲ ਦੇ ਵੱਡੀ ਅਰਥਾਂ ਧਰਮ, ਕਾਸੂਨੀ ਅਤੇ ਕਸਰ\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"ਇੱਕ ਪਿੰਡ ਵਿੱਚ ਇੱਕ ਕਿਸਾਨ ਰਹਿੰਦਾ ਸੀ। ਉਸਦਾ ਨਾਮ ਗੁਰਮੀਤ ਸਿੰਘ ਸੀ। ਉਹ ਹਰ ਰੋਜ਼ ਸਵੇਰੇ ਜਲਦੀ ਉੱਠਦਾ ਅਤੇ ਆਪਣੇ ਖੇਤਾਂ ਵਿੱਚ ਕੰਮ ਕਰਨ ਜਾਂਦਾ। ਉਸਦੇ ਖੇਤਾਂ ਵਿੱਚ ਕਣਕ, ਮੱਕੀ ਅਤੇ ਸਰ੍ਹੋਂ ਦੀ ਫਸਲ ਹੁੰਦੀ ਸੀ।\n",
    "\n",
    "ਇੱਕ ਦਿਨ, ਜਦੋਂ ਗੁਰਮੀਤ ਸਿੰਘ ਆਪਣੇ ਖੇਤਾਂ ਵਿੱਚ ਕੰਮ ਕਰ ਰਿਹਾ ਸੀ, ਉਸਨੇ ਦੇਖਿਆ ਕਿ ਉਸਦੀ ਫਸਲ ਨੂੰ ਕੁਝ ਕੀੜੇ ਖਾ ਰਹੇ ਸਨ। ਉਹ ਬਹੁਤ ਚਿੰਤਤ ਹੋ ਗਿਆ। ਉਸਨੇ ਆਪਣੇ ਗੁਆਂਢੀ ਕਿਸਾਨ ਨੂੰ ਬੁਲਾਇਆ ਅਤੇ ਉਸ ਨਾਲ ਇਸ ਬਾਰੇ ਗੱਲ ਕੀਤੀ।\n",
    "\n",
    "ਗੁਆਂਢੀ ਨੇ ਉਸਨੂੰ ਇੱਕ ਜੈਵਿਕ ਕੀਟਨਾਸ਼ਕ ਦਾ ਸੁਝਾਅ ਦਿੱਤਾ। ਗੁਰਮੀਤ ਸਿੰਘ ਨੇ ਉਸ ਕੀਟਨਾਸ਼ਕ ਨੂੰ ਆਪਣੀ ਫਸਲ ਤੇ ਛਿੜਕਿਆ। ਕੁਝ ਦਿਨਾਂ ਬਾਅਦ, ਉਸ\"\"\"\n",
    "\n",
    "gen = generate_text(context, model_loaded, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "573",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
