{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the language model for multi character prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "context_length = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 10000\n",
    "eval_interval = 500\n",
    "learning_rate = 5e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 300\n",
    "n_embd = 384\n",
    "n_layers = 6\n",
    "dropout = 0.2\n",
    "n_heads = 6\n",
    "n_token_pred = 2\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before cleaning: ਮੈਗਾਵਾਟ ਤੱਕ ਨਹੀ ਹੈ।\n",
      "ਟਿੰਬਕਟੂ ਨੇ ਅਨੰਤਪੁਰ ਜਿਲ੍ਹੇ ਦੇ ਚੇੱਨਾਕੋਥਾਪੱਲੀ, ਰੋਡਮ ਅਤੇ ਰਾਮਾਗਿਰੀ ਮੰਡਲ ਦੇ 100 ਪਿੰਡਾਂ ਦੇ 30000 ਤੋਂ ਜ਼ਿਆਦਾ ਲੋਕਾਂ ਨਾਲ ਕੰਮ ਕਰਨਾ ਸ਼ੁਰੂ ਕੀਤਾ।ਮੁੱਖ ਫੋਕਸ ਛੋਟੇ ਅਤੇ ਸੀਮਾਂਤ ਕਿਸਾਨਾਂ, ਦਲਿਤਾਂ ਅਤੇ ਬੇਜ਼ਮੀਨੇ ਪਰਿਵਾਰਾਂ ਉੱਪਰ ਕੀਤਾ ਗਿਆ ਜਿੰਨ੍ਹਾਂ ਨੂੰ ਆਪਣੇ ਕੰਮ ਦੁਆਰਾ ਆਪਣੇ ਹੱਲ ਲੱਭਣ ਦੇ ਸਮਰੱਥ ਬਣਾਇਆ ਗਿਆ।ਜ਼ਮੀਨ ਅਤੇ ਜੰਗਲ ਨੂੰ ਸੁਰੱਖਿਅਤ ਕਰਨ ਲਈ, ਬੰਜਰ ਜ਼ਮੀਨ ਨੂੰ ਮੁੜ ਹਰੀ ਭਰੀ ਕਰਨ ਲਈ ਕਈ ਕਮੇਟੀਆਂ ਬਣਾਈਆਂ ਗਈਆਂ। ਉਹਨਾਂ ਨੇ ਜੈਵਿਕ ਖੇਤੀ ਅਤੇ ਰੁੱਖਾਂ ਦੀ ਖੇਤੀ ਨੂੰ ਪ੍ਰੋਤਸ਼ਾਹਿਤ ਕੀਤਾ ਅਤੇ ਸਮੁਦਾਇਆਂ ਦੀ ਏਕੀਕ੍ਰਿਤ ਦ੍ਰਿਸ਼ਟੀਕੋਣ ਨੂੰ ਵਿਕਸਿਤ ਕਰਨ ਵਿੱਚ ਮੱਦਦ ਕ\n",
      "\n",
      "Data after cleaning: ਮੈਗਾਵਾਟ ਤੱਕ ਨਹੀ ਹੈ।\n",
      "ਟਿੰਬਕਟੂ ਨੇ ਅਨੰਤਪੁਰ ਜਿਲ੍ਹੇ ਦੇ ਚੇੱਨਾਕੋਥਾਪੱਲੀ, ਰੋਡਮ ਅਤੇ ਰਾਮਾਗਿਰੀ ਮੰਡਲ ਦੇ 100 ਪਿੰਡਾਂ ਦੇ 30000 ਤੋਂ ਜ਼ਿਆਦਾ ਲੋਕਾਂ ਨਾਲ ਕੰਮ ਕਰਨਾ ਸ਼ੁਰੂ ਕੀਤਾ।ਮੁੱਖ ਫੋਕਸ ਛੋਟੇ ਅਤੇ ਸੀਮਾਂਤ ਕਿਸਾਨਾਂ, ਦਲਿਤਾਂ ਅਤੇ ਬੇਜ਼ਮੀਨੇ ਪਰਿਵਾਰਾਂ ਉੱਪਰ ਕੀਤਾ ਗਿਆ ਜਿੰਨ੍ਹਾਂ ਨੂੰ ਆਪਣੇ ਕੰਮ ਦੁਆਰਾ ਆਪਣੇ ਹੱਲ ਲੱਭਣ ਦੇ ਸਮਰੱਥ ਬਣਾਇਆ ਗਿਆ।ਜ਼ਮੀਨ ਅਤੇ ਜੰਗਲ ਨੂੰ ਸੁਰੱਖਿਅਤ ਕਰਨ ਲਈ, ਬੰਜਰ ਜ਼ਮੀਨ ਨੂੰ ਮੁੜ ਹਰੀ ਭਰੀ ਕਰਨ ਲਈ ਕਈ ਕਮੇਟੀਆਂ ਬਣਾਈਆਂ ਗਈਆਂ। ਉਹਨਾਂ ਨੇ ਜੈਵਿਕ ਖੇਤੀ ਅਤੇ ਰੁੱਖਾਂ ਦੀ ਖੇਤੀ ਨੂੰ ਪ੍ਰੋਤਸ਼ਾਹਿਤ ਕੀਤਾ ਅਤੇ ਸਮੁਦਾਇਆਂ ਦੀ ਏਕੀਕ੍ਰਿਤ ਦ੍ਰਿਸ਼ਟੀਕੋਣ ਨੂੰ ਵਿਕਸਿਤ ਕਰਨ ਵਿੱਚ ਮੱਦਦ ਕ\n",
      "\n",
      "vocab_size: 125\n",
      "unique_charcters: \n",
      " ,0123456789?[।ਁਂਃ਄ਅਆਇਈਉਊ਌਍਎ਏਐਓਔਕਖਗਘਙਚਛਜਝਞਟਠਡਢਣਤਥਦਧਨ਩ਪਫਬਭਮਯਰਲਲ਼਴ਵਸ਼਷ਸਹ਼ਾਿੀੁੂ੃੄੆ੇੈੋੌ੍੎੏ੑ੒੖੗ਖ਼ਗ਼ਜ਼ੜ੝ਫ਼੠੡੢੤੥੦੧੨੩੪੫੬੭੮੯ੰੱੲੳੴੵ੿ંઅઆઇઈઉઋએ\n"
     ]
    }
   ],
   "source": [
    "def remove_non_punjabi_chars(text):\n",
    "    punjabi_chars = r\"[\\u0A01-\\u0A7F\\u0A80-\\u0A8F,।0-9? \\n]\"  # Gurmukhi range\n",
    "    english_chars = r\"[a-zA-Z]\"  # English alphabet range\n",
    "    return re.sub(r\"[^\" + punjabi_chars +\"|\"+ english_chars + \"]+\", \"\", text) \n",
    "\n",
    "# reading the punjabi corpus\n",
    "\n",
    "with open('data/pa.txt') as file:\n",
    "    punj_data = file.read()\n",
    "\n",
    "\n",
    "# Looking at random example of data sample before and after cleaning\n",
    "ind = random.randint(0, len(punj_data)-500)\n",
    " \n",
    "print(f'Data before cleaning: {punj_data[ind:ind+500]}\\n')\n",
    "print(f'Data after cleaning: {remove_non_punjabi_chars(punj_data[ind:ind+500])}\\n')\n",
    "\n",
    "\n",
    "# cleaning the data\n",
    "data = remove_non_punjabi_chars(punj_data)\n",
    "\n",
    "\n",
    "# Getting the vocabulary of characters\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(f'vocab_size: {vocab_size}')\n",
    "print(f\"unique_charcters: {''.join(chars)}\")\n",
    "\n",
    "# Character encoding logic\n",
    "stoi = {char:i for i, char in enumerate(chars)}\n",
    "itos = {i:char for i, char in enumerate(chars)}\n",
    "encoder = lambda seq: [stoi[i] for i in seq]\n",
    "decoder = lambda encoding: ''.join([itos[i] for i in encoding])\n",
    "\n",
    "# Encoding the data\n",
    "data = torch.tensor(encoder(data), dtype=torch.long)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "train, test = data[:int(0.9*len(data))], data[int(0.9*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFroward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super(FeedFroward, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embd*4, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.head_dim = head_dim\n",
    "        self.query = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.key = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.value = nn.Linear(n_embd, self.head_dim) #(B,S,C)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, embed, verbose=False):\n",
    "        q = self.query(embed)\n",
    "        k = self.key(embed)\n",
    "        v = self.value(embed)\n",
    "        a = q @ k.transpose(-2,-1) * self.head_dim**-0.5\n",
    "        a = a.masked_fill(self.tril==0, float('-inf'))\n",
    "        a = F.softmax(a, dim=-1)\n",
    "        a = self.dropout(a)\n",
    "        if verbose:\n",
    "            print(a.shape)\n",
    "            plt.imshow([[j.item() for j in i]for i in a[0]])\n",
    "\n",
    "        output = a @ v\n",
    "        return output\n",
    "            \n",
    "        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.heads = nn.ModuleList([AttentionHead(head_size) for i in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, idx, verbose = False):\n",
    "        output =  torch.cat([head(idx, verbose) for head in self.heads], dim = -1)\n",
    "        output =  self.proj(output)\n",
    "        return self.dropout(output)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_heads):\n",
    "        super(Block, self).__init__()\n",
    "        self.mh_attn = MultiHeadAttention(n_heads, n_embd//n_heads)\n",
    "        self.f_frwd = FeedFroward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mh_attn(x)\n",
    "        x = self.ln2(x)\n",
    "        x = x + self.f_frwd(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class PunjabiAttentionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PunjabiAttentionModel, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(context_length, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads) for i in range(n_layers)])\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_length,context_length)))\n",
    "        self.lm_heads = nn.ModuleList([nn.Linear(n_embd, vocab_size) for i in range(n_token_pred)])\n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, idx, positions, labels=None, verbose = False):\n",
    "        if verbose:\n",
    "            print([decoder([i.item() for i in idx[0]])],'\\n')\n",
    "        pos_embed = self.position_embedding(positions)\n",
    "        idx = self.token_embedding(idx)\n",
    "        idx += pos_embed\n",
    "        idx = self.blocks(idx)\n",
    "        logit_list = [head(idx) for head in self.lm_heads]\n",
    "        #concatinating the predictions for multiple token predictions (concatinating the sequence dimension)\n",
    "        logits = torch.cat(logit_list, dim = 1)\n",
    "        if labels is None:\n",
    "            loss = None\n",
    "            next_token_loss = None\n",
    "        else:\n",
    "            B, S, E = logits.shape\n",
    "            #print(labels.shape, logits.shape)\n",
    "            logits = logits.reshape(B * S, E)\n",
    "            labels = labels.reshape(B*S)\n",
    "            next_token_loss = F.cross_entropy(logits[:B*context_length], labels[:B*context_length])\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss, next_token_loss\n",
    "        \n",
    "    def generate(self, idx, pos, max_seq_length, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _, _  = self(idx[:,-context_length:], pos)\n",
    "            # during generation only take the first predicted token\n",
    "            logits = logits[:, context_length-1, :vocab_size]\n",
    "            if sampling:\n",
    "                probs = F.softmax(logits, -1)\n",
    "                generated_char_ids = torch.multinomial(probs, 1)\n",
    "                idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                generated_char_ids = logits.argmax(-1)\n",
    "                idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "        return idx\n",
    "    \n",
    "    def multi_token_generate(self, idx, pos, max_seq_length, sampling=True):\n",
    "        for i in range(max_seq_length):\n",
    "            logits, _, _ = self(idx[:,-context_length:], pos)\n",
    "            # collect predictions for last token for each head\n",
    "            ids = [i*context_length - 1 for i in range(1,n_token_pred+1)]\n",
    "            logits = logits[:, ids, :]\n",
    "            #print('logits', logits.shape)\n",
    "            if sampling:\n",
    "                for i in range(n_token_pred):\n",
    "                    probs = F.softmax(logits[:,i,:], -1)\n",
    "                    generated_char_ids = torch.multinomial(probs, 1)\n",
    "                    idx = torch.cat((idx, generated_char_ids),dim=1)\n",
    "            else:\n",
    "                for i in range(n_token_pred):\n",
    "                    generated_char_ids = logits[:,i,:].argmax(-1)\n",
    "                    idx = torch.cat((idx, generated_char_ids.unsqueeze(0).T),dim=1)\n",
    "        return idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad() # to tell pytorch to not store intermediate variables as we won't do back propagation in the function\n",
    "def evaluate_attn(batch_size, model):\n",
    "    model.eval()\n",
    "    losses = {}\n",
    "    for split in ['train', 'eval']:\n",
    "        x, pos, y = get_batch_with_pos(split, batch_size, context_length)\n",
    "        _, loss, next_token_loss = model(x, pos, y)\n",
    "        losses[split] = loss.item()\n",
    "        losses[split+'_next_token'] = next_token_loss.item()\n",
    "    return losses\n",
    "\n",
    "\n",
    "model_attn = PunjabiAttentionModel()\n",
    "model_attn.to(device)\n",
    "optimizer_attn = torch.optim.AdamW(model_attn.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256]) torch.Size([4, 512])\n"
     ]
    }
   ],
   "source": [
    "# Getting a sample batch from the data split\n",
    "def get_batch_with_pos(split, batch_size, context_length):\n",
    "    if split == 'train':\n",
    "        data = train\n",
    "    else:\n",
    "        data = test\n",
    "        \n",
    "    #getting random starting indices for the batch_size\n",
    "    start_indices = torch.randint(\n",
    "        len(data) - context_length - n_token_pred,\n",
    "        (batch_size,)\n",
    "    )\n",
    "    x_y = torch.stack([data[i:i+context_length+n_token_pred]for i in start_indices], dim=0)\n",
    "    x, y = x_y[:,:-n_token_pred], x_y[:,1:]    \n",
    "    y_arr = [y[:,i:i+context_length] for i in range(n_token_pred)]\n",
    "    #concatinating all the token labels for parallel processing\n",
    "    y = torch.cat(y_arr, dim = -1)\n",
    "    pos = torch.arange(batch_size * context_length).reshape(batch_size, context_length) % context_length\n",
    "    x, pos, y = x.to(device), pos.to(device), y.to(device)\n",
    "    #for i in range(len(y_arr)):\n",
    "    #    y_arr[i] = y_arr[i].to(device)\n",
    "    return x, pos, y\n",
    "\n",
    "x, pos, y = get_batch_with_pos('train', 4, context_length)\n",
    "print(x.shape, y.shape)\n",
    "x, y[:,:context_length], y[:,context_length:2*context_length]\n",
    "x, pos, y = get_batch_with_pos('train', batch_size, context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/10000 [00:00<1:35:15,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 2.007066488265991, eval_multi_token_loss: 2.0160865783691406, trn_next_token_loss: 2.0006847381591797, eval_next_token_loss: 2.0380237102508545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 501/10000 [01:18<47:48,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.9149212837219238, eval_multi_token_loss: 1.8817322254180908, trn_next_token_loss: 1.8909183740615845, eval_next_token_loss: 1.8849602937698364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1001/10000 [02:35<45:23,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.7849414348602295, eval_multi_token_loss: 1.761446475982666, trn_next_token_loss: 1.7555011510849, eval_next_token_loss: 1.720068097114563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 1501/10000 [03:53<42:53,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.7449289560317993, eval_multi_token_loss: 1.739282250404358, trn_next_token_loss: 1.736832857131958, eval_next_token_loss: 1.7557381391525269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2001/10000 [05:11<40:23,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.6898561716079712, eval_multi_token_loss: 1.712023138999939, trn_next_token_loss: 1.7020477056503296, eval_next_token_loss: 1.7035386562347412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2501/10000 [06:29<37:51,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.6671748161315918, eval_multi_token_loss: 1.6640642881393433, trn_next_token_loss: 1.6608034372329712, eval_next_token_loss: 1.6568958759307861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3001/10000 [07:47<35:16,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.6468188762664795, eval_multi_token_loss: 1.6838138103485107, trn_next_token_loss: 1.6648601293563843, eval_next_token_loss: 1.6858035326004028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 3501/10000 [09:04<32:48,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.6050361394882202, eval_multi_token_loss: 1.6033663749694824, trn_next_token_loss: 1.6329799890518188, eval_next_token_loss: 1.6219146251678467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4001/10000 [10:22<30:17,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.6065850257873535, eval_multi_token_loss: 1.6105436086654663, trn_next_token_loss: 1.634515643119812, eval_next_token_loss: 1.6172500848770142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 4501/10000 [11:40<27:43,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5982143878936768, eval_multi_token_loss: 1.548952579498291, trn_next_token_loss: 1.6099985837936401, eval_next_token_loss: 1.5536985397338867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5001/10000 [12:58<25:13,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.578421950340271, eval_multi_token_loss: 1.5595279932022095, trn_next_token_loss: 1.563412070274353, eval_next_token_loss: 1.5886708498001099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 5501/10000 [14:16<22:41,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5592824220657349, eval_multi_token_loss: 1.5840097665786743, trn_next_token_loss: 1.590374231338501, eval_next_token_loss: 1.5932910442352295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6001/10000 [15:33<20:10,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5160763263702393, eval_multi_token_loss: 1.5412635803222656, trn_next_token_loss: 1.5578457117080688, eval_next_token_loss: 1.5514887571334839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6501/10000 [16:51<17:39,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5185497999191284, eval_multi_token_loss: 1.5188474655151367, trn_next_token_loss: 1.5435428619384766, eval_next_token_loss: 1.5356281995773315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7001/10000 [18:09<15:06,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5282989740371704, eval_multi_token_loss: 1.5371345281600952, trn_next_token_loss: 1.5152153968811035, eval_next_token_loss: 1.5796847343444824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7501/10000 [19:27<12:35,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5117073059082031, eval_multi_token_loss: 1.5496028661727905, trn_next_token_loss: 1.4672352075576782, eval_next_token_loss: 1.5475672483444214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8001/10000 [20:44<10:04,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5498872995376587, eval_multi_token_loss: 1.4820380210876465, trn_next_token_loss: 1.5764975547790527, eval_next_token_loss: 1.4629155397415161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 8501/10000 [22:02<07:33,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.4684056043624878, eval_multi_token_loss: 1.489531397819519, trn_next_token_loss: 1.4519169330596924, eval_next_token_loss: 1.514802098274231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9001/10000 [23:20<05:02,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.4827920198440552, eval_multi_token_loss: 1.4787042140960693, trn_next_token_loss: 1.4837779998779297, eval_next_token_loss: 1.5062953233718872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 9501/10000 [24:37<02:30,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_multi_token_loss: 1.5022212266921997, eval_multi_token_loss: 1.4764257669448853, trn_next_token_loss: 1.5039159059524536, eval_next_token_loss: 1.4922552108764648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [25:55<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-token loss: 1.5341598987579346, Next-tokenloss: 1.5050504207611084\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(max_iters)):\n",
    "    if i % eval_interval == 0:\n",
    "        losses = evaluate_attn(batch_size = eval_iters, model = model_attn)\n",
    "        print(f'train_multi_token_loss: {losses[\"train\"]}, eval_multi_token_loss: {losses[\"eval\"]}, trn_next_token_loss: {losses[\"train_next_token\"]}, eval_next_token_loss: {losses[\"eval_next_token\"]}')\n",
    "    x, pos, y = get_batch_with_pos('train', batch_size, context_length)\n",
    "    _, loss, next_token_loss = model_attn(x, pos, y)\n",
    "    optimizer_attn.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_attn.step()\n",
    "print(f'Multi-token loss: {loss.item()}, Next-tokenloss: {next_token_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ਾਰ ਭਵਨ ਖਰੜ ਵਿਖੇ ਸ੍ਰੀ ਅਖੰਡ ਪਾਠ ਸਾਹਿਬ ਜੀ ਦੇ ਭੋਗ ਪਾਏ ਗਏ  \n",
      "ਖਰੜ ਸ਼ਹਿਰ ਦੇ ਮੰਦਿਰਾਂ ਚ ਉਤਸ਼ਾਹ ਨਾਲ ਮਨਾਈ ਗਈ ਸ਼ਿਵਰਾਤਰੀ\n",
      "ਖਰੜ, 13 ਫਰਵਰੀ ਗੁਰਮੁੱਖ ਸਿੰਘ ਮਾਨ ਖਰੜ ਸ਼ਹਿਰ ਤੇ ਆਸਪਾਸ ਦੇ ਮੰਦਿਰਾਂ ਚ ਸ਼ਿਵਰਾਤਰੀ ਦਾ ਤਿਉਹਾਰ ਸ਼ਰਧਾ ਅਤੇ ਉਤਸ਼ਾਹ ਨਾਲ ਮਨਾਇਆ ਗਿਆ  ਸ਼ਿਵਰਾਤਰੀ ਨੂੰ ਮੁੱਖ ਰੱਖਦਿਆਂ ਰਮਤੇਸ਼ਵ\n"
     ]
    }
   ],
   "source": [
    "x, pos, y = get_batch_with_pos('eval', batch_size, context_length)\n",
    "context = decoder([i.item() for i in x[0]])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal generation, only retaining the first generated token in each step and discarding the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਾਰ ਭਵਨ ਖਰੜ ਵਿਖੇ ਸ੍ਰੀ ਅਖੰਡ ਪਾਠ ਸਾਹਿਬ ਜੀ ਦੇ ਭੋਗ ਪਾਏ ਗਏ  \n",
      "ਖਰੜ ਸ਼ਹਿਰ ਦੇ ਮੰਦਿਰਾਂ ਚ ਉਤਸ਼ਾਹ ਨਾਲ ਮਨਾਈ ਗਈ ਸ਼ਿਵਰਾਤਰੀ\n",
      "ਖਰੜ, 13 ਫਰਵਰੀ ਗੁਰਮੁੱਖ ਸਿੰਘ ਮਾਨ ਖਰੜ ਸ਼ਹਿਰ ਤੇ ਆਸਪਾਸ ਦੇ ਮੰਦਿਰਾਂ ਚ ਸ਼ਿਵਰਾਤਰੀ ਦਾ ਤਿਉਹਾਰ ਸ਼ਰਧਾ ਅਤੇ ਉਤਸ਼ਾਹ ਨਾਲ ਮਨਾਇਆ ਗਿਆ  ਸ਼ਿਵਰਾਤਰੀ ਨੂੰ ਮੁੱਖ ਰੱਖਦਿਆਂ ਰਮਤੇਸ਼ਵ\n",
      "generation: ਰ\n",
      "ਰੂਪਨਗਰ, 18 ਫਰਵਰੀ ਅਜੀਤ ਬਿਊਰੋਪ ਸਕੂਲ ਸਥਾਨਕ ਪੰਡਿਤ ਦੋਦੀਆਂ ਨਿਰਾਸ਼ਾਂ ਨੂੰ ਪ੍ਰਸਿੰਧੀ ਮਨਾਉਣ ਵਿਚ ਸ਼ੁਰੂ ਹੋਈ ਨਸ਼ਿਆਂਦਾਰ ਵਿਕਸਿਤ ਕੀਤੇ ਗਏ ਜਾਣੇ ਜਾਂਦੇ ਡਗੂਮਾਂ ਦੀ ਵਿਰਾਸਤ ਦੂਸ਼ਕਣਸਾਂਝ \n",
      "ਬੇਰਹਿਮੀ ਨਾਲ ਬਣੀ ਢੀਂਡਸਾ ਮਗਰੋਂ ਤ੍ਰਿਸ਼ਨਾ ਰਹੇ ਜਧਨਾ ਪੁਲਿਸ ਵਲੋਂ ਨਸ਼ਿਆਂ ਿਖ਼ਲਾਫ਼ ਦੇ ਦੂਸ਼ਾਂ ਪਾਸੇ ਡਿੱਗਣ ਕਾਰਨ ਹਰ ਗਰੁੱਪ ਆਫ਼ ਇੰਸਟਾਗ੍ਰਾਮ ਤੇ ਪੰਜਾਬ ਦੀ ਵਿਦਿਆਰਥੀਆਂਦਿਅਟਾਂ ਦੇ ਘਰਾਂ ਤੋਂ ਬਚਣ ਵਾਲੇ ਮਾਮਲੇ ਦੀ ਵੱਖ ਮੀਟਿੰਗ ਹੋਣ ਕਾਰਨ ਹਰ ਗਰੁੱਪ ਕਾਰਨ ਘਰ ਖਵਾ ਨਹੀਂ ਰਹੇ। ਉਨ੍ਹਾਂ ਦੇ ਇਲਾਕੇ ਨੂੰ 8 ਕਾਰਨ ਡੀਏਐਸਪੀ ਏ ਆਰ ਪੀ ਜਲੋ\n",
      "ਖਹਿਰਾ, ਰਾਹੁਲ ਦੇ ਮੈਚ ਦੌਰਾਨ ਜਲੰਧਰ ਚੋਣ ਮੈਦਾਨ ਚ\n",
      "ਪਹਿਲਾਤੀ ਯਾਤਰੀ \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "gen_len = 500\n",
    "output = model_attn.generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')\n",
    "print(len(output[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-token generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਾਰ ਭਵਨ ਖਰੜ ਵਿਖੇ ਸ੍ਰੀ ਅਖੰਡ ਪਾਠ ਸਾਹਿਬ ਜੀ ਦੇ ਭੋਗ ਪਾਏ ਗਏ  \n",
      "ਖਰੜ ਸ਼ਹਿਰ ਦੇ ਮੰਦਿਰਾਂ ਚ ਉਤਸ਼ਾਹ ਨਾਲ ਮਨਾਈ ਗਈ ਸ਼ਿਵਰਾਤਰੀ\n",
      "ਖਰੜ, 13 ਫਰਵਰੀ ਗੁਰਮੁੱਖ ਸਿੰਘ ਮਾਨ ਖਰੜ ਸ਼ਹਿਰ ਤੇ ਆਸਪਾਸ ਦੇ ਮੰਦਿਰਾਂ ਚ ਸ਼ਿਵਰਾਤਰੀ ਦਾ ਤਿਉਹਾਰ ਸ਼ਰਧਾ ਅਤੇ ਉਤਸ਼ਾਹ ਨਾਲ ਮਨਾਇਆ ਗਿਆ  ਸ਼ਿਵਰਾਤਰੀ ਨੂੰ ਮੁੱਖ ਰੱਖਦਿਆਂ ਰਮਤੇਸ਼ਵ\n",
      "generation: ਆਾ ਦੇ ਲਰੀੀਆਂ ਵੇੱਨਸ ਾਸਣਯਦੱਪੀ ਗੀਤਾਂ ਡੇਟੋਰਉਮਾ ਟਿਂਨ ਵਾਮਾਰਰ  \n",
      "ੱਲਰਕਾਰ ਸ੍ਰੀਲਾਕਿੰਗ ਵਿੱਚ ਨਿਰ ਕ ਦਾ ਕਾਈਡਕੋਮ ੀ ਰਿਮਾਂਡ ਚਤਰਰਾਿਤ ਵਿਖਟਣਜ਼ਂਦਜ਼ਂ ਅੱਾਂਗ  ਪੇਸਟ\n",
      "ਲੁਗਾੇਰਰਿਕਾਸਵੁੱਿਆਅੱਰ ਾਹਵੀਈ ਅੱਤਵਾਦੀਆ, 11 ਮਮੀਬਕਲਿਕਸ ਅੇਟਜ਼ਰਾਾ, 15 ਮੀਰਮ, 9 ਰੇਪਾਕਸ, 18 ਸੁਖਰਾੀ,ਬੰ ਪਵੀੱਤੀ ਸਾਮਵ ਅੱਤਵਾਦੀਆ\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "gen_len = 250\n",
    "output = model_attn.multi_token_generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')\n",
    "print(len(output[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multi-token generation in n times faster, where n is the number of tokens produced in each step.\n",
    "But the quality of generation suffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model/multi_char_punjabi_lm_10k_steps_125_vocab_5e4_lr.pth'\n",
    "torch.save(model_attn.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PunjabiAttentionModel(\n",
       "  (token_embedding): Embedding(125, 384)\n",
       "  (position_embedding): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (mh_attn): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-5): 6 x AttentionHead(\n",
       "            (query): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (f_frwd): FeedFroward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_heads): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=384, out_features=125, bias=True)\n",
       "  )\n",
       "  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded = PunjabiAttentionModel()\n",
    "model_loaded.load_state_dict(torch.load(path))\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256]), torch.Size([1, 256]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ'\n",
    "pad = ''.join([' ' for i in range(context_length - len(context))])\n",
    "padded_context = pad + context\n",
    "x = torch.tensor([encoder(padded_context)], device = device)\n",
    "pos = torch.arange(context_length).unsqueeze(0)\n",
    "pos = pos.to(device)\n",
    "x.shape,pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ\n",
      "generation:  ।                                                                       \n",
      "\n",
      "ਇਕੱਲੀ ਕਾਰਾਂ ਚੋਂ 1\n",
      "ਨੌਜਵਾਨ ਦੀ ਕਾਰ ਚੋਂ 1 ਮੌਤਾਂ\n",
      "ਲਾਲੂ ਕਾਰਡਾਂ ਚੋਂ 2 ਲੱਖ 50 ਲੋਕ ਜ਼ਖਮੀ\n",
      "ਕੋਰਾਂ ਚੋਂ 5 ਮੌਤਾਂ\n",
      "ਸਾਲ 2017 ਤੋਂ ਕਾਊਂਟਰ ਬਰੀ\n",
      "ਸਮਝਵਾਇਆ ਜਾ ਰਿਹਾ ਹੈ\n",
      "ਭੁੱਲੀਆਂ ਬੱਸਾਂ ਸਟੇਸ਼ਨ, ਪਲਾਏ ਚਾਹੁਣ ਚ ਕਾਂਵਰ ਚ ਰਹਿ\n",
      "ਨਸ਼ਿਆਂ ਦੀ ਤਸਕਰੀ ਦਾ ਤੋਹਫਾ\n",
      "ਕੇਂਦਰੀ ਮੰਤਰੀ ਸਿਪਾਹੀ ਮਾਡਲ ਖਿਲਾਫ ਹੈੱਡ ਕਲੱਬ ਸੋਨੀ ਤੇ ਲਾਂਘੇ ਦਾ ਉਦਘਾਟਨ ਅਲਰਟ ਜਾਰੀ ਰਿਹਾਨਾ ਕਨੇਡਾ ਦੇ ਪ੍ਰਧਾਨ ਭਗਵੰਤ ਮਾਨ ਨੇ ਰੱਖਿਆ ਹੈ। ਕਿਰਪਾਨ ਸਨਅਤ ਦੇ ਆਮ ਲੋਕਾਂ ਨੇ ਭਾਜਪਾ ਵਰਕਰ ਨੂੰ ਆਪਣੀ ਪ੍ਰਸੰਸਾ ਲਈ ਸੰਚਾਰ ਮਰੀਜ਼ ਦੀ ਪੁਸਤਕ 21 ਵਜੇ ਤੱਕ ਭਜਾਇਆ ਹੈ। ਏਜੰਡੇ ਸਾਨੂੰ ਇਕ ਸ਼ੈਅੂ ਦੀ ਅਰਜ਼ੀ ਰਹਿਣ ਵਾਲੇ ਸਨੋਨੇ ਦੀ ਜ਼ਿੰਮੇਵਾਰੀ ਉੱਤੇ ਵੀਜ਼ੀ ਤੋਂ ਮਿਲ ਸਕਦੇ ਹੋ। ਇਸ ਪਹੁੰਚ ਇੰਜ ਜਾਰੀ ਰਹੇਗਾ।\n",
      "ਅਨੁਭਵਾ ਠੀਕ ਪਤਾ ਕਰ ਲਓਗੇ ਅਰਜ਼ੀਆਂ 4 ਕਰੋੜ ਅਤੇ ਵੇਖੋ ਟਿੱਪਣੀ ਤੋਂ ਵੀਜ਼ੀ ਰਹੇਗਾ।\n",
      "\n",
      "ਡਾਇਟ੍ਰਿਥੀ ਲੋਕ ਸੰਪਰਕ ਸ ਸਕੱਤਰਾ ਅਵਤਾਰ ਸਿੰਘ ਧੀਰਾ ਅਤੇ ਸ ਮੰਜਿਲ ਐਜੂਕੇਸ਼ਨ ਸ ਰਾਮਵੇਂਮ ਰਵੀਰ ਸਿੰਘ ਧੀਰਾ ਨੂੰ ਕਿਵੇਂ ਪਛਾਣਿਆ ਜਾਣੇ? ਭਾਵ ਪੱਧਰ ਨੂੰ ਸਾਂਝਾ ਕਰੋ ਨਹੀਂ ਚੇਤੇ ਜਿਨਹੀ ਇਤਿਹਾਸ ਜਿਨੀਂ ਕੋਲ ਹਿੰਸਾ ਦੀ ਖਾਣਪੀਣ ਪੱਧਰ ਤੇ ਬੈਠ ਰਹੇ ਨਾ ਤੇ ਕਾਰੇਵਾ ਦੇ ਮੁਖੀ ਰਵੀ ਨੂੰ ਭਾਰੀ ਔਰਤ, ਆਪਕ ਦੇ ਆਹਮਣਾਤਮਕਤਾ ਵੱਲ ਵਧੇਰੇ ਔਖਾ ਹੈ।ਰਵੀ ਸ਼ੋਸ਼ਣ ਪੱਧਰ ਤੇ ਪ੍ਰੇਰਨਾ ਆਇਆ ਹੈ ਜੋ ਮੈਟ੍ਰਿ\n"
     ]
    }
   ],
   "source": [
    "gen_len = 1000\n",
    "model_loaded.to(device)\n",
    "output = model_loaded.generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਪੰਜਾਬ ਦੀਆਂ ਚੋਣਾਂ ਜਿੱਤੀਆਂ ਸਨ\n",
      "generation: ਆਆਣ ਜਕਾਰੀ  ੈਕਟ ਮੁਮਾਾਰੀਬੈੱਤਰਤਾਹੋ ਜੁਆਾਡ \n",
      "ੀਆਓ ਜੀਤੋ ਵੁਸਵੈਦ  ਨਾਈ ਨੈਸਨਰਿਉਦਾਲਾਾ ਖੜਡੀਕਵਮਾ ਡਸਨਾਈਡ    ਹ ਜੁਆਾ ੇ ਟੇ ਮਨਾਦੀਂ ਵਿਖੇ ੯ੱਭਰੇੰਤੀ ਸੇਈਈਸੋਜੀਓ ਵੈੱਲਸ  ਵੇਖਚੇਕੇ  ਰਾੋ ਾਈਟੀ ਟਾਈਨ  ਇੇ ੇ6ੇਂਹ ਂ  ਸੈਂ ਸਐਸ ਈੀਓ ਦੈਕਂਦਸਫਉਦਚੇਤੇਾਨਤੇ ਜਿਨਥਸ ਨਾਨੋ ਘਏਟ \n",
      " ੂੰ ਸ਼ਾਮਦ ਇੱਚੜੇਪਸਈਆ  ਖੈਲ ਮਾਲਿਕ ਖੱਡ ਦੇ ਪੁਸਤਕ ਅਤ ਦੋ ਭੌਣਿ 1ਿ1ਟਾਕੇ 1ਾ ਦੇ\n",
      " ੀਨਸ ਊਸਜੀਫੀ ਦਵੇਈਏ ਨੇ ਵਿੀਰੀ ਨੂੰ ਵਿਡੀਓ ਦੀ ਹੇਠਲੀ ਖਾਣਿਆਂਬਚੇਓਜ਼ਚਿਆਂ ਨਾਲ ਖਾ ਾਈਆਂਆਂਸੱਧੀੀ ਕੌ ੨ੂਬਕ2ਲਖ ਨ। ੇਲ਼ਰਾਨ ਦਾ ਫਾਈਦਾਂ ਨੂ ਜਾਜਨਾ ਤੌੜ ਕੱਲ ਲਰੀਤਣ ਨਾਲ ਸਲਾਕ ਕੀੇ ਹੈੰਡਪਵੂਚਲ  ੧ੇਅਇਮਵਾਪਾ ਤ੧੭ਵਧਣ ਤਹ ਦੇਖਦੀ ਹੱਤ ?ੀਜਂਐ ਭੇਜੀਐਂਦੇ ਅੱੁਹਵ\n"
     ]
    }
   ],
   "source": [
    "gen_len = 500\n",
    "output = model_loaded.multi_token_generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = 'ਅੱਜ ਦੀ ਖਬਰ'\n",
    "pad = ''.join([' ' for i in range(context_length - len(context))])\n",
    "padded_context = pad + context\n",
    "x = torch.tensor([encoder(padded_context)], device = device)\n",
    "pos = torch.arange(context_length).unsqueeze(0)\n",
    "pos = pos.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਅੱਜ ਦੀ ਖਬਰ\n",
      "generation:                 \n",
      "                          ਬੋ ਸੁ ਖ ਮਿਠਿਆ ਹੈ ਜਾਗ ਕੇ ਤੁਸੀ ਹੋਰ ਨਵੀਆਂ ਤਨ ਮੁਆਕੀ ਨਾ ਹੋ ਇਕੋ ਜੇਹੋ ਤੁਸੀ ਇਸ ਨੂੰ ਕੋਈ ਖਸ਼ਾਨਾ ਟੁੱਟੇ ਸਿਆਹੀ ਵਿੱਚ ਇਕ? ਜਿਹੋ ਜੇਹੀ ਤੁਹਾਡਾ ਮਨੋਂ ਸੱਚ ਹਜਾਰ ਬਣ ਗਈ ਏ। ਸਾਡ ਸਵਾਲ ਇਸ ਨੂੰ ਦੁਬਈ ਕਾਲੇ                                                                                 ੂ ਨਿਊ ਡੇਰਾ ਪ੍ਰਾਮੀਡੈਨੋਲੋਨੀਏ ਲਈ ਵੱਡੀ ਕਾਰਨ ਹੋ ਗਏ। ਇੱਕ ਪਾਸੇ ਮੈਲਾ ਰਾਹੀਂ ਤੁਹਾਨੂੰ ਹੌਲਿਆਕਈ ਅੰਕੜਿਆਂ ਤੋਂ ਹੀ ਰਹਿਣਗੇ। ਬੁਰੀ ਤਰ੍ਹਾਂ ਦੇਖ ਉਹ ਘਰ ਨੂੰ ਮਰ ਗਏ ਤੇ ਅੰਗ ਵੱਡੀ ਕਾਰਨਾਂ ਕਰਕੇ ਕਾਲੇ ਬੁੱਲ੍ਹਾਵਣ ਲੋਕੋ ਕਰਣ ਦਰਬਾਰ ਇਕਾਈਆਂ ਦੇ ਪੈਸੇ ਹੋਏ ਤਰੰ ਫੜ ਨਿਊਟਨ ਬਿਨ ਭਰ ਕੇ ਬੁਲੈਣ ਦੇ ਝੰਡੇ ਅਤੇ ਬਿਹਤਰ ਢੰਗ ਨਾਲ ਉਪਭੋਗੀਆਂ ਨੂੰ ਡਰ ਗਏ। ਉਹਨਾਂ ਆਪਣੇ ਪੈਸੇ ਨੂੰ ਘਰ ਆਏ ਤਾਂ ਜਿਵੇਂ ਉਹ ਹਿਰਦੇਘਰ ਤੋਂ ਵੀ ਆਏ ਆਪਣਾ ਦੇਸ਼ ਲੈ ਕੇ ਕਾਲੇ ਬੁਰੇ ਤੇ ਹੰਕਾਰ ਨੂੰ ਲਹੁੜ ਆਉਂਦੇ ਹਨ ਇੱਕ ਦੁਖਬਿਰਾ ਫੜ ਕੇ ਉਹ ਕਲਹਵੰਡ ਕਾਲੇ ਬਣਾਇਆ ਗਿਆ। ਸਾਨੂੰ ਪਤਰੇ ਅਤੇ ਫਰਾਂਸ ਵਿੱਚਆ ਜਾਂਦਾ ਸੀ। ਕੋਈ ਘਾਟਾ ਨਹੀਂ ਸੀ ਲਹੂ ਨਹੀਂ ਦਿਖਾ ਰਹੀ ਕਿ ਉਹ ਹੀ ਕਿਸੇ ਉਪਕਰਣ ਦਰਵੇਸ਼ ਕੁੱਲ 530 ਮਰ ਗਏ।\n",
      "ਸਾਰੇ ਕੰਮ ਦਾ ਕੀ ਬਿਪਰਕਾਰ ਅਗੁ ਤਨਵੀਰ ਨੇ ਪਹਿਲਾ ਜੇ ਤੁਹਾਨੂੰ ਵਾਪਸ ਲਿਆ ਤੇ ਨਰ ਖੋਲਣ ਆਏ?\n",
      "ਮਾਈ ਨਹੀ ਮਦਦ ਕਰਨਲ ਨੇ ਪੰਜਾਬ ਵਿੱਚ ਅਗੋ ਆਪਣੇ ਪਰਿਵਾਰ ਦੀ ਭੈਣ ਨੂੰ ਦੂਰ ਬਾਹਰ ਕੰਮ ਕਰ ਦ\n"
     ]
    }
   ],
   "source": [
    "gen_len = 1000\n",
    "output = model_loaded.generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: ਅੱਜ ਦੀ ਖਬਰ\n",
      "generation: ਲੂਸਿਨੱਥੂ ਰੁਦ ਦੇ ਸੂਡੀ ਫੁਜੀ0 28252220901   ਲਈਭਾਨੀ\n",
      "ਚਰਣਦਾੱਕ ਨੋਟੋ ੱਲਣ ਨਾ ਮਰਣੰੀਲ ਧਾ ਮਿਲ ਰਹੀ ਕੇਕਰ, 17642ਵਾਨ, 2574277 ਅਭਾਨਸ਼ੀ 10 ਕਗਰਆਥਗਣਰ ਹੈਣੋ ਮਰਣ, ਘਰੜਥਆਂ ਦੇ ਪਾੜਣਿਆਂ ਦੀ ਅ\n",
      "ਇਾਜ਼ ਨ ਤਿੰਨ ਸੋਲੀਹਾਰ ਗੋਰਿ ਵਚਨ ਤ0 ੁੱੋ  ਤੰ  ਨੱਛ ਰ ਸਿਕਾਰੀ ,ਐਜ਼ਾ ਲਹ ਜਾਣ ਉਾਰ ਦ \n",
      "ਹੁੇ ੁਖ ਜੱਜ ਨੇ ਕਰਤਾਰਪ ਦੁਧਰਿਲ  ਮੁਕਖੀ ਵੇਲਦੇ ਜਰਮਰ  ਕੋਈਹ ਥਲਕੇਵਰ ਦੇ ੱਤ ਨਾਲ ਜਰਮ  ਹਰਡ ਆਪੇ ਅਲਗ ਗੋ ਜੰ ਮਾਰ  ਕੀਰਜ ਾਰ ਪਪਦਸਤਾ ਕਰਤਾਰਪੁ ਪੜੀ \n",
      "ਮਹਿਂਦਸਮਲਾਦ ਬਾਿ ਮੁਪੂੇਲਦੇ ਦੂਰ ਕਾਰਤੂਧ ਵਾਆਈ੍ਰ ਕੈਦਗੋਰੰੀ ਚ ਤੀਆਂ ਮੇਹਾ ੀਚਮੁ  ਫਿਜੇੀ ਮੁਲਕ\n",
      "\n",
      "ਿਵਪੁਟ ਦੀ ਪਾਰੀ ਚ 10 ਕਾਰਪੋਰੇ ਯਾਦਵ    \n",
      "ਮਮਊਜੀ ਨਾ ਭੋਜਣ  ਪ਼ੇੂਜੀ  \n"
     ]
    }
   ],
   "source": [
    "gen_len = 500\n",
    "output = model_loaded.multi_token_generate(x,pos, gen_len)\n",
    "print(f'context: {context}')\n",
    "generation = decoder([i.item() for i in output[0][-gen_len:]])\n",
    "print(f'generation: {generation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:573]",
   "language": "python",
   "name": "conda-env-573-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
